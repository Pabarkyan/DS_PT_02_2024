{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESUMEN PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.DataFrame([1.5, 1.6, 1.75, 1.80], index=['Jane', 'Joe', 'Susan', 'Mike'])\n",
    "\n",
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict) \n",
    "\n",
    "lista = ['Pepe', 'Pedro', 'Jose']\n",
    "df_lista = pd.DataFrame(lista)\n",
    "\n",
    "data = {\n",
    "    'Ciudad': ['Madrid', 'Barcelona', 'Valencia', 'Sevilla', 'Zaragoza'],\n",
    "    'Población': [3223334, 1620343, 791413, 688711, 666880],\n",
    "    'Año de Fundación': [860, -15, 138, 712, -14],\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # columnas\n",
    "df.index # indices\n",
    "df.values # Devuelve valores\n",
    "df.keys()\n",
    "df.T # traspuesta\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagen](./01-Teoría/img/merges.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Año</th>\n",
       "      <th>Director</th>\n",
       "      <th>Nacionalidad</th>\n",
       "      <th>Nacimiento</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inception</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>2010</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Reino Unido</td>\n",
       "      <td>1970</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>2008</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Reino Unido</td>\n",
       "      <td>1970</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>2014</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Reino Unido</td>\n",
       "      <td>1970</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>1994</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>1963</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kill Bill: Vol. 1</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>2003</td>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>1963</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Titulo             Direct   Año           Director  \\\n",
       "0          Inception  Christopher Nolan  2010  Christopher Nolan   \n",
       "1    The Dark Knight  Christopher Nolan  2008  Christopher Nolan   \n",
       "2       Interstellar  Christopher Nolan  2014  Christopher Nolan   \n",
       "3       Pulp Fiction  Quentin Tarantino  1994  Quentin Tarantino   \n",
       "4  Kill Bill: Vol. 1  Quentin Tarantino  2003  Quentin Tarantino   \n",
       "\n",
       "     Nacionalidad  Nacimiento _merge  \n",
       "0     Reino Unido        1970   both  \n",
       "1     Reino Unido        1970   both  \n",
       "2     Reino Unido        1970   both  \n",
       "3  Estados Unidos        1963   both  \n",
       "4  Estados Unidos        1963   both  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos unos dataframes de ejemplo:\n",
    "data_peliculas = {\n",
    "    'Titulo': ['Inception', 'The Dark Knight', 'Interstellar', 'Pulp Fiction', 'Kill Bill: Vol. 1'],\n",
    "    'Director': ['Christopher Nolan', 'Christopher Nolan', 'Christopher Nolan', 'Quentin Tarantino', 'Quentin Tarantino'],\n",
    "    'Año': [2010, 2008, 2014, 1994, 2003]\n",
    "}\n",
    "peliculas_df = pd.DataFrame(data_peliculas)\n",
    "\n",
    "data_directores = {\n",
    "    'Director': ['Christopher Nolan', 'Quentin Tarantino', 'Martin Scorsese'],\n",
    "    'Nacionalidad': ['Reino Unido', 'Estados Unidos', 'Estados Unidos'],\n",
    "    'Nacimiento': [1970, 1963, 1942]\n",
    "}\n",
    "directores_df = pd.DataFrame(data_directores)\n",
    "\n",
    "# En terminos graficos el orden de como pongamos los dataframes sera el orden derecha e izquierda, respectivamente, del merge\n",
    "merged_df = pd.merge(peliculas_df, directores_df,  # Aqui los dataframes que queremos combinar\n",
    "    on=['Director'], # Esto puede ser una lista para poder combinar varias columnas\n",
    "    how='outer', # Indica la forma del merge, en la imagen se ven las diferencias, es outer de forma default\n",
    "    indicator=True) # Creara una columna _merge que indica si \n",
    "merged_df\n",
    "\n",
    "# Imaginemos que director no se llama director en alguna de las dos:\n",
    "peliculas_df.columns = ['Titulo', 'Direct', 'Año']\n",
    "merged_df2 = pd.merge(peliculas_df, directores_df,  # Aqui los dataframes que queremos combinar\n",
    "    left_on=['Direct'], right_on=['Director'],\n",
    "    how='inner',\n",
    "    indicator=True) # El problema es que las columnas se podrian llegar a duplicar\n",
    "merged_df2 # Preguntad Jonatan porque no se unen Direct y Director\n",
    "\n",
    "# Recordamos que podemos hacer merge de multiples columnas, con una lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9332 entries, 0 to 9331\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mag           9331 non-null   float64\n",
      " 1   magType       9331 non-null   object \n",
      " 2   time          9332 non-null   int64  \n",
      " 3   place         9332 non-null   object \n",
      " 4   tsunami       9332 non-null   int64  \n",
      " 5   parsed_place  9332 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 437.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>time</th>\n",
       "      <th>place</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>parsed_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>4.9</td>\n",
       "      <td>mb</td>\n",
       "      <td>1538872003570</td>\n",
       "      <td>67km SSW of Intipuca, El Salvador</td>\n",
       "      <td>0</td>\n",
       "      <td>El Salvador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>1.6</td>\n",
       "      <td>ml</td>\n",
       "      <td>1538009428474</td>\n",
       "      <td>123km NNW of Arctic Village, Alaska</td>\n",
       "      <td>0</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mag magType           time                                place  \\\n",
       "1913  4.9      mb  1538872003570    67km SSW of Intipuca, El Salvador   \n",
       "5896  1.6      ml  1538009428474  123km NNW of Arctic Village, Alaska   \n",
       "\n",
       "      tsunami parsed_place  \n",
       "1913        0  El Salvador  \n",
       "5896        0       Alaska  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terremotos = pd.read_csv('./01-Teoría/data/earthquakes.csv', \n",
    "    sep=',', # De forma default sera la coma\n",
    "    encoding=\"utf-8\" # utf-8 es el default, \"latin-1\" es el castellano\n",
    ")\n",
    "\n",
    "terremotos.info() # detalles de tipos y memoria\n",
    "terremotos.describe() # detalles estadisticos\n",
    "terremotos.tail() # Mostrar n ultimas filas\n",
    "terremotos.head(2) # Mostar n primeras filas\n",
    "terremotos.sample(2) # Muestra aleatoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones basicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.35\n",
       "1       1.29\n",
       "2       3.42\n",
       "3       0.44\n",
       "4       2.16\n",
       "        ... \n",
       "9327    0.62\n",
       "9328    1.00\n",
       "9329    2.40\n",
       "9330    1.10\n",
       "9331    0.66\n",
       "Name: mag, Length: 9332, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terremotos['mag'].sum() # Suma todos los valores\n",
    "terremotos['mag'].count() # Cuenta cuantos hay, interesante en booleanos\n",
    "len(terremotos['mag']) # Esto no es lo mismo porque el count no cuenta Nans\n",
    "terremotos['mag'].max()\n",
    "terremotos['mag'].min()\n",
    "terremotos['mag'].median() # mediana\n",
    "terremotos['mag'].mean() # media\n",
    "terremotos['mag'].mode() # moda\n",
    "terremotos['mag'].std() # desviacion tipica\n",
    "terremotos['mag'].unique() # Muestra los valores unicos\n",
    "terremotos['mag'].duplicated() # Valores duplicados\n",
    "terremotos['mag'].quantile(0.95) # percentiles\n",
    "terremotos['mag']*1 # multriplica todos, cualquier operacion es valida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mascaras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos poner tantas condiciones como queramos \n",
    "resultado = terremotos[(terremotos['parsed_place'] == 'Japan') & (terremotos['mag'] >= 4.9)]\n",
    "# Basicamente buscamos dentro del dataframe terremotos todos los terremotos de japon con una magnitud igual o mayor a 4.9\n",
    "\n",
    "resultado1 = terremotos[terremotos['mag'] == terremotos['mag'].max()]\n",
    "# Buscamos todos los terremotos con una escala maxima\n",
    "\n",
    "# Importante: los operadores de las mascaras siempre son |, &, == y nunca cosas como and o or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = pd.read_csv('./01-Teoría/data/faang.csv')\n",
    "\n",
    "# groupby: elemento que crea agrupaciones para hacer operaciones\n",
    "faang.groupby(['ticker'])['volume'].sum()\n",
    "# lo que hace groupby es basicamente es agrupar por elementos unicos, en este caso estamos agrupando por ticker,\n",
    "# que tiene las cateogiras aapl, amzn, fb, goog, nflx y separa cada uno y coge el volumen de cada categoria, y luego\n",
    "# hemos hecho un sum, devolviendonos la suma de todos los volumenes de cada categoría.\n",
    "\n",
    "# apply: operaciones linea por linea\n",
    "faang['apertura top'] = faang['open'].apply(lambda x: x > 1400)\n",
    "# Imaginemos como la x a cada row de open. Hemos creado una columna donde por cada fila de open \n",
    "# Comprobamos si el elemento es mayor a 1400 y devuelve un booleano y lo añade a esa misma fila pero \n",
    "# con la nueva columna\n",
    "\n",
    "# transform: parecido al apply pero podemos hacer operaciones a grupos\n",
    "faang['dist_media'] = faang.groupby(['ticker'])['open'].transform(lambda x: x - x.mean())\n",
    "# lo que hacemos y por lo que se diferencia del apply, es que estamos creando una columna, operando linea por linea\n",
    "# pero en este caso la x es cada resultado de open separado por categoria, de esta forma podemos operar individualmente\n",
    "# la x y acceder a x.mean() que en este caso es la media pero de todo open de cada categoria, al devolver el resultado\n",
    "# lo coloca en la fila donde ha cogido la informacion, es decir cuando se accede al dataframe sin el groupby, se coloca\n",
    "# donde corresponde.\n",
    "\n",
    "# falta aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loc e Iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se utiliza el método .loc[] para filtrar las filas y seleccionar las columnas al mismo tiempo\n",
    "todo_en_uno = terremotos[terremotos['parsed_place'] == 'Japan'][['parsed_place', 'mag', 'magType']]\n",
    "otra = terremotos.loc[terremotos['parsed_place'] == 'Japan', ['parsed_place', 'mag', 'magType']]\n",
    "# En este codigo ambos hacen lo mismo, seleccionan todas las filas del dataframe terremoto donde el lugar sea japon\n",
    "# y luego seleccionan las columnas lugar, magnitud y tipo de magnitud y crea un dataframe de esto,\n",
    "# pero .loc[] es útil cuando necesitas seleccionar datos de manera más precisa, cuando las condiciones de selección \n",
    "# son más complejas o cuando deseas realizar operaciones de asignación de manera segura.\n",
    "\n",
    "# El método .iloc[] se utiliza para seleccionar datos en función de sus posiciones numéricas en el DataFrame.\n",
    "subset = terremotos.iloc[:5, :3]\n",
    "# :5 indica que queremos seleccionar desde la primera fila hasta la quinta fila (exclusiva).\n",
    "# :3 indica que queremos seleccionar desde la primera columna hasta la tercera columna\n",
    "\n",
    "# es útil cuando necesitas seleccionar datos en función de su posición numérica en lugar de sus etiquetas.\n",
    "# Esto es especialmente útil cuando trabajas con grandes conjuntos de datos y no necesariamente conoces las etiquetas \n",
    "# de las filas o columnas, pero sabes su posición relativa dentro del DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>time</th>\n",
       "      <th>place</th>\n",
       "      <th>tsunami</th>\n",
       "      <th>parsed_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.35</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475168010</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.29</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475129610</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.42</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539475062610</td>\n",
       "      <td>8km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>ml</td>\n",
       "      <td>1539474978070</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.16</td>\n",
       "      <td>md</td>\n",
       "      <td>1539474716050</td>\n",
       "      <td>10km NW of Avenal, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>0.62</td>\n",
       "      <td>md</td>\n",
       "      <td>1537230228060</td>\n",
       "      <td>9km ENE of Mammoth Lakes, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>1.00</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537230135130</td>\n",
       "      <td>3km W of Julian, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>2.40</td>\n",
       "      <td>md</td>\n",
       "      <td>1537229908180</td>\n",
       "      <td>35km NNE of Hatillo, Puerto Rico</td>\n",
       "      <td>0</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>1.10</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537229545350</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9331</th>\n",
       "      <td>0.66</td>\n",
       "      <td>ml</td>\n",
       "      <td>1537228864470</td>\n",
       "      <td>9km NE of Aguanga, CA</td>\n",
       "      <td>0</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9331 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mag magType           time                             place  tsunami  \\\n",
       "0     1.35      ml  1539475168010             9km NE of Aguanga, CA        0   \n",
       "1     1.29      ml  1539475129610             9km NE of Aguanga, CA        0   \n",
       "2     3.42      ml  1539475062610             8km NE of Aguanga, CA        0   \n",
       "3     0.44      ml  1539474978070             9km NE of Aguanga, CA        0   \n",
       "4     2.16      md  1539474716050             10km NW of Avenal, CA        0   \n",
       "...    ...     ...            ...                               ...      ...   \n",
       "9327  0.62      md  1537230228060      9km ENE of Mammoth Lakes, CA        0   \n",
       "9328  1.00      ml  1537230135130               3km W of Julian, CA        0   \n",
       "9329  2.40      md  1537229908180  35km NNE of Hatillo, Puerto Rico        0   \n",
       "9330  1.10      ml  1537229545350             9km NE of Aguanga, CA        0   \n",
       "9331  0.66      ml  1537228864470             9km NE of Aguanga, CA        0   \n",
       "\n",
       "     parsed_place  \n",
       "0      California  \n",
       "1      California  \n",
       "2      California  \n",
       "3      California  \n",
       "4      California  \n",
       "...           ...  \n",
       "9327   California  \n",
       "9328   California  \n",
       "9329  Puerto Rico  \n",
       "9330   California  \n",
       "9331   California  \n",
       "\n",
       "[9331 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿hay algun nan en el dataframe?\n",
    "terremotos.isna().any() # podemos usar isna() o isnull()\n",
    "\n",
    "# magType y mag son las unicas columnas con Nan\n",
    "# Eliminamar el Nan\n",
    "terremotos.dropna(subset=['mag'], inplace=True) # El inplace true para que modifique el dataframe directamente\n",
    "\n",
    "# Rellenar los Nans\n",
    "terremotos['magType'] = terremotos['magType'].fillna(\"\")\n",
    "terremotos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>102223600.0</td>\n",
       "      <td>aapl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>43.637501</td>\n",
       "      <td>42.990002</td>\n",
       "      <td>43.132500</td>\n",
       "      <td>43.057499</td>\n",
       "      <td>118071600.0</td>\n",
       "      <td>aapl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  Unnamed: 0       high        low       open      close  \\\n",
       "0  2018-01-02           0  43.075001  42.314999  42.540001  43.064999   \n",
       "1  2018-01-03           1  43.637501  42.990002  43.132500  43.057499   \n",
       "\n",
       "        volume ticker  \n",
       "0  102223600.0   aapl  \n",
       "1  118071600.0   aapl  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang = pd.read_csv('./01-Teoría/data/faang.csv')\n",
    "\n",
    "# Creamos un indice\n",
    "faang.set_index('date', inplace=True) # Es una buena practica establecer la fecha como indice, comprobando antes que no hay cosas como duplicados\n",
    "\n",
    "# Si queremos quitar el indice\n",
    "faang.reset_index(inplace=True)\n",
    "faang.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesos tipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas\n",
    "faang.columns\n",
    "faang.columns = [x.lower() for x in faang.columns] # cambiamos las columnas\n",
    "faang.rename(columns={'open': 'Open'}, inplace=True) # Otra forma\n",
    "\n",
    "faang.drop(columns=[\"unnamed: 0\"], inplace=True, errors='ignore') # Eliminar columnas ignorando errores\n",
    "\n",
    "# Averiguamos el tipo de dato de la columna date\n",
    "faang['date'].dtypes\n",
    "type(faang['date'][0])\n",
    "faang['date'] = pd.to_datetime(faang['date']) # pasamos a formato fecha\n",
    "\n",
    "# Para cambiar el tipo de dato de una columna (en este caso lo pasamos a int y luego lo volvemos a dejar en float)\n",
    "terremotos['mag'] = terremotos['mag'].astype(str).astype(float)\n",
    "\n",
    "# Comprobamos si existen duplicados: dos formas, importante hacerlo en columnas donde el valor debe ser unico (no es el caso del codigo de abajo)\n",
    "faang['date'].value_counts() # En forma de dataserie, esto es interesante tambien si solo hay dos valores y queremos ver cuantos son true y cuantos falses (por ejemplo)\n",
    "faang[faang[\"date\"].duplicated()] # En forma de dataframe\n",
    "\n",
    "# Ordenar\n",
    "faang_ordenado = faang.sort_index() # Ordena por indice de forma ascendente por defecto\n",
    "faang_ordenado = faang.sort_index(ascending=False) # esto es de mayor a menor\n",
    "faang_ordenado = faang.sort_values(by='high' ,ascending=True) # ascending es true de forma default\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

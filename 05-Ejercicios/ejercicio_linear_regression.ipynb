{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39b08738-02bc-4f7f-bfa5-f0e8afb94037",
    "_uuid": "40228e8478617fa52cb27da39bedbc4d2eea8831"
   },
   "source": [
    "## **Predicting Housing Prices for regions in the USA.**\n",
    "\n",
    "The data contains the following columns:\n",
    "\n",
    "* 'Avg. Area Income': Avg. Income of residents of the city house is located in.\n",
    "* 'Avg. Area House Age': Avg Age of Houses in same city\n",
    "* 'Avg. Area Number of Rooms': Avg Number of Rooms for Houses in same city\n",
    "* 'Avg. Area Number of Bedrooms': Avg Number of Bedrooms for Houses in same city\n",
    "* 'Area Population': Population of city house is located in\n",
    "* 'Price': Price that the house sold at\n",
    "* 'Address': Address for the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4afddcca-ebe2-4b81-9bcf-700841c8cd9c",
    "_uuid": "a41cbd7e7ee45d1859b75c11db843b2ca1ce06ef"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "499a4b39-04ab-4fae-82e9-51255ee1cf8b",
    "_uuid": "df7d07be0d1051cdf43415d65fb1f4b13bac86c6"
   },
   "outputs": [],
   "source": [
    "# loading csv data to dataframe \n",
    "USA_Housing = pd.read_csv('data/USA_Housing.csv')\n",
    "# checking out the Data\n",
    "USA_Housing.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ce3aa20-a38a-4eec-8c49-f737d0de3b76",
    "_uuid": "9c566b7f3356b0d66f0b9c6213f38b42b343cb9f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#checking columns and total records\n",
    "USA_Housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "87810e67-48af-4eda-b000-6ba92b68340b",
    "_uuid": "655d6deb9b354bb3997090ae09418b85609884fb"
   },
   "source": [
    " **Generating descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN value.\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d76c0b52-60a6-463a-82e8-5b37a6b12505",
    "_uuid": "a18b840ef25937bb6a8b93d0b04aff9e9dff8b9b"
   },
   "outputs": [],
   "source": [
    "USA_Housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la columna address no la podemos usar al ser un texto diferente para cada casa\n",
    "# Elimina dicha columna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia los nombres de las columnas para elminar espacios, mayúsculas y signos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea dos variables X e y\n",
    "# X contiene las features\n",
    "# y contiene la variable a precedir, en este caso precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza la regresión lineal\n",
    "\n",
    "# Creación del modelo utilizando matrices como en scikitlearn\n",
    "# ==============================================================================\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el intercept del modelo\n",
    "\n",
    "# La convenciones determinan que las features se llamen X \n",
    "# Además, tendremos habitualmente un conjunto de train y otro de test (con un split del 80/20, habitualmente)\n",
    "# Por lo tanto, X_train contiene las features del train\n",
    "# Este caso es tan sencillo y con pocos datos que no tenemos X_test, pero aparecerá\n",
    "X_train = \n",
    "# Añadimos una columna de 1 porque necesitamos una constante que determine el intercept o B0, el punto donde corta la recta con el eje Y\n",
    "# Por eso añadimos una columna constante de 0s\n",
    "# Veremos que estoy aparece en muchos otros modelos (en redes neuronales se llama bias)\n",
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "# OLS: creamos el modelo del tipo Ordinary Least Squares (por alguna razón creo que una vez dije Optimal pero es Ordinary)\n",
    "modelo = sm.OLS(endog=, exog=X_train)\n",
    "# Ajustamos el modelo, es decir, hacemos el calculo de la mejor recta posible según los criterios del OLS\n",
    "modelo = modelo.fit()\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrepreta los coeficientes, R2, R2 ajustado y  F-statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haz un gráfico de los residuos para comprobar que no hay sesgos y calcula su media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional: para practicar cálculos\n",
    "# Siguiendo el notebook 00_regresion_lineal calcula y comprueba que te salen los mismos números para:\n",
    "# R2\n",
    "# R2 ajustado\n",
    "# F-statistic\n",
    "# RMSE\n",
    "# y todos los demas vistos en el notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train y test\n",
    "\n",
    "Esta vez vamos a separar train y test para hacer predicciones con datos no usados en el modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Esta vez, nuestro modelo serán el 80% de los datos y el test el 20% de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(, , test_size = 0.20, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una nueva regresión lineal (no uses el mismo nombre que la anterior!!!) usando X_train e y_train\n",
    "# Realiza la regresión lineal\n",
    "\n",
    "# Creación del modelo utilizando matrices como en scikitlearn\n",
    "# ==============================================================================\n",
    "# A la matriz de predictores se le tiene que añadir una columna de 1s para el intercept del modelo\n",
    "\n",
    "# La convenciones determinan que las features se llamen X \n",
    "# Además, tendremos habitualmente un conjunto de train y otro de test (con un split del 80/20, habitualmente)\n",
    "# Por lo tanto, X_train contiene las features del train\n",
    "# Este caso es tan sencillo y con pocos datos que no tenemos X_test, pero aparecerá\n",
    "#X_train = USA_Housing[[\"Avg. Area Income\",\t\"Avg. Area House Age\",\t\"Avg. Area Number of Rooms\", \t\"Avg. Area Number of Bedrooms\",\t\"Area Population\"]]\n",
    "\n",
    "# Añadimos una columna de 1 porque necesitamos una constante que determine el intercept o B0, el punto donde corta la recta con el eje Y\n",
    "# Por eso añadimos una columna constante de 0s\n",
    "# Veremos que estoy aparece en muchos otros modelos (en redes neuronales se llama bias)\n",
    "X_train = sm.add_constant(X_train, prepend=True)\n",
    "# OLS: creamos el modelo del tipo Ordinary Least Squares (por alguna razón creo que una vez dije Optimal pero es Ordinary)\n",
    "modelo_ = sm.OLS(endog=, exog=)\n",
    "# Ajustamos el modelo, es decir, hacemos el calculo de la mejor recta posible según los criterios del OLS\n",
    "modelo_ = modelo_.fit()\n",
    "print(modelo_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predice los precios para X_test usando este nuevo modelo y el anterior\n",
    "# utiliza el método predict que tienen los modelos \n",
    "X_test = sm.add_constant(X_test, prepend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara el error en cada modelo. ¿Cuál es mayor? ¿Sabrías decir el motivo?\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c77fdb427e7cbc9bc1367dd530fc2b36aacdbbde1ac83c85833b10dfa8b831c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate cancer prediction \n",
    "\n",
    "#### Data\n",
    "\n",
    "We consider a medical study conducted on 97 men with prostate cancer.\n",
    "The focus is on the relationship between the prostate specific antigen (psa), which is elevated in men with prostate cancer, and others clinical measures. \n",
    "The others clinical measures are the predictors variables, gathered in a medical examination, and the amount of expression of the antigen associated with the cancer detection is the response variable (lpsa).\n",
    "\n",
    "Thus the data frame is made of 97 observations on 9 variables:\n",
    "* lcavol: log cancer volume\n",
    "* lweight: log prostate weight\n",
    "* age: patient age in years\n",
    "* lbph: log amount of benign prostatic hyperplasia\n",
    "* svi: seminal vesicle invasion\n",
    "* lcp: log of capsular penetration\n",
    "* gleason: Gleason score\n",
    "* pgg45: percent of Gleason score 4 or 5\n",
    "* lpsa: log prostate specific antigen\n",
    "\n",
    "The goal is to find models predicting the response lpsa.\n",
    "\n",
    "#### Models\n",
    "\n",
    "The data are represented by $n$ points in $p$ dimensions, thus the predictor variable is written $X\\in\\mathbb{R}^{n\\times p}$ and the response variable is $y\\in\\mathbb{R}^n$.\n",
    "\n",
    "In this work, we're insterested in the relationship between the predictor $X$ and the response $y$.\n",
    "To determine this relationship, we adopt regression models.\n",
    "The standard baseline is achieved with linear regression and we compare results for regularized regressions: **Ridge regression**, **Lasso** and **Elastic Net**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpsa_data = pd.read_csv('data/prostate_dataset.txt', delimiter='\\t')\n",
    "lpsa_data.drop(columns=['col'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783\n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519\n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519\n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519\n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpsa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280521</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.734460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.280521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.433319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.169593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.179809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.566218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.548813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>0.368987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.433319</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.179809</td>\n",
       "      <td>0.566218</td>\n",
       "      <td>0.548813</td>\n",
       "      <td>0.368987</td>\n",
       "      <td>0.422316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.280521  0.225000  0.027350  0.538845  0.675310  0.432417   \n",
       "lweight  0.280521  1.000000  0.347969  0.442264  0.155385  0.164537  0.056882   \n",
       "age      0.225000  0.347969  1.000000  0.350186  0.117658  0.127668  0.268892   \n",
       "lbph     0.027350  0.442264  0.350186  1.000000 -0.085843 -0.006999  0.077820   \n",
       "svi      0.538845  0.155385  0.117658 -0.085843  1.000000  0.673111  0.320412   \n",
       "lcp      0.675310  0.164537  0.127668 -0.006999  0.673111  1.000000  0.514830   \n",
       "gleason  0.432417  0.056882  0.268892  0.077820  0.320412  0.514830  1.000000   \n",
       "pgg45    0.433652  0.107354  0.276112  0.078460  0.457648  0.631528  0.751905   \n",
       "lpsa     0.734460  0.433319  0.169593  0.179809  0.566218  0.548813  0.368987   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.433652  0.734460  \n",
       "lweight  0.107354  0.433319  \n",
       "age      0.276112  0.169593  \n",
       "lbph     0.078460  0.179809  \n",
       "svi      0.457648  0.566218  \n",
       "lcp      0.631528  0.548813  \n",
       "gleason  0.751905  0.368987  \n",
       "pgg45    1.000000  0.422316  \n",
       "lpsa     0.422316  1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpsa_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783\n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519\n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519\n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519\n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpsa_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280521</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.734460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.280521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.433319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.347969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.169593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.027350</td>\n",
       "      <td>0.442264</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.179809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>-0.085843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.566218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.675310</td>\n",
       "      <td>0.164537</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>-0.006999</td>\n",
       "      <td>0.673111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.548813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.432417</td>\n",
       "      <td>0.056882</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.077820</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.514830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>0.368987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.433652</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.276112</td>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.457648</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>0.751905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.433319</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.179809</td>\n",
       "      <td>0.566218</td>\n",
       "      <td>0.548813</td>\n",
       "      <td>0.368987</td>\n",
       "      <td>0.422316</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.280521  0.225000  0.027350  0.538845  0.675310  0.432417   \n",
       "lweight  0.280521  1.000000  0.347969  0.442264  0.155385  0.164537  0.056882   \n",
       "age      0.225000  0.347969  1.000000  0.350186  0.117658  0.127668  0.268892   \n",
       "lbph     0.027350  0.442264  0.350186  1.000000 -0.085843 -0.006999  0.077820   \n",
       "svi      0.538845  0.155385  0.117658 -0.085843  1.000000  0.673111  0.320412   \n",
       "lcp      0.675310  0.164537  0.127668 -0.006999  0.673111  1.000000  0.514830   \n",
       "gleason  0.432417  0.056882  0.268892  0.077820  0.320412  0.514830  1.000000   \n",
       "pgg45    0.433652  0.107354  0.276112  0.078460  0.457648  0.631528  0.751905   \n",
       "lpsa     0.734460  0.433319  0.169593  0.179809  0.566218  0.548813  0.368987   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.433652  0.734460  \n",
       "lweight  0.107354  0.433319  \n",
       "age      0.276112  0.169593  \n",
       "lbph     0.078460  0.179809  \n",
       "svi      0.457648  0.566218  \n",
       "lcp      0.631528  0.548813  \n",
       "gleason  0.751905  0.368987  \n",
       "pgg45    1.000000  0.422316  \n",
       "lpsa     0.422316  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpsa_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The more correlated variable with the response lpsa is lcavol.\n",
    "  Thus in a data analysis, the lcavol variable must be included as a predictor.\n",
    "\n",
    "* The correlation matrix shows that gleason and pgg45 are actually correlated. \n",
    "  Indeed, the variable pgg45 measures the percentage of 4 or 5 Gleason scores that were recorded before the final current Gleason score.\n",
    "\n",
    "Let plot the relationship between the response lpsa and the lcavol feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(lpsa_data['lcavol'], lpsa_data['lpsa'])\n",
    "plt.xlabel('lcavol', fontsize=16)\n",
    "plt.ylabel('lpsa', fontsize=16)\n",
    "plt.title(\"Relationship between lpsa and lcavol\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a pretty clear linear relationship with positive correlation, as seen on the correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data train/test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
       "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
       "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
       "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  97.000000   97.000000  97.000000  \n",
       "mean    6.752577   24.381443   2.478387  \n",
       "std     0.722134   28.204035   1.154329  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.731656  \n",
       "50%     7.000000   15.000000   2.591516  \n",
       "75%     7.000000   40.000000   3.056357  \n",
       "max     9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpsa_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como tenemos nicamente 97 observaciones, vamos a separar 60/37 para intentar tener volumen en train y test.\n",
    "\n",
    "###### PD. Sale mal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : the first rows \n",
    "# test : the last rows \n",
    "n_split = 60\n",
    "train = lpsa_data.iloc[:60]\n",
    "test = lpsa_data.iloc[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=['lpsa'])\n",
    "y_test = test['lpsa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['lpsa'])\n",
    "y_train = train['lpsa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.286522449705847\n",
      "Train RMSE: 0.5352779181937612\n",
      "Test MSE: 2.820838873794865\n",
      "Test RMSE: 1.6795353148400498\n"
     ]
    }
   ],
   "source": [
    "print(\"Train MSE:\", metrics.mean_squared_error(y_train, lr.predict(X_train)))\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print(\"Test MSE:\", metrics.mean_squared_error(y_test, lr.predict(X_test)))\n",
    "print(\"Test RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "attachments": {
    "Sin ttulo.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sin ttulo.png](<attachment:Sin ttulo.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.817244</td>\n",
       "      <td>3.512151</td>\n",
       "      <td>62.516667</td>\n",
       "      <td>0.017512</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.734113</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>1.809756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.022356</td>\n",
       "      <td>0.405856</td>\n",
       "      <td>7.443554</td>\n",
       "      <td>1.428480</td>\n",
       "      <td>0.181020</td>\n",
       "      <td>1.049179</td>\n",
       "      <td>0.696034</td>\n",
       "      <td>24.455771</td>\n",
       "      <td>0.811103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.212938</td>\n",
       "      <td>3.261885</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.434868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.886033</td>\n",
       "      <td>3.508528</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>-0.178337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.909433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.479321</td>\n",
       "      <td>3.809672</td>\n",
       "      <td>67.250000</td>\n",
       "      <td>1.479298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.529626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.153590</td>\n",
       "      <td>4.280132</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.171337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.656757</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.812410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  60.000000  60.000000  60.000000  60.000000  60.000000  60.000000   \n",
       "mean    0.817244   3.512151  62.516667   0.017512   0.033333  -0.734113   \n",
       "std     1.022356   0.405856   7.443554   1.428480   0.181020   1.049179   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.212938   3.261885  59.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     0.886033   3.508528  64.000000  -0.178337   0.000000  -1.386294   \n",
       "75%     1.479321   3.809672  67.250000   1.479298   0.000000  -0.430783   \n",
       "max     3.153590   4.280132  79.000000   2.171337   1.000000   2.656757   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  60.000000   60.000000  60.000000  \n",
       "mean    6.583333   15.500000   1.809756  \n",
       "std     0.696034   24.455771   0.811103  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.434868  \n",
       "50%     6.500000    2.000000   1.909433  \n",
       "75%     7.000000   20.000000   2.529626  \n",
       "max     9.000000  100.000000   2.812410  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.213953</td>\n",
       "      <td>3.818334</td>\n",
       "      <td>66.054054</td>\n",
       "      <td>0.234697</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.720225</td>\n",
       "      <td>7.027027</td>\n",
       "      <td>38.783784</td>\n",
       "      <td>3.562653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.866739</td>\n",
       "      <td>0.399843</td>\n",
       "      <td>7.003753</td>\n",
       "      <td>1.496221</td>\n",
       "      <td>0.506712</td>\n",
       "      <td>1.436977</td>\n",
       "      <td>0.686638</td>\n",
       "      <td>28.220496</td>\n",
       "      <td>0.722263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.446287</td>\n",
       "      <td>3.070376</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.841998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.731656</td>\n",
       "      <td>3.582129</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.972975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.198335</td>\n",
       "      <td>3.823192</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.457893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.807594</td>\n",
       "      <td>3.917011</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.638997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.909542</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3.712352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  37.000000  37.000000  37.000000  37.000000  37.000000  37.000000   \n",
       "mean    2.213953   3.818334  66.054054   0.234697   0.513514   0.720225   \n",
       "std     0.866739   0.399843   7.003753   1.496221   0.506712   1.436977   \n",
       "min    -0.446287   3.070376  44.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     1.731656   3.582129  62.000000  -1.386294   0.000000  -0.430783   \n",
       "50%     2.198335   3.823192  68.000000   0.438255   1.000000   0.810930   \n",
       "75%     2.807594   3.917011  69.000000   1.638997   1.000000   1.909542   \n",
       "max     3.821004   4.780383  78.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason      pgg45       lpsa  \n",
       "count  37.000000  37.000000  37.000000  \n",
       "mean    7.027027  38.783784   3.562653  \n",
       "std     0.686638  28.220496   0.722263  \n",
       "min     6.000000   0.000000   2.841998  \n",
       "25%     7.000000  15.000000   2.972975  \n",
       "50%     7.000000  40.000000   3.457893  \n",
       "75%     7.000000  60.000000   3.712352  \n",
       "max     9.000000  95.000000   5.582932  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora, lo haremos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train : the first rows \n",
    "# test : the last rows \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Esta vez, nuestro modelo sern el 80% de los datos y el test el 20% de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(lpsa_data.drop(columns=[\"lpsa\"]), lpsa_data[\"lpsa\"], test_size = 0.38, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 8)\n",
      "(37, 8)\n",
      "(60,)\n",
      "(37,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediccion Train y test\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_T = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.46641709886601684\n",
      "Train RMSE: 0.6829473617095367\n",
      "Test MSE: 0.4556378245771581\n",
      "Test RMSE: 0.6750094996199373\n"
     ]
    }
   ],
   "source": [
    "print(\"Train MSE:\", metrics.mean_squared_error(y_train, lr.predict(X_train)))\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print(\"Test MSE:\", metrics.mean_squared_error(y_test, lr.predict(X_test)))\n",
    "print(\"Test RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.508830</td>\n",
       "      <td>3.693007</td>\n",
       "      <td>64.833333</td>\n",
       "      <td>0.203303</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>-0.109868</td>\n",
       "      <td>6.733333</td>\n",
       "      <td>21.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.141785</td>\n",
       "      <td>0.431867</td>\n",
       "      <td>7.404000</td>\n",
       "      <td>1.509052</td>\n",
       "      <td>0.426522</td>\n",
       "      <td>1.482964</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>24.804433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.726160</td>\n",
       "      <td>3.468032</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.519698</td>\n",
       "      <td>3.696258</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.438255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.092401</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.440459</td>\n",
       "      <td>3.931508</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.643805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>36.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.471966</td>\n",
       "      <td>4.718052</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  60.000000  60.000000  60.000000  60.000000  60.000000  60.000000   \n",
       "mean    1.508830   3.693007  64.833333   0.203303   0.233333  -0.109868   \n",
       "std     1.141785   0.431867   7.404000   1.509052   0.426522   1.482964   \n",
       "min    -1.203973   2.374906  43.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.726160   3.468032  61.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.519698   3.696258  66.000000   0.438255   0.000000  -1.092401   \n",
       "75%     2.440459   3.931508  69.000000   1.643805   0.000000   1.321756   \n",
       "max     3.471966   4.718052  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45  \n",
       "count  60.000000   60.000000  \n",
       "mean    6.733333   21.833333  \n",
       "std     0.578328   24.804433  \n",
       "min     6.000000    0.000000  \n",
       "25%     6.000000    0.000000  \n",
       "50%     7.000000   15.000000  \n",
       "75%     7.000000   36.250000  \n",
       "max     9.000000  100.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train y X_test... son realmente iguales?\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.092463</td>\n",
       "      <td>3.525054</td>\n",
       "      <td>62.297297</td>\n",
       "      <td>-0.066587</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>-0.292064</td>\n",
       "      <td>6.783784</td>\n",
       "      <td>28.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.207323</td>\n",
       "      <td>0.407222</td>\n",
       "      <td>7.340394</td>\n",
       "      <td>1.354422</td>\n",
       "      <td>0.397061</td>\n",
       "      <td>1.260272</td>\n",
       "      <td>0.916974</td>\n",
       "      <td>32.932272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.254642</td>\n",
       "      <td>3.244544</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.193922</td>\n",
       "      <td>3.473518</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>-0.051293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.731656</td>\n",
       "      <td>3.773910</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.266948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.420368</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  37.000000  37.000000  37.000000  37.000000  37.000000  37.000000   \n",
       "mean    1.092463   3.525054  62.297297  -0.066587   0.189189  -0.292064   \n",
       "std     1.207323   0.407222   7.340394   1.354422   0.397061   1.260272   \n",
       "min    -1.347074   2.769459  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.254642   3.244544  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.193922   3.473518  63.000000  -0.051293   0.000000  -0.798508   \n",
       "75%     1.731656   3.773910  66.000000   1.266948   0.000000   0.300105   \n",
       "max     3.821004   4.780383  76.000000   2.326302   1.000000   2.420368   \n",
       "\n",
       "         gleason      pgg45  \n",
       "count  37.000000  37.000000  \n",
       "mean    6.783784  28.513514  \n",
       "std     0.916974  32.932272  \n",
       "min     6.000000   0.000000  \n",
       "25%     6.000000   0.000000  \n",
       "50%     7.000000  15.000000  \n",
       "75%     7.000000  60.000000  \n",
       "max     9.000000  95.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpsa_data[\"lcavol_s\"] = lpsa_data[\"lcavol\"].astype(int)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.38, random_state=42)\n",
    "for train_index, test_index in split.split(lpsa_data, lpsa_data[\"lcavol_s\"]):\n",
    "    X_train = lpsa_data.iloc[train_index]\n",
    "    X_test = lpsa_data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>lcavol_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.301004</td>\n",
       "      <td>3.617593</td>\n",
       "      <td>64.050000</td>\n",
       "      <td>0.262621</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-0.278595</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>23.083333</td>\n",
       "      <td>2.381677</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.198542</td>\n",
       "      <td>0.410365</td>\n",
       "      <td>7.091234</td>\n",
       "      <td>1.476477</td>\n",
       "      <td>0.360085</td>\n",
       "      <td>1.317032</td>\n",
       "      <td>0.794579</td>\n",
       "      <td>29.575122</td>\n",
       "      <td>1.177201</td>\n",
       "      <td>0.991489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.444116</td>\n",
       "      <td>3.367183</td>\n",
       "      <td>60.750000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709252</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.440862</td>\n",
       "      <td>3.628319</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.526720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.591516</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.086639</td>\n",
       "      <td>3.849615</td>\n",
       "      <td>68.250000</td>\n",
       "      <td>1.667575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810930</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.983002</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.302849</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.656757</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.477509</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  60.000000  60.000000  60.000000  60.000000  60.000000  60.000000   \n",
       "mean    1.301004   3.617593  64.050000   0.262621   0.150000  -0.278595   \n",
       "std     1.198542   0.410365   7.091234   1.476477   0.360085   1.317032   \n",
       "min    -1.203973   2.691243  43.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.444116   3.367183  60.750000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.440862   3.628319  65.000000   0.526720   0.000000  -0.798508   \n",
       "75%     2.086639   3.849615  68.250000   1.667575   0.000000   0.810930   \n",
       "max     3.302849   4.780383  79.000000   2.326302   1.000000   2.656757   \n",
       "\n",
       "         gleason       pgg45       lpsa   lcavol_s  \n",
       "count  60.000000   60.000000  60.000000  60.000000  \n",
       "mean    6.750000   23.083333   2.381677   1.000000  \n",
       "std     0.794579   29.575122   1.177201   0.991489  \n",
       "min     6.000000    0.000000  -0.430783  -1.000000  \n",
       "25%     6.000000    0.000000   1.709252   0.000000  \n",
       "50%     7.000000    8.000000   2.591516   1.000000  \n",
       "75%     7.000000   40.000000   2.983002   2.000000  \n",
       "max     9.000000  100.000000   5.477509   3.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>lcavol_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.429478</td>\n",
       "      <td>3.647348</td>\n",
       "      <td>63.567568</td>\n",
       "      <td>-0.162777</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>-0.018453</td>\n",
       "      <td>6.756757</td>\n",
       "      <td>26.486486</td>\n",
       "      <td>2.635214</td>\n",
       "      <td>1.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.157435</td>\n",
       "      <td>0.461388</td>\n",
       "      <td>8.077887</td>\n",
       "      <td>1.387483</td>\n",
       "      <td>0.474579</td>\n",
       "      <td>1.525715</td>\n",
       "      <td>0.596537</td>\n",
       "      <td>26.083862</td>\n",
       "      <td>1.114103</td>\n",
       "      <td>0.957035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.620576</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800058</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.598681</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.568788</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.409644</td>\n",
       "      <td>3.917011</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.936093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.348073</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.457893</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.718052</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.582932</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  37.000000  37.000000  37.000000  37.000000  37.000000  37.000000   \n",
       "mean    1.429478   3.647348  63.567568  -0.162777   0.324324  -0.018453   \n",
       "std     1.157435   0.461388   8.077887   1.387483   0.474579   1.525715   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.620576   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.598681  65.000000  -1.386294   0.000000  -0.430783   \n",
       "75%     2.409644   3.917011  68.000000   0.936093   1.000000   1.348073   \n",
       "max     3.821004   4.718052  78.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason      pgg45       lpsa   lcavol_s  \n",
       "count  37.000000  37.000000  37.000000  37.000000  \n",
       "mean    6.756757  26.486486   2.635214   1.027027  \n",
       "std     0.596537  26.083862   1.114103   0.957035  \n",
       "min     6.000000   0.000000   0.371564  -1.000000  \n",
       "25%     6.000000   0.000000   1.800058   0.000000  \n",
       "50%     7.000000  20.000000   2.568788   1.000000  \n",
       "75%     7.000000  40.000000   3.457893   2.000000  \n",
       "max     9.000000  80.000000   5.582932   3.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=[\"lcavol_s\"])\n",
    "X_test = X_test.drop(columns=[\"lcavol_s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 1.1555745155937351\n",
      "Train RMSE: 1.0749765186243536\n",
      "Test MSE: 1.2504856084478755\n",
      "Test RMSE: 1.118251138361985\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Train MSE:\", metrics.mean_squared_error(y_train, lr.predict(X_train)))\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print(\"Test MSE:\", metrics.mean_squared_error(y_test, lr.predict(X_test)))\n",
    "print(\"Test RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpsa_data[\"lcavol_s\"] = round(lpsa_data[\"lcavol\"]).astype(int)\n",
    "lpsa_data[\"lcavol_s\"] = lpsa_data[\"lcavol_s\"].replace(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lcavol_s\n",
       " 1    30\n",
       " 2    23\n",
       " 3    21\n",
       " 0    14\n",
       "-1     9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpsa_data[\"lcavol_s\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.38, random_state=42)\n",
    "for train_index, test_index in split.split(lpsa_data, lpsa_data[\"lcavol_s\"]):\n",
    "    X_train = lpsa_data.iloc[train_index]\n",
    "    X_test = lpsa_data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>lcavol_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.345637</td>\n",
       "      <td>3.613961</td>\n",
       "      <td>63.516667</td>\n",
       "      <td>-0.027204</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.239895</td>\n",
       "      <td>6.716667</td>\n",
       "      <td>22.733333</td>\n",
       "      <td>2.468625</td>\n",
       "      <td>1.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.173515</td>\n",
       "      <td>0.451641</td>\n",
       "      <td>7.632428</td>\n",
       "      <td>1.465485</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>1.349602</td>\n",
       "      <td>0.640224</td>\n",
       "      <td>26.555900</td>\n",
       "      <td>1.208289</td>\n",
       "      <td>1.255384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.498974</td>\n",
       "      <td>3.267666</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.709252</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.377626</td>\n",
       "      <td>3.553816</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>-0.663070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.591516</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.144864</td>\n",
       "      <td>3.879486</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.490289</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.714376</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.061019</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.471966</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.582932</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  60.000000  60.000000  60.000000  60.000000  60.000000  60.000000   \n",
       "mean    1.345637   3.613961  63.516667  -0.027204   0.250000  -0.239895   \n",
       "std     1.173515   0.451641   7.632428   1.465485   0.436667   1.349602   \n",
       "min    -0.994252   2.691243  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.498974   3.267666  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.377626   3.553816  64.500000  -0.663070   0.000000  -0.798508   \n",
       "75%     2.144864   3.879486  68.000000   1.490289   0.250000   0.714376   \n",
       "max     3.471966   4.780383  78.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason      pgg45       lpsa   lcavol_s  \n",
       "count  60.000000  60.000000  60.000000  60.000000  \n",
       "mean    6.716667  22.733333   2.468625   1.316667  \n",
       "std     0.640224  26.555900   1.208289   1.255384  \n",
       "min     6.000000   0.000000  -0.430783  -1.000000  \n",
       "25%     6.000000   0.000000   1.709252   0.750000  \n",
       "50%     7.000000  10.000000   2.591516   1.000000  \n",
       "75%     7.000000  40.000000   3.061019   2.000000  \n",
       "max     9.000000  90.000000   5.582932   3.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>lcavol_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.357100</td>\n",
       "      <td>3.653237</td>\n",
       "      <td>64.432432</td>\n",
       "      <td>0.307208</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>-0.081209</td>\n",
       "      <td>6.810811</td>\n",
       "      <td>27.054054</td>\n",
       "      <td>2.494216</td>\n",
       "      <td>1.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.203063</td>\n",
       "      <td>0.392618</td>\n",
       "      <td>7.197764</td>\n",
       "      <td>1.421990</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>1.487442</td>\n",
       "      <td>0.844520</td>\n",
       "      <td>30.880546</td>\n",
       "      <td>1.077095</td>\n",
       "      <td>1.209944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.582216</td>\n",
       "      <td>3.473518</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.008214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.458615</td>\n",
       "      <td>3.682610</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.936093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.597837</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.568788</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.024193</td>\n",
       "      <td>3.865979</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.638997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.037354</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.718052</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.122262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.656757</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.684443</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  37.000000  37.000000  37.000000  37.000000  37.000000  37.000000   \n",
       "mean    1.357100   3.653237  64.432432   0.307208   0.162162  -0.081209   \n",
       "std     1.203063   0.392618   7.197764   1.421990   0.373684   1.487442   \n",
       "min    -1.347074   2.374906  44.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.582216   3.473518  61.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.458615   3.682610  65.000000   0.936093   0.000000  -0.597837   \n",
       "75%     2.024193   3.865979  68.000000   1.638997   0.000000   1.321756   \n",
       "max     3.821004   4.718052  79.000000   2.122262   1.000000   2.656757   \n",
       "\n",
       "         gleason       pgg45       lpsa   lcavol_s  \n",
       "count  37.000000   37.000000  37.000000  37.000000  \n",
       "mean    6.810811   27.054054   2.494216   1.378378  \n",
       "std     0.844520   30.880546   1.077095   1.209944  \n",
       "min     6.000000    0.000000  -0.162519  -1.000000  \n",
       "25%     6.000000    0.000000   2.008214   1.000000  \n",
       "50%     7.000000   15.000000   2.568788   1.000000  \n",
       "75%     7.000000   50.000000   3.037354   2.000000  \n",
       "max     9.000000  100.000000   4.684443   3.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpsa_data.drop(columns=[\"col\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train[\"lpsa\"]\n",
    "X_train.drop(columns=[\"lpsa\", \"lcavol_s\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test[\"lpsa\"]\n",
    "X_test.drop(columns=[\"lpsa\", \"lcavol_s\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning models\n",
    "\n",
    "\n",
    "# 1) Linear regression baseline\n",
    "\n",
    "The linear regression attemps to model the relationship between the predictors variables $X$ and the response variable $y$.\n",
    "It consists in finding a linear function $f:\\mathbb{R}^p \\to \\mathbb{R}$ which predicts the response $y_i$ from the predictors $X_{i1},...,X_{ip}$ given $n$ observations for $i=1,...,n$.\n",
    "\n",
    "In Python, the linear regression is implemented as  [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) in the linear_model module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "baseline_error = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Train MSE:\", metrics.mean_squared_error(y_train, lr.predict(X_train)))\n",
    "print(\"Train RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print(\"Test MSE:\", metrics.mean_squared_error(y_test, lr.predict(X_test)))\n",
    "print(\"Test RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Regularization\n",
    "\n",
    "In order to avoid over-learning, the regularization method allows to control the model complexity.\n",
    "The model minimizes the error plus a regularization term $\\lambda Reg(\\beta)$ measuring the complexity, where $Reg(\\beta)$ is a penalty term and $\\lambda$ is an hyper-parameter.\n",
    "The hyper-parameter controls the relative influence of the error term and the amount of regularization.\n",
    "The optimal value of $\\lambda$ can be found by cross validation (see repository [cross-validation](https://github.com/christelle-git/cross-validation/)). \n",
    "\n",
    "## 2.1) Ridge regression \n",
    "\n",
    "In the Ridge regression, the regularization term is $Reg(\\beta) = ||\\beta||_2^2$.\n",
    "The Ridge regression allows to reduce the magnitude of the weights $\\beta_i$ of the linear regression, and thus avoid over-learning.\n",
    "The Ridge regression has a grouped selection effect: the correlated variables have the same weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridgeR = Ridge(alpha =,)\n",
    "ridgeR.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train MSE sin regularizacin:\", round(metrics.mean_squared_error(y_train, lr.predict(X_train)),5))\n",
    "print(\"Test MSE sin regularizacin:\", round(metrics.mean_squared_error(y_test, lr.predict(X_test)),5))\n",
    "\n",
    "print(\"Train MSE:\", round(metrics.mean_squared_error(y_train, ridgeR.predict(X_train)),5))\n",
    "print(\"Test MSE:\", round(metrics.mean_squared_error(y_test, ridgeR.predict(X_test)),5))\n",
    "print(\"Test RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, ridgeR.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Least Absolute Shrinkage and Selection Operator\n",
    "\n",
    "The following method goes further by selecting some variables to be removed from the Ridge regression, thus reducing the dimension.\n",
    "The method is called Least Absolute Shrinkage and Selection Operator (Lasso) and the resulting simplified model is a **sparse model** or parsimonious model.\n",
    "In the Lasso, the regularization term is defined by $Reg(\\beta) = ||\\beta||_1$.\n",
    "\n",
    "The Lasso performs a model's feature selection: for correlated variables, it retains only one variable and sets other correlated variables to zero.\n",
    "The counterpart is that it obviously induces a loss of information resulting in lower accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lassoR = Lasso(alpha=)\n",
    "lassoR.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train MSE sin regularizacin:\", round(metrics.mean_squared_error(y_train, lr.predict(X_train)),4))\n",
    "print(\"Test MSE sin regularizacin:\", round(metrics.mean_squared_error(y_test, lr.predict(X_test)),4))\n",
    "\n",
    "print(\"Train MSE: %0.4f\" % metrics.mean_squared_error(y_train, lassoR.predict(X_train)))\n",
    "print(\"Test MSE: %0.4f\" % metrics.mean_squared_error(y_test, lassoR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Elastic net\n",
    "\n",
    "The Elastic Net method is a hybrid of the Ridge regression and the Lasso, thus overcomes the issue of losing information.\n",
    "The regularization term combines both the $L_1$ and the $L_2$ regularizations.\n",
    "More precisely, the regularisation term is set to $Reg(\\beta) = \\lambda((1-\\alpha)||\\beta||_1+\\alpha||\\beta||_2^2)$ where $\\alpha$ is an additional parameter to fit.\n",
    "\n",
    "The Elastic net has a selecting effect on variables as Lasso but keep correlated variables as Ridge regression.\n",
    "Thus the Elastic net model is less sparse than the Lasso, keeping more information. \n",
    "However the model is more demanding in computational resources.\n",
    "\n",
    "In what follows we present results for $\\alpha=0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha = , l1_ratio = )\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train MSE: %0.4f\" % metrics.mean_squared_error(y_train, elastic_net.predict(X_train)))\n",
    "print(\"Test MSE: %0.4f\" % metrics.mean_squared_error(y_test, elastic_net.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "# Model selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Lasso performs better than others methods (Elastic net: $\\alpha=0.5$). \n",
    "* The Lasso is more parsimonious but there is likely to be a loss of accuracy.\n",
    "* The Elastic net performs better than the Ridge regression (with $\\alpha=0.5$).\n",
    "* The Elastic net can be tuned to outperform Lasso but it is more demanding in computational resources.\n",
    "\n",
    "**=> The Elastic net is a good trade-off for accuracy and computational cost balance between the Ridge regression and the Lasso**.\n",
    "\n",
    "\n",
    "In order to optimize the model by fitting the optimal parameters, a cross validation can be performed.\n",
    "The functions sklearn.linear_model.RidgeCV, sklearn.linear_model.LassoCV and sklearn.linear_model.ElasticNetCV in Python perform an automatic tunning of hyperparameters for the Rigde regression, the Lasso and the Elastic Net respectively."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c77fdb427e7cbc9bc1367dd530fc2b36aacdbbde1ac83c85833b10dfa8b831c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPor defecto, keras no tira de GPU\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install tensorflow\n",
    "# !pip install keras (NO NECESARIO YA INTEGRADO EN TENSORFLOW)\n",
    "'''\n",
    "Por defecto, keras no tira de GPU\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar y abrir VS Code si hace falta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[25000,12,18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays). Aplano a una dimension cada imagen.\n",
    "# Escalamos ya que vamos a usar gradient descent, y le afecta mucho la escala de las features.\n",
    "# Ejecutar esta celda solo una vez. Sino reescalará\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Reserve 10,000 samples for validation. Entraran dentro del modelo para validar. No es validacion cruzada\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINICION/CONSTRUCCION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax.  \n",
    "\n",
    "Es decir vamos a volver a montar esta arquitectura:  \n",
    "<img src=\"./img/mlp_clasification.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Un poco más sobre la activación softmax:    \n",
    "\n",
    "Fórmula:  \n",
    "<img src=\"./img/softmax_function.png\" alt=\"drawing\" width=\"150\"/>\n",
    "\n",
    "Función de transferencia:  \n",
    "<img src=\"./img/softmax_activation.png\" alt=\"drawing\" width=\"150\"/>\n",
    "\n",
    "Ejemplo de funcionamiento:  \n",
    "<img src=\"./img/softmax_example.png\" alt=\"drawing\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonatan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Una manera de declarar la red neuronal\n",
    "\n",
    "# Siempre hay que declarar la capa sequential para empezar a declarar la red\n",
    "# Se trata de la API sequential\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten, aplana en un unico vector. Y especificamos el tamaño de la entrada\n",
    "# Es como si hiciese un .reshape(-1, 28*28)\n",
    "# \"kernel_initializer\" o \"bias_initializer\" No lo usamos pero seria para inicializar los pesos de otra manera\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Capas de la red. Dense es la capa de neuronas. Necesitamos numero y activacion\n",
    "model.add(keras.layers.Dense(units = 300, # Numero de neuronas de la capa\n",
    "                             activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(100,\n",
    "                             activation='relu'))\n",
    "\n",
    "# Capa de salida, con tamaño del número de clases\n",
    "# Suele ir aqui un softmax. Para multiclase guay. Si es binaria -> sigmoide\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "]\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y una forma mediante encademaniento de funciones (usando lo que se denomina la Functional API)\n",
    "input_layer = keras.layers.Input(shape = (28,28))\n",
    "flatten_layer = keras.layers.Flatten()(input_layer)\n",
    "hidden_1 = keras.layers.Dense(300, activation = \"relu\")(flatten_layer)\n",
    "hidden_2 = keras.layers.Dense(100, activation = \"relu\")(hidden_1)\n",
    "output = keras.layers.Dense(10, activation = \"softmax\")(hidden_2)\n",
    "model = keras.Model(inputs = [input_layer], outputs = [output])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La functional API me va a permitir construir redes como estas:\n",
    "\n",
    "<img src=\"./img/otras_arquitecturas.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_2, built=True>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=input_layer_2, built=True>,\n",
       " <Flatten name=flatten_2, built=True>,\n",
       " <Dense name=dense_6, built=True>,\n",
       " <Dense name=dense_7, built=True>,\n",
       " <Dense name=dense_8, built=True>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[2]\n",
    "weights, biases = hidden1.get_weights()\n",
    "\n",
    "# 784 features (pixeles de las imagenes) x 300 neuronas\n",
    "# Los pesos están inicializados aleatoriamente\n",
    "weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicializadores:  \n",
    "- Los pesos inicializados a cero -> No aprendizaje\n",
    "- Desde siempre se inicializan \"aleatoriamente\", pero no sólo de forma uniforme (todos los valores con la misma probabilidad), sino que se emplean diferentes distribuciones de probabilidad con parámetros que dependen del número de entradas y salidas de la capa. El objetivo esintentar que las varianzas de las entradas sean similares a las de las salidas y evitar el problema del gradiente que se desvanece (\"Vanishing Gradient\" problem):  \n",
    "    *   Glorot inizialization (por defecto la de Keras, con función uniforme de distribución) -> Para cuando tienes funciones de activación (ninguna, tanh, sigmoid, softmax, aunque también se usa por defecto :-) para casi todo) [Xavier Glorot & Yoshua Bengio]\n",
    "    *   He inizialization, -> Para cuando tienes ReLU, Leaky ReLU, ELU, GELU, Swish, Mish [He Kaiming et al.]\n",
    "    *   LeCunn inizialization -> Para cuando tienes SELU [Jean LeCunn]\n",
    "- Es un hiperparámetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "model.compile(\n",
    "    # Stocastic gradient descent. El algoritmo para minimizar la loss function\n",
    "    # El stocastic va haciendo muestreo en cada evaluacion, no usa todo el dataset\n",
    "    # Podemos modificar el learning rate(0.01 por defecto) mediante el parametro lr\n",
    "    optimizer=keras.optimizers.SGD(),  # Optimizer, con parámetros por defecto\n",
    "    \n",
    "    \n",
    "    # Loss function to minimize\n",
    "    # sparse_categorical_crossentropy cuando tenemos un label en nuna columna\n",
    "    # Si lo tuviesemos en varias tipo dummy, cogeriamos categorical_crossentropy\n",
    "    # binary_crossentropy si es una neurona, clasi binario\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente (... casi, los parámetros del optimizador serán los que tenga por defecto)\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "# La primera hidden layer tiene 784 entradas x 300 salidas\n",
    "# Son los 235500 params = 783x300 + 300 (bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAPAS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vayamos construyendo nuestra __lista de capas__ (para guardar en el \"Toolbox\"):\n",
    "\n",
    "__Entrenables__:  \n",
    "__* Dense__ -> Capa completamente conectada a las neuronas de la capa anterior y a la posterior  \n",
    "    Hiperparámetros asociados:     \n",
    "        * units: Number of neurons, dimensionality of the output space  \n",
    "        * activation: Activation function to use. If you don't specify anything, no activation is applied  \n",
    "        * kernel_initializer: Initializer for the kernel weights matrix.  \n",
    "        * bias_initializer: Initializer for the bias vector. (Suelen inicializarse a cero)\n",
    "        * Kernel_regularizar: Los clásicos (L1,L2,...)\n",
    " \n",
    "__Funcionales__:       \n",
    "__* Input__ -> Capa para definir la forma de la entrada (shape), que se puede pasar como input_shape\n",
    "__* Flatten__ -> Capa que aplana (convierte su entrada en un vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras funciones de activación interesantes: SELU (1.67*ELU) y Swish (también SiLU, o Sigmoid linear unit)... No entrar en pánico, vais a usar ReLU, Softmax y no-activation, y en algunos casos (quizás): sigmoid, tanh y las (x)LU (SELU, Siwsh,etc)\n",
    "\n",
    "<img src=\"./img/activation_functions.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIMIZADORES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también vamos completando lista de hiperparámetros, estos asociados al \"Optimizador\"/\"Modelo\":  \n",
    "Tipo de optimizador:  \n",
    "* __SGD__, Gradient descent \"genérico\" (puedes añadirle \"momento\", es decir que a la hora de descontar el gradiente tenga en cuenta el vector medio de gradientes pasados)\n",
    "  \n",
    "\n",
    "* __Adagrad__, Hace gradient descent pero ajusta el gradiente para compensar las componentes de mayor valor numérico (es como evitar irse por las pendientes más inclinadas)... Es decir evita irse a mínimos locales al precio de enlentecer el entrenamiento.    \n",
    "\n",
    "* __RMSprop__, Versión de AdaGrad, pero considera principalmente los últimos valores del gradiente. Es decir, busca lo bueno de Adagrad reduciendo sus peligros.    \n",
    "\n",
    "* __Adam__, _Adaptative Moment Estimation_, combina RMSProp y el uso de momento. Es el rey actual (junto con sus versiones) para grandes cantidades de datos.    \n",
    "\n",
    "* __AdamW, Nadam, AdaMax__, variantes del anterior. \n",
    "\n",
    "Comparativa, donde * es malo y *** bueno (extraído del \"Hands-on Machine Learning with....\" de Aurelien Geron, 3a Edicion)\n",
    "\n",
    "<img src=\"./img/Comparativa-optimizadores.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "Keras también permite:\n",
    "__Adadelta__ _(variante de Adagrad)_, __Adafactor__ y __Ftrl__\n",
    "\n",
    "      \n",
    "Hiperparámetros Genéricos:\n",
    "Learning Rate: Coeficiente aplicado al descenso de gradiente, como en otros modelos que ya hemos visto\n",
    "Asociados al Gradient Clipping: clipnorm, clipvalue, global_clipnorm\n",
    "\n",
    "Cada optimizador además puede tener sus propios hiperparámetros (ver: https://keras.io/api/optimizers/)\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuciones de pérdida y métricas\n",
    "__Función de perdida__: La función a minimizar durante el entrenamiento (son las mismas que en otros modelos no Deep)  \n",
    "- Clasificación: En clases Keras -> __BinaryCrossEntropy, CategoricalCrossEntropy, SparseCategoricalCrossEntropy__  \n",
    "- Regresión: En clases Keras -> __MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, CosineSimilarity__   \n",
    "\n",
    "__Métricas__:  \n",
    "- Regresión: __MAE, MSE, MAPE__ :-)  \n",
    "- Clasificación: __Accuracy, Precision, Recall, f1, AuRoC__  \n",
    "\n",
    "¿Cuál es la diferencia entre Categorical y Sparse? ¿Por qué las funciones de pérdida son diferentes a las métricas en Clasificación? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El __batch_size__ es la cantidad de muestras que utiliza el SGD, y las __epochs__ son las iteraciones que realiza en el entrenamiento. (Son hiperparámetros de entrenamiento)    \n",
    "\n",
    "En una epoch se entrenan tantos batches como sea necesario para recorrer todo el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6284 - loss: 1.3910 - val_accuracy: 0.8977 - val_loss: 0.3984\n",
      "Epoch 2/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.4036 - val_accuracy: 0.9115 - val_loss: 0.3145\n",
      "Epoch 3/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.3219 - val_accuracy: 0.9250 - val_loss: 0.2721\n",
      "Epoch 4/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2858 - val_accuracy: 0.9317 - val_loss: 0.2534\n",
      "Epoch 5/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2626 - val_accuracy: 0.9360 - val_loss: 0.2318\n",
      "Epoch 6/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.2374 - val_accuracy: 0.9382 - val_loss: 0.2154\n",
      "Epoch 7/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.2208 - val_accuracy: 0.9451 - val_loss: 0.2014\n",
      "Epoch 8/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2050 - val_accuracy: 0.9473 - val_loss: 0.1899\n",
      "Epoch 9/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.1917 - val_accuracy: 0.9518 - val_loss: 0.1787\n",
      "Epoch 10/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1772 - val_accuracy: 0.9540 - val_loss: 0.1680\n",
      "Epoch 11/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1659 - val_accuracy: 0.9561 - val_loss: 0.1607\n",
      "Epoch 12/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.1553 - val_accuracy: 0.9574 - val_loss: 0.1536\n",
      "Epoch 13/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9578 - loss: 0.1485 - val_accuracy: 0.9598 - val_loss: 0.1482\n",
      "Epoch 14/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1396 - val_accuracy: 0.9615 - val_loss: 0.1437\n",
      "Epoch 15/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1328 - val_accuracy: 0.9632 - val_loss: 0.1362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEn el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\\nSi vemos que ya no baja mas, no serán necesarias tantas epochs.\\nImprimera tantas lineas como epochs hayamos puesto\\n\\nTampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\\nUtil para datasets desbalanceados.\\n\\nEl loss que muestra es el categoricalcrossentropy\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64, # numero de muestras empleadas en el entrenamiento de SGD\n",
    "    epochs=15, # 1 por defecto. Insuficiente. Numero de vueltas del backpropagation\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # En vez de validation data podemos usar el argumento validation_split=0.1\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1255 - val_accuracy: 0.9647 - val_loss: 0.1340\n",
      "Epoch 2/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1223 - val_accuracy: 0.9640 - val_loss: 0.1301\n",
      "Epoch 3/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1167 - val_accuracy: 0.9656 - val_loss: 0.1265\n",
      "Epoch 4/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.1084 - val_accuracy: 0.9654 - val_loss: 0.1254\n",
      "Epoch 5/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.1069 - val_accuracy: 0.9663 - val_loss: 0.1217\n",
      "Epoch 6/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1017 - val_accuracy: 0.9688 - val_loss: 0.1144\n",
      "Epoch 7/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0940 - val_accuracy: 0.9688 - val_loss: 0.1129\n",
      "Epoch 8/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0914 - val_accuracy: 0.9707 - val_loss: 0.1112\n",
      "Epoch 9/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9751 - loss: 0.0895 - val_accuracy: 0.9699 - val_loss: 0.1094\n",
      "Epoch 10/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0870 - val_accuracy: 0.9717 - val_loss: 0.1062\n",
      "Epoch 11/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0816 - val_accuracy: 0.9721 - val_loss: 0.1040\n",
      "Epoch 12/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0766 - val_accuracy: 0.9718 - val_loss: 0.1020\n",
      "Epoch 13/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0734 - val_accuracy: 0.9728 - val_loss: 0.1028\n",
      "Epoch 14/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.0749 - val_accuracy: 0.9731 - val_loss: 0.0992\n",
      "Epoch 15/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0712 - val_accuracy: 0.9730 - val_loss: 0.0979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a322012c30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 'auto', 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7811800241470337,\n",
       "  0.8955000042915344,\n",
       "  0.9107000231742859,\n",
       "  0.9201800227165222,\n",
       "  0.9287800192832947,\n",
       "  0.9335799813270569,\n",
       "  0.9381999969482422,\n",
       "  0.9423800110816956,\n",
       "  0.9466999769210815,\n",
       "  0.950219988822937,\n",
       "  0.9532600045204163,\n",
       "  0.9552800059318542,\n",
       "  0.9582800269126892,\n",
       "  0.9605600237846375,\n",
       "  0.9623000025749207],\n",
       " 'loss': [0.8926215767860413,\n",
       "  0.3771762251853943,\n",
       "  0.3133458197116852,\n",
       "  0.2794243097305298,\n",
       "  0.2546207308769226,\n",
       "  0.23450949788093567,\n",
       "  0.21713079512119293,\n",
       "  0.20182326436042786,\n",
       "  0.1883915662765503,\n",
       "  0.17627263069152832,\n",
       "  0.16541695594787598,\n",
       "  0.1557200849056244,\n",
       "  0.14718849956989288,\n",
       "  0.13919012248516083,\n",
       "  0.1321486085653305],\n",
       " 'val_accuracy': [0.8977000117301941,\n",
       "  0.9114999771118164,\n",
       "  0.925000011920929,\n",
       "  0.9316999912261963,\n",
       "  0.9359999895095825,\n",
       "  0.9381999969482422,\n",
       "  0.9451000094413757,\n",
       "  0.9473000168800354,\n",
       "  0.9517999887466431,\n",
       "  0.9539999961853027,\n",
       "  0.9560999870300293,\n",
       "  0.9574000239372253,\n",
       "  0.9598000049591064,\n",
       "  0.9614999890327454,\n",
       "  0.9631999731063843],\n",
       " 'val_loss': [0.398357629776001,\n",
       "  0.314452588558197,\n",
       "  0.2721129357814789,\n",
       "  0.2533722519874573,\n",
       "  0.2317543774843216,\n",
       "  0.21537087857723236,\n",
       "  0.2014458328485489,\n",
       "  0.1898953914642334,\n",
       "  0.1786670833826065,\n",
       "  0.1680469512939453,\n",
       "  0.1607140302658081,\n",
       "  0.1536007672548294,\n",
       "  0.148244246840477,\n",
       "  0.1437073051929474,\n",
       "  0.13623099029064178]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Podemos ver como evoluciona el entrenamiento, en funcion de los epochs\n",
    "# Validacion y training estan muy cerca, no hay overfitting!\n",
    "# Todavia no ha acabado de coverger ya que el loss en validacion sigue bajando,\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.1079\n",
      "test loss, test acc: [0.09238413721323013, 0.9717000126838684]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "\n",
    "# Metodo evaluate para que nos de el error vs las metricas elegidas en la funcion compile\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonatan\\AppData\\Local\\Temp\\ipykernel_13840\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "predictions shape: (1, 10)\n",
      "[0.    0.    0.001 0.002 0.    0.    0.    0.997 0.    0.   ]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Ojo aqui viene slicing xq presupone que le entran varios inputs\n",
    "Nos da las probabilidades de pertenecer a una clase u otra.\n",
    "'''\n",
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions[0])\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona.\n",
    "     \n",
    "Vamos a configurar una red como esta:  \n",
    "<img src=\"./img/mlp_regresion.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonatan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 1.1565 - loss: 1.4503 - val_RootMeanSquaredError: 0.8524 - val_loss: 0.7266\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - RootMeanSquaredError: 0.7633 - loss: 0.5835 - val_RootMeanSquaredError: 0.8759 - val_loss: 0.7671\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - RootMeanSquaredError: 0.7594 - loss: 0.5772 - val_RootMeanSquaredError: 1.1234 - val_loss: 1.2620\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - RootMeanSquaredError: 0.7750 - loss: 0.6084 - val_RootMeanSquaredError: 1.0108 - val_loss: 1.0217\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - RootMeanSquaredError: 1.1168 - loss: 1.3241 - val_RootMeanSquaredError: 0.6749 - val_loss: 0.4555\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - RootMeanSquaredError: 0.6808 - loss: 0.4637 - val_RootMeanSquaredError: 0.6805 - val_loss: 0.4631\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - RootMeanSquaredError: 0.6700 - loss: 0.4495 - val_RootMeanSquaredError: 0.6513 - val_loss: 0.4242\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - RootMeanSquaredError: 0.6442 - loss: 0.4152 - val_RootMeanSquaredError: 0.6433 - val_loss: 0.4139\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - RootMeanSquaredError: 0.6394 - loss: 0.4092 - val_RootMeanSquaredError: 0.6404 - val_loss: 0.4101\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - RootMeanSquaredError: 0.6170 - loss: 0.3811 - val_RootMeanSquaredError: 0.6463 - val_loss: 0.4177\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - RootMeanSquaredError: 0.6172 - loss: 0.3816 - val_RootMeanSquaredError: 0.6359 - val_loss: 0.4044\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - RootMeanSquaredError: 0.6210 - loss: 0.3859 - val_RootMeanSquaredError: 0.6574 - val_loss: 0.4322\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - RootMeanSquaredError: 0.6303 - loss: 0.3975 - val_RootMeanSquaredError: 0.6303 - val_loss: 0.3973\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - RootMeanSquaredError: 0.6011 - loss: 0.3617 - val_RootMeanSquaredError: 0.6436 - val_loss: 0.4143\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - RootMeanSquaredError: 0.6126 - loss: 0.3754 - val_RootMeanSquaredError: 0.6271 - val_loss: 0.3933\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - RootMeanSquaredError: 0.6151 - loss: 0.3786 - val_RootMeanSquaredError: 0.6240 - val_loss: 0.3894\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - RootMeanSquaredError: 0.6025 - loss: 0.3632 - val_RootMeanSquaredError: 0.6226 - val_loss: 0.3876\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - RootMeanSquaredError: 0.6028 - loss: 0.3638 - val_RootMeanSquaredError: 0.6217 - val_loss: 0.3865\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - RootMeanSquaredError: 0.6010 - loss: 0.3614 - val_RootMeanSquaredError: 0.6237 - val_loss: 0.3890\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - RootMeanSquaredError: 0.6033 - loss: 0.3644 - val_RootMeanSquaredError: 0.6164 - val_loss: 0.3799\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - RootMeanSquaredError: 0.6187 - loss: 0.3832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    keras.layers.Dense(30, activation=\"relu\",\n",
    "                       input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "    # Sin fun de activa. ReLu no iria mal si el output es positivo. Sigmoide si esta acotado.\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics = [\"RootMeanSquaredError\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: [0.3755013048648834, 0.6127815842628479]\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE:\",mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonatan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.8443 - RootMeanSquaredError: 1.2785 - loss: 1.7080 - val_MeanAbsoluteError: 0.5000 - val_RootMeanSquaredError: 0.7518 - val_loss: 0.5651\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - MeanAbsoluteError: 0.5334 - RootMeanSquaredError: 0.8768 - loss: 0.7794 - val_MeanAbsoluteError: 0.5053 - val_RootMeanSquaredError: 0.6837 - val_loss: 0.4674\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - MeanAbsoluteError: 0.5026 - RootMeanSquaredError: 0.6891 - loss: 0.4749 - val_MeanAbsoluteError: 0.4843 - val_RootMeanSquaredError: 0.6668 - val_loss: 0.4446\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - MeanAbsoluteError: 0.4868 - RootMeanSquaredError: 0.6701 - loss: 0.4495 - val_MeanAbsoluteError: 0.4707 - val_RootMeanSquaredError: 0.6531 - val_loss: 0.4266\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - MeanAbsoluteError: 0.4698 - RootMeanSquaredError: 0.6546 - loss: 0.4287 - val_MeanAbsoluteError: 0.4693 - val_RootMeanSquaredError: 0.6404 - val_loss: 0.4101\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - MeanAbsoluteError: 0.4557 - RootMeanSquaredError: 0.6346 - loss: 0.4029 - val_MeanAbsoluteError: 0.4500 - val_RootMeanSquaredError: 0.6311 - val_loss: 0.3982\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - MeanAbsoluteError: 0.4663 - RootMeanSquaredError: 0.6533 - loss: 0.4276 - val_MeanAbsoluteError: 0.4449 - val_RootMeanSquaredError: 0.6235 - val_loss: 0.3888\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - MeanAbsoluteError: 0.4454 - RootMeanSquaredError: 0.6247 - loss: 0.3903 - val_MeanAbsoluteError: 0.4462 - val_RootMeanSquaredError: 0.6200 - val_loss: 0.3844\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - MeanAbsoluteError: 0.4456 - RootMeanSquaredError: 0.6239 - loss: 0.3893 - val_MeanAbsoluteError: 0.4325 - val_RootMeanSquaredError: 0.6170 - val_loss: 0.3807\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - MeanAbsoluteError: 0.4445 - RootMeanSquaredError: 0.6257 - loss: 0.3916 - val_MeanAbsoluteError: 0.4351 - val_RootMeanSquaredError: 0.6087 - val_loss: 0.3706\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - MeanAbsoluteError: 0.4412 - RootMeanSquaredError: 0.6193 - loss: 0.3837 - val_MeanAbsoluteError: 0.4352 - val_RootMeanSquaredError: 0.6074 - val_loss: 0.3689\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - MeanAbsoluteError: 0.4327 - RootMeanSquaredError: 0.6054 - loss: 0.3668 - val_MeanAbsoluteError: 0.4302 - val_RootMeanSquaredError: 0.6061 - val_loss: 0.3673\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - MeanAbsoluteError: 0.4301 - RootMeanSquaredError: 0.6114 - loss: 0.3739 - val_MeanAbsoluteError: 0.4351 - val_RootMeanSquaredError: 0.6088 - val_loss: 0.3707\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - MeanAbsoluteError: 0.4375 - RootMeanSquaredError: 0.6123 - loss: 0.3750 - val_MeanAbsoluteError: 0.4343 - val_RootMeanSquaredError: 0.6088 - val_loss: 0.3706\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - MeanAbsoluteError: 0.4384 - RootMeanSquaredError: 0.6213 - loss: 0.3863 - val_MeanAbsoluteError: 0.4289 - val_RootMeanSquaredError: 0.6020 - val_loss: 0.3625\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - MeanAbsoluteError: 0.4326 - RootMeanSquaredError: 0.6068 - loss: 0.3683 - val_MeanAbsoluteError: 0.4231 - val_RootMeanSquaredError: 0.5991 - val_loss: 0.3589\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - MeanAbsoluteError: 0.4252 - RootMeanSquaredError: 0.5989 - loss: 0.3587 - val_MeanAbsoluteError: 0.4164 - val_RootMeanSquaredError: 0.5991 - val_loss: 0.3589\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - MeanAbsoluteError: 0.4253 - RootMeanSquaredError: 0.6037 - loss: 0.3646 - val_MeanAbsoluteError: 0.4193 - val_RootMeanSquaredError: 0.5977 - val_loss: 0.3573\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - MeanAbsoluteError: 0.4372 - RootMeanSquaredError: 0.6186 - loss: 0.3830 - val_MeanAbsoluteError: 0.4259 - val_RootMeanSquaredError: 0.5977 - val_loss: 0.3572\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - MeanAbsoluteError: 0.4199 - RootMeanSquaredError: 0.5905 - loss: 0.3487 - val_MeanAbsoluteError: 0.4209 - val_RootMeanSquaredError: 0.5956 - val_loss: 0.3547\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - MeanAbsoluteError: 0.4127 - RootMeanSquaredError: 0.5873 - loss: 0.3452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "#Otra forma pure-Keras:\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "\n",
    "norm_layer = keras.layers.Normalization(input_shape = X_train.shape[1:]) # Es una Standardization\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    norm_layer,\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "    # Sin fun de activa. ReLu no iria mal si el output es positivo. Sigmoide si esta acotado.\n",
    "])\n",
    "optimizer = keras.optimizers.SGD()\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=optimizer, metrics = [\"RootMeanSquaredError\",\"MeanAbsoluteError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: [0.34420809149742126, 0.5866925120353699, 0.4141022562980652]\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE:\",mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nueva capa al toolbox:\n",
    "\n",
    "Funcionales:  \n",
    "__Normalize__: keras.layers.Normalization -> Nos hace la standardizacion de la entrada \n",
    "Hay que ejecutar el metodo Adapt antes de llamar al fit del modelo que incluya la capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma es emplear el formato TensorFlow. En este caso crea un directorio con varios ficheros que facilita el despliegue en algunas aplicaciones (ojo, que habría que llevar a producción todo el directorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model_otro.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model_k= keras.models.load_model(\"my_keras_model_otro.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.3614 - mean_absolute_error: 0.4241 - root_mean_squared_error: 0.6010\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.3522 - mean_absolute_error: 0.4203 - root_mean_squared_error: 0.5933\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.3498 - mean_absolute_error: 0.4210 - root_mean_squared_error: 0.5914\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.3508 - mean_absolute_error: 0.4176 - root_mean_squared_error: 0.5923\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - loss: 0.3522 - mean_absolute_error: 0.4181 - root_mean_squared_error: 0.5933\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 0.3498 - mean_absolute_error: 0.4168 - root_mean_squared_error: 0.5912\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.3504 - mean_absolute_error: 0.4136 - root_mean_squared_error: 0.5916\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.3549 - mean_absolute_error: 0.4184 - root_mean_squared_error: 0.5957\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - loss: 0.3415 - mean_absolute_error: 0.4150 - root_mean_squared_error: 0.5843\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 0.3378 - mean_absolute_error: 0.4114 - root_mean_squared_error: 0.5810\n",
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3504 - mean_absolute_error: 0.4173 - root_mean_squared_error: 0.5919 - val_loss: 0.3426 - val_mean_absolute_error: 0.4144 - val_root_mean_squared_error: 0.5853\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - loss: 0.3425 - mean_absolute_error: 0.4120 - root_mean_squared_error: 0.5851 - val_loss: 0.3420 - val_mean_absolute_error: 0.4137 - val_root_mean_squared_error: 0.5848\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.3510 - mean_absolute_error: 0.4196 - root_mean_squared_error: 0.5923 - val_loss: 0.3505 - val_mean_absolute_error: 0.4189 - val_root_mean_squared_error: 0.5921\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3529 - mean_absolute_error: 0.4157 - root_mean_squared_error: 0.5938 - val_loss: 0.3380 - val_mean_absolute_error: 0.4112 - val_root_mean_squared_error: 0.5814\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.3361 - mean_absolute_error: 0.4085 - root_mean_squared_error: 0.5794 - val_loss: 0.3390 - val_mean_absolute_error: 0.4097 - val_root_mean_squared_error: 0.5822\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3467 - mean_absolute_error: 0.4143 - root_mean_squared_error: 0.5886 - val_loss: 0.3376 - val_mean_absolute_error: 0.4083 - val_root_mean_squared_error: 0.5810\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3379 - mean_absolute_error: 0.4098 - root_mean_squared_error: 0.5809 - val_loss: 0.3353 - val_mean_absolute_error: 0.4096 - val_root_mean_squared_error: 0.5790\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.3235 - mean_absolute_error: 0.3999 - root_mean_squared_error: 0.5684 - val_loss: 0.3331 - val_mean_absolute_error: 0.4007 - val_root_mean_squared_error: 0.5771\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 0.3454 - mean_absolute_error: 0.4118 - root_mean_squared_error: 0.5873 - val_loss: 0.3676 - val_mean_absolute_error: 0.4257 - val_root_mean_squared_error: 0.6063\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.3639 - mean_absolute_error: 0.4195 - root_mean_squared_error: 0.6025 - val_loss: 0.3422 - val_mean_absolute_error: 0.4121 - val_root_mean_squared_error: 0.5849\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3430 - mean_absolute_error: 0.4127 - root_mean_squared_error: 0.5856 - val_loss: 0.3324 - val_mean_absolute_error: 0.4041 - val_root_mean_squared_error: 0.5765\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.3351 - mean_absolute_error: 0.4115 - root_mean_squared_error: 0.5788 - val_loss: 0.3442 - val_mean_absolute_error: 0.4179 - val_root_mean_squared_error: 0.5867\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.3526 - mean_absolute_error: 0.4174 - root_mean_squared_error: 0.5937 - val_loss: 0.3398 - val_mean_absolute_error: 0.4075 - val_root_mean_squared_error: 0.5829\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3407 - mean_absolute_error: 0.4104 - root_mean_squared_error: 0.5835 - val_loss: 0.3353 - val_mean_absolute_error: 0.4019 - val_root_mean_squared_error: 0.5790\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.3446 - mean_absolute_error: 0.4117 - root_mean_squared_error: 0.5870 - val_loss: 0.3335 - val_mean_absolute_error: 0.4075 - val_root_mean_squared_error: 0.5775\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3309 - mean_absolute_error: 0.4081 - root_mean_squared_error: 0.5752 - val_loss: 0.3312 - val_mean_absolute_error: 0.4019 - val_root_mean_squared_error: 0.5755\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3411 - mean_absolute_error: 0.4083 - root_mean_squared_error: 0.5839 - val_loss: 0.3304 - val_mean_absolute_error: 0.4014 - val_root_mean_squared_error: 0.5748\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3392 - mean_absolute_error: 0.4105 - root_mean_squared_error: 0.5823 - val_loss: 0.3325 - val_mean_absolute_error: 0.4056 - val_root_mean_squared_error: 0.5766\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3296 - mean_absolute_error: 0.4054 - root_mean_squared_error: 0.5739 - val_loss: 0.3298 - val_mean_absolute_error: 0.3964 - val_root_mean_squared_error: 0.5743\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3299 - mean_absolute_error: 0.4035 - root_mean_squared_error: 0.5742 - val_loss: 0.3378 - val_mean_absolute_error: 0.4098 - val_root_mean_squared_error: 0.5812\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.3470 - mean_absolute_error: 0.4160 - root_mean_squared_error: 0.5884 - val_loss: 0.3395 - val_mean_absolute_error: 0.3963 - val_root_mean_squared_error: 0.5827\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3322 - mean_absolute_error: 0.4038 - root_mean_squared_error: 0.5763 - val_loss: 0.3293 - val_mean_absolute_error: 0.4009 - val_root_mean_squared_error: 0.5739\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3434 - mean_absolute_error: 0.4107 - root_mean_squared_error: 0.5858 - val_loss: 0.3271 - val_mean_absolute_error: 0.4043 - val_root_mean_squared_error: 0.5720\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3419 - mean_absolute_error: 0.4102 - root_mean_squared_error: 0.5846 - val_loss: 0.3260 - val_mean_absolute_error: 0.3996 - val_root_mean_squared_error: 0.5709\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3277 - mean_absolute_error: 0.4044 - root_mean_squared_error: 0.5723 - val_loss: 0.3247 - val_mean_absolute_error: 0.3954 - val_root_mean_squared_error: 0.5698\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3265 - mean_absolute_error: 0.4042 - root_mean_squared_error: 0.5710 - val_loss: 0.3291 - val_mean_absolute_error: 0.4048 - val_root_mean_squared_error: 0.5737\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - loss: 0.3379 - mean_absolute_error: 0.4056 - root_mean_squared_error: 0.5809 - val_loss: 0.3261 - val_mean_absolute_error: 0.3964 - val_root_mean_squared_error: 0.5710\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3375 - mean_absolute_error: 0.4083 - root_mean_squared_error: 0.5807 - val_loss: 0.3251 - val_mean_absolute_error: 0.3974 - val_root_mean_squared_error: 0.5702\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.3185 - mean_absolute_error: 0.3975 - root_mean_squared_error: 0.5642 - val_loss: 0.3405 - val_mean_absolute_error: 0.3967 - val_root_mean_squared_error: 0.5835\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3331 - mean_absolute_error: 0.4024 - root_mean_squared_error: 0.5767 - val_loss: 0.3470 - val_mean_absolute_error: 0.4206 - val_root_mean_squared_error: 0.5891\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "10 esta bien. Lo pondemos a 5 para el ejercicio\n",
    "¿Qué considera como dejar de mejorar? parametros min_delta y baseline\n",
    "'''\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, \n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros y tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guía \"casera\":\n",
    "\n",
    "1- Recetas (adaptada de \"Hands-on...\")  PARA MLPs!!!!    \n",
    "    * Capas:   \n",
    "        - Empezar con una capa oculta e ir añadiendo (dependiendo de la complejidad del problema, probar wide & deep)\n",
    "        - Si pocas features -> más neuronas  (aumentar la combinación de features) (num_features < 100) [Orientativo]  \n",
    "        - Si muchas features  -> menos neuronas (proyección tipo PCA) (num_features > 1000) [Orientativo] e ir aumentando en capas sucesivas\n",
    "        - O empezar con muchas (doble de tus features e ir \"estrechando los pantalones\")  \n",
    "        - Construcción en prisma o pirámide (para empezar)  \n",
    "        - Inicialización: Empezar con Glorot, cambiar a He  \n",
    "        - Activación: ReLU salvo la última, si muchas capas probar -> SELU o Swish (con el inicializador a LeCunn) \n",
    "    * Optimizadores:   \n",
    "        - Si muchos datos*features -> Adam o AdamW con sus valores por defecto  \n",
    "        - Si no, SGD con Nesterov activado, y momento a 0.9  \n",
    "        - Learning rate -> 0.001-0.0001 para empezar e ir creciendo (learning-rate warm-up) (Si te atreves, buscar adaptative learning rate y optimizar con esto)  \n",
    "    * Entrenamiento:  \n",
    "        - Epoch, probar con pocas para ver duración -> Epochs altas y Callback de Early Stop activado  \n",
    "        - Batch_Size -> 32, si tienes muchos datos y una GPU a mano puedes subir mucho 64,128,256...\n",
    "    * Regularización (lo veremos):  \n",
    "        - Dropout al 0.25-0.5 (sin SELU)\n",
    "\n",
    "\n",
    "\n",
    "2- Pasos  \n",
    "    - Si overfitting -> Regularizar: Earlystopping, Dropout (lo veremos en la siguiente sección)  \n",
    "    - Comprobar underfitting -> Aumentar epochs, aumentar batch_size  \n",
    "    - Jugar con optimizador: learning rate (de pequeño a grande), tipo de optimizador   \n",
    "    - Jugar con número de capas (ojo al overfitting) y las funciones de activación y la inicialización de pesos  \n",
    "    - Jugar con el número de neuronas por capa (suele ser piramide o prisma, pero puedes jugar a expandir dimensiones)  \n",
    "    - Combinar los dos anteriores  \n",
    "\n",
    "3- Keras Tuner:\n",
    "    https://keras.io/guides/keras_tuner/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herramientas adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3373 - mean_absolute_error: 0.4042 - root_mean_squared_error: 0.5804 - val_loss: 0.3287 - val_mean_absolute_error: 0.3969 - val_root_mean_squared_error: 0.5733\n",
      "Epoch 2/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3314 - mean_absolute_error: 0.4041 - root_mean_squared_error: 0.5756 - val_loss: 0.3285 - val_mean_absolute_error: 0.3986 - val_root_mean_squared_error: 0.5732\n",
      "Epoch 3/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3335 - mean_absolute_error: 0.4015 - root_mean_squared_error: 0.5772 - val_loss: 0.3254 - val_mean_absolute_error: 0.4004 - val_root_mean_squared_error: 0.5704\n",
      "Epoch 4/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3216 - mean_absolute_error: 0.4011 - root_mean_squared_error: 0.5667 - val_loss: 0.3332 - val_mean_absolute_error: 0.4070 - val_root_mean_squared_error: 0.5773\n",
      "Epoch 5/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3336 - mean_absolute_error: 0.4078 - root_mean_squared_error: 0.5775 - val_loss: 0.3253 - val_mean_absolute_error: 0.3996 - val_root_mean_squared_error: 0.5703\n",
      "Epoch 6/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3524 - mean_absolute_error: 0.4119 - root_mean_squared_error: 0.5933 - val_loss: 0.3299 - val_mean_absolute_error: 0.4034 - val_root_mean_squared_error: 0.5743\n",
      "Epoch 7/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3314 - mean_absolute_error: 0.4066 - root_mean_squared_error: 0.5755 - val_loss: 0.3319 - val_mean_absolute_error: 0.4070 - val_root_mean_squared_error: 0.5761\n",
      "Epoch 8/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3351 - mean_absolute_error: 0.4056 - root_mean_squared_error: 0.5782 - val_loss: 0.3248 - val_mean_absolute_error: 0.4019 - val_root_mean_squared_error: 0.5699\n",
      "Epoch 9/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3385 - mean_absolute_error: 0.4079 - root_mean_squared_error: 0.5816 - val_loss: 0.3278 - val_mean_absolute_error: 0.3978 - val_root_mean_squared_error: 0.5725\n",
      "Epoch 10/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3291 - mean_absolute_error: 0.4037 - root_mean_squared_error: 0.5735 - val_loss: 0.3268 - val_mean_absolute_error: 0.4019 - val_root_mean_squared_error: 0.5717\n",
      "Epoch 11/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3198 - mean_absolute_error: 0.3992 - root_mean_squared_error: 0.5654 - val_loss: 0.3272 - val_mean_absolute_error: 0.4039 - val_root_mean_squared_error: 0.5720\n",
      "Epoch 12/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3234 - mean_absolute_error: 0.4000 - root_mean_squared_error: 0.5686 - val_loss: 0.3308 - val_mean_absolute_error: 0.3983 - val_root_mean_squared_error: 0.5752\n",
      "Epoch 13/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3218 - mean_absolute_error: 0.3978 - root_mean_squared_error: 0.5672 - val_loss: 0.3237 - val_mean_absolute_error: 0.3963 - val_root_mean_squared_error: 0.5690\n",
      "Epoch 14/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3318 - mean_absolute_error: 0.4047 - root_mean_squared_error: 0.5757 - val_loss: 0.3242 - val_mean_absolute_error: 0.3961 - val_root_mean_squared_error: 0.5694\n",
      "Epoch 15/50\n",
      "\u001b[1m192/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3011 - mean_absolute_error: 0.3848 - root_mean_squared_error: 0.5484"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPara lanzarlo desde el jupyter notebook\\n%load_ext tensorboard\\n%tensorboard --logdir=./my_logs --port=6006\\n\\nPara lanzarlo desde el terminal, hay que estar en la carpeta de los logs\\ntensorboard --logdir=./my_logs --port=6006\\n\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BootCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "167a7833a0358ac30a26ad970c5914014f41a5348f3dc652232a762d6e3283fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

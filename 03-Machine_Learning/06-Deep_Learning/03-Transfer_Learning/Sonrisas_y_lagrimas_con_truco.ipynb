{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"train_set.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>paths</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>data\\train\\happy\\100.jpg</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>data\\train\\happy\\10000.jpg</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>data\\train\\happy\\10001.jpg</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>data\\train\\happy\\10005.jpg</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10035</td>\n",
       "      <td>data\\train\\happy\\10035.jpg</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12097</th>\n",
       "      <td>9966</td>\n",
       "      <td>data\\train\\sadness\\9966.jpg</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>9974</td>\n",
       "      <td>data\\train\\sadness\\9974.jpg</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12099</th>\n",
       "      <td>9976</td>\n",
       "      <td>data\\train\\sadness\\9976.jpg</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12100</th>\n",
       "      <td>9986</td>\n",
       "      <td>data\\train\\sadness\\9986.jpg</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12101</th>\n",
       "      <td>9997</td>\n",
       "      <td>data\\train\\sadness\\9997.jpg</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_img                        paths    label\n",
       "0         100     data\\train\\happy\\100.jpg    happy\n",
       "1       10000   data\\train\\happy\\10000.jpg    happy\n",
       "2       10001   data\\train\\happy\\10001.jpg    happy\n",
       "3       10005   data\\train\\happy\\10005.jpg    happy\n",
       "4       10035   data\\train\\happy\\10035.jpg    happy\n",
       "...       ...                          ...      ...\n",
       "12097    9966  data\\train\\sadness\\9966.jpg  sadness\n",
       "12098    9974  data\\train\\sadness\\9974.jpg  sadness\n",
       "12099    9976  data\\train\\sadness\\9976.jpg  sadness\n",
       "12100    9986  data\\train\\sadness\\9986.jpg  sadness\n",
       "12101    9997  data\\train\\sadness\\9997.jpg  sadness\n",
       "\n",
       "[12102 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['arrays'] = train_set['paths'].apply(lambda x: cv2.imread(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>paths</th>\n",
       "      <th>label</th>\n",
       "      <th>arrays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>data\\train\\happy\\100.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>[[[162, 162, 162], [163, 163, 163], [158, 158,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>data\\train\\happy\\10000.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>[[[134, 134, 134], [127, 127, 127], [134, 134,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>data\\train\\happy\\10001.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>[[[253, 253, 253], [253, 253, 253], [247, 247,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>data\\train\\happy\\10005.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>[[[183, 183, 183], [184, 184, 184], [183, 183,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10035</td>\n",
       "      <td>data\\train\\happy\\10035.jpg</td>\n",
       "      <td>happy</td>\n",
       "      <td>[[[249, 249, 249], [235, 235, 235], [46, 46, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12097</th>\n",
       "      <td>9966</td>\n",
       "      <td>data\\train\\sadness\\9966.jpg</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[[[97, 97, 97], [137, 137, 137], [161, 161, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>9974</td>\n",
       "      <td>data\\train\\sadness\\9974.jpg</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[[[60, 60, 60], [25, 25, 25], [27, 27, 27], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12099</th>\n",
       "      <td>9976</td>\n",
       "      <td>data\\train\\sadness\\9976.jpg</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[[[44, 44, 44], [44, 44, 44], [45, 45, 45], [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12100</th>\n",
       "      <td>9986</td>\n",
       "      <td>data\\train\\sadness\\9986.jpg</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[[[109, 109, 109], [23, 23, 23], [21, 21, 21],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12101</th>\n",
       "      <td>9997</td>\n",
       "      <td>data\\train\\sadness\\9997.jpg</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[[[92, 92, 92], [86, 86, 86], [87, 87, 87], [8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_img                        paths    label  \\\n",
       "0         100     data\\train\\happy\\100.jpg    happy   \n",
       "1       10000   data\\train\\happy\\10000.jpg    happy   \n",
       "2       10001   data\\train\\happy\\10001.jpg    happy   \n",
       "3       10005   data\\train\\happy\\10005.jpg    happy   \n",
       "4       10035   data\\train\\happy\\10035.jpg    happy   \n",
       "...       ...                          ...      ...   \n",
       "12097    9966  data\\train\\sadness\\9966.jpg  sadness   \n",
       "12098    9974  data\\train\\sadness\\9974.jpg  sadness   \n",
       "12099    9976  data\\train\\sadness\\9976.jpg  sadness   \n",
       "12100    9986  data\\train\\sadness\\9986.jpg  sadness   \n",
       "12101    9997  data\\train\\sadness\\9997.jpg  sadness   \n",
       "\n",
       "                                                  arrays  \n",
       "0      [[[162, 162, 162], [163, 163, 163], [158, 158,...  \n",
       "1      [[[134, 134, 134], [127, 127, 127], [134, 134,...  \n",
       "2      [[[253, 253, 253], [253, 253, 253], [247, 247,...  \n",
       "3      [[[183, 183, 183], [184, 184, 184], [183, 183,...  \n",
       "4      [[[249, 249, 249], [235, 235, 235], [46, 46, 4...  \n",
       "...                                                  ...  \n",
       "12097  [[[97, 97, 97], [137, 137, 137], [161, 161, 16...  \n",
       "12098  [[[60, 60, 60], [25, 25, 25], [27, 27, 27], [2...  \n",
       "12099  [[[44, 44, 44], [44, 44, 44], [45, 45, 45], [4...  \n",
       "12100  [[[109, 109, 109], [23, 23, 23], [21, 21, 21],...  \n",
       "12101  [[[92, 92, 92], [86, 86, 86], [87, 87, 87], [8...  \n",
       "\n",
       "[12102 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_img</th>\n",
       "      <th>paths</th>\n",
       "      <th>arrays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10019</td>\n",
       "      <td>data/test/10019.jpg</td>\n",
       "      <td>[[[159, 159, 159], [157, 157, 157], [158, 158,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10023</td>\n",
       "      <td>data/test/10023.jpg</td>\n",
       "      <td>[[[195, 195, 195], [198, 198, 198], [193, 193,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10074</td>\n",
       "      <td>data/test/10074.jpg</td>\n",
       "      <td>[[[105, 105, 105], [40, 40, 40], [45, 45, 45],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10096</td>\n",
       "      <td>data/test/10096.jpg</td>\n",
       "      <td>[[[255, 255, 255], [253, 253, 253], [253, 253,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10106</td>\n",
       "      <td>data/test/10106.jpg</td>\n",
       "      <td>[[[6, 6, 6], [4, 4, 4], [5, 5, 5], [7, 7, 7], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>9864</td>\n",
       "      <td>data/test/9864.jpg</td>\n",
       "      <td>[[[13, 13, 13], [12, 12, 12], [7, 7, 7], [7, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>987</td>\n",
       "      <td>data/test/987.jpg</td>\n",
       "      <td>[[[194, 194, 194], [199, 199, 199], [200, 200,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>9885</td>\n",
       "      <td>data/test/9885.jpg</td>\n",
       "      <td>[[[29, 29, 29], [23, 23, 23], [22, 22, 22], [1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>9889</td>\n",
       "      <td>data/test/9889.jpg</td>\n",
       "      <td>[[[246, 246, 246], [245, 245, 245], [247, 247,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>9923</td>\n",
       "      <td>data/test/9923.jpg</td>\n",
       "      <td>[[[13, 13, 13], [10, 10, 10], [8, 8, 8], [4, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_img                paths  \\\n",
       "0      10019  data/test/10019.jpg   \n",
       "1      10023  data/test/10023.jpg   \n",
       "2      10074  data/test/10074.jpg   \n",
       "3      10096  data/test/10096.jpg   \n",
       "4      10106  data/test/10106.jpg   \n",
       "...      ...                  ...   \n",
       "2959    9864   data/test/9864.jpg   \n",
       "2960     987    data/test/987.jpg   \n",
       "2961    9885   data/test/9885.jpg   \n",
       "2962    9889   data/test/9889.jpg   \n",
       "2963    9923   data/test/9923.jpg   \n",
       "\n",
       "                                                 arrays  \n",
       "0     [[[159, 159, 159], [157, 157, 157], [158, 158,...  \n",
       "1     [[[195, 195, 195], [198, 198, 198], [193, 193,...  \n",
       "2     [[[105, 105, 105], [40, 40, 40], [45, 45, 45],...  \n",
       "3     [[[255, 255, 255], [253, 253, 253], [253, 253,...  \n",
       "4     [[[6, 6, 6], [4, 4, 4], [5, 5, 5], [7, 7, 7], ...  \n",
       "...                                                 ...  \n",
       "2959  [[[13, 13, 13], [12, 12, 12], [7, 7, 7], [7, 7...  \n",
       "2960  [[[194, 194, 194], [199, 199, 199], [200, 200,...  \n",
       "2961  [[[29, 29, 29], [23, 23, 23], [22, 22, 22], [1...  \n",
       "2962  [[[246, 246, 246], [245, 245, 245], [247, 247,...  \n",
       "2963  [[[13, 13, 13], [10, 10, 10], [8, 8, 8], [4, 4...  \n",
       "\n",
       "[2964 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv(\"test_set.csv\", index_col=0)\n",
    "test_set['arrays'] = test_set['paths'].apply(lambda x: cv2.imread(x))\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuestra X, tendremos que quedarnos unicamente con un color por pixel.\n",
    "\n",
    "Para ello utilizamos el método stack() para aplanar las imágenes, es decir, convertir los pixeles en un array 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "train_set[train_set.label == \"happy\"].index\n",
    "train_set[train_set.label == \"sadness\"].index\n",
    "\n",
    "# aplico label enconder para convertir en numeros happy y sadness\n",
    "label_enconder = preprocessing.LabelEncoder()\n",
    "label_enconder.fit(train_set.label)\n",
    "y = label_encoder.transform(train_set.label)\n",
    "\n",
    "y = y.reshape(-1,1) # la transformo en matriz de 1D\n",
    "y.shape\n",
    "\n",
    "X = train_set['arrays']\n",
    "X = np.array(X)\n",
    "X = np.stack(X)\n",
    "\n",
    "X_test = test_set['arrays']\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.stack(X_test) # une todas las arrays de cada fila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos la X para que los datos estén entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = X/255 \n",
    "X_test_scaled = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos entre train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9681, 48, 48, 3)\n",
      "(2421, 48, 48, 3)\n",
      "(9681, 1)\n",
      "(2421, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los modelos de regresión me daban error y en el código de Marta, he visto tensorflow, he investigado y he trabajado el modelo usándolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 11s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "vgg = keras.applications.VGG16(weights='imagenet', include_top=False)\n",
    "vgg.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gaussian_noise (GaussianNoi  (None, 48, 48, 3)        0         \n",
      " se)                                                             \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,111,234\n",
      "Trainable params: 15,110,210\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.GaussianNoise(.2,input_shape=(48, 48,3)))\n",
    "model.add(vgg) # convolution layers\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(.4)) # para evitar overfitting\n",
    "model.add(keras.layers.Dense(units = 512,\n",
    "                            activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dropout(.4))  # para evitar overfitting\n",
    "model.add(keras.layers.BatchNormalization())# para acelerar el proceso\n",
    "model.add(keras.layers.Dense(units = 256,\n",
    "                            activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dropout(.2))  # para evitar overfitting\n",
    "model.add(keras.layers.Dense(units = 2,\n",
    "                            activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(1e-5),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, verbose=1,\n",
    "    mode='auto', restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "152/152 [==============================] - 427s 3s/step - loss: 0.8625 - sparse_categorical_accuracy: 0.5267 - val_loss: 0.6180 - val_sparse_categorical_accuracy: 0.6605\n",
      "Epoch 2/60\n",
      "152/152 [==============================] - 433s 3s/step - loss: 0.7779 - sparse_categorical_accuracy: 0.5901 - val_loss: 0.5636 - val_sparse_categorical_accuracy: 0.7080\n",
      "Epoch 3/60\n",
      "152/152 [==============================] - 423s 3s/step - loss: 0.7119 - sparse_categorical_accuracy: 0.6389 - val_loss: 0.5429 - val_sparse_categorical_accuracy: 0.7323\n",
      "Epoch 4/60\n",
      "152/152 [==============================] - 415s 3s/step - loss: 0.6065 - sparse_categorical_accuracy: 0.7062 - val_loss: 0.6181 - val_sparse_categorical_accuracy: 0.6708\n",
      "Epoch 5/60\n",
      "152/152 [==============================] - 431s 3s/step - loss: 0.5492 - sparse_categorical_accuracy: 0.7381 - val_loss: 0.4180 - val_sparse_categorical_accuracy: 0.8150\n",
      "Epoch 6/60\n",
      "152/152 [==============================] - 439s 3s/step - loss: 0.4922 - sparse_categorical_accuracy: 0.7721 - val_loss: 0.4153 - val_sparse_categorical_accuracy: 0.8137\n",
      "Epoch 7/60\n",
      "152/152 [==============================] - 480s 3s/step - loss: 0.4623 - sparse_categorical_accuracy: 0.7900 - val_loss: 0.3580 - val_sparse_categorical_accuracy: 0.8451\n",
      "Epoch 8/60\n",
      "152/152 [==============================] - 434s 3s/step - loss: 0.4379 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.3504 - val_sparse_categorical_accuracy: 0.8488\n",
      "Epoch 9/60\n",
      "152/152 [==============================] - 350s 2s/step - loss: 0.4122 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.3949 - val_sparse_categorical_accuracy: 0.8306\n",
      "Epoch 10/60\n",
      "152/152 [==============================] - 403s 3s/step - loss: 0.3933 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.3676 - val_sparse_categorical_accuracy: 0.8426\n",
      "Epoch 11/60\n",
      "152/152 [==============================] - 408s 3s/step - loss: 0.3874 - sparse_categorical_accuracy: 0.8276 - val_loss: 0.3186 - val_sparse_categorical_accuracy: 0.8608\n",
      "Epoch 12/60\n",
      "152/152 [==============================] - 404s 3s/step - loss: 0.3656 - sparse_categorical_accuracy: 0.8376 - val_loss: 0.4172 - val_sparse_categorical_accuracy: 0.8187\n",
      "Epoch 13/60\n",
      "152/152 [==============================] - 5315s 35s/step - loss: 0.3483 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.3076 - val_sparse_categorical_accuracy: 0.8686\n",
      "Epoch 14/60\n",
      "152/152 [==============================] - 384s 3s/step - loss: 0.3328 - sparse_categorical_accuracy: 0.8515 - val_loss: 0.4775 - val_sparse_categorical_accuracy: 0.7798\n",
      "Epoch 15/60\n",
      "152/152 [==============================] - 439s 3s/step - loss: 0.3245 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.3129 - val_sparse_categorical_accuracy: 0.8604\n",
      "Epoch 16/60\n",
      "152/152 [==============================] - 432s 3s/step - loss: 0.3202 - sparse_categorical_accuracy: 0.8601 - val_loss: 0.3155 - val_sparse_categorical_accuracy: 0.8600\n",
      "Epoch 17/60\n",
      "152/152 [==============================] - 3972s 26s/step - loss: 0.3039 - sparse_categorical_accuracy: 0.8693 - val_loss: 0.3068 - val_sparse_categorical_accuracy: 0.8682\n",
      "Epoch 18/60\n",
      "152/152 [==============================] - 349s 2s/step - loss: 0.2979 - sparse_categorical_accuracy: 0.8735 - val_loss: 0.2943 - val_sparse_categorical_accuracy: 0.8724\n",
      "Epoch 19/60\n",
      "152/152 [==============================] - 405s 3s/step - loss: 0.2911 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.3219 - val_sparse_categorical_accuracy: 0.8563\n",
      "Epoch 20/60\n",
      "152/152 [==============================] - 410s 3s/step - loss: 0.2792 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.2867 - val_sparse_categorical_accuracy: 0.8798\n",
      "Epoch 21/60\n",
      "152/152 [==============================] - 387s 3s/step - loss: 0.2728 - sparse_categorical_accuracy: 0.8828 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8525\n",
      "Epoch 22/60\n",
      "152/152 [==============================] - 752s 5s/step - loss: 0.2474 - sparse_categorical_accuracy: 0.8984 - val_loss: 0.3126 - val_sparse_categorical_accuracy: 0.8612\n",
      "Epoch 23/60\n",
      "152/152 [==============================] - 361s 2s/step - loss: 0.2531 - sparse_categorical_accuracy: 0.8952 - val_loss: 0.3361 - val_sparse_categorical_accuracy: 0.8579\n",
      "Epoch 24/60\n",
      "152/152 [==============================] - 1283s 8s/step - loss: 0.2312 - sparse_categorical_accuracy: 0.8994 - val_loss: 0.4717 - val_sparse_categorical_accuracy: 0.7815\n",
      "Epoch 25/60\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.2337 - sparse_categorical_accuracy: 0.9015Restoring model weights from the end of the best epoch: 20.\n",
      "152/152 [==============================] - 291s 2s/step - loss: 0.2337 - sparse_categorical_accuracy: 0.9015 - val_loss: 0.3236 - val_sparse_categorical_accuracy: 0.8682\n",
      "Epoch 25: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 60,\n",
    "    validation_data = (X_test,y_test),\n",
    "    callbacks=[earlystop] #para evitar overfitting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 20s 259ms/step - loss: 0.2867 - sparse_categorical_accuracy: 0.8798\n",
      "final accuracy :  0.8798017501831055\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"final accuracy : \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 25s 262ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.argmax(axis=1)\n",
    "le.inverse_transform(predictions.argmax(axis=1))\n",
    "submission_prediction = pd.DataFrame(data = test_set, columns = ['id_img'])\n",
    "submission_prediction['label'] = le.inverse_transform(predictions.argmax(axis=1))\n",
    "submission_prediction.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e135d3e91da69d5319bc10e432aed47c85fb00b049291b1f4aed48ebcc856af7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

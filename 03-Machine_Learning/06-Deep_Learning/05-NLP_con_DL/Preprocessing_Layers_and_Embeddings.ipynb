{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAPAS DE PREPROCESADO DE KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que sklearn tenemos sus \"transformers\" y difernentes funciones para poder procesar los datos, para luego, si queremos incluirlos en un pipeline, en Keras existen \"capas\" de preprocesamiento que podemos incluir en el modelo de forma análoga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con un dataset que empleamos en su día para \"no-supervisado\", para revisar unas cuantas de esas capas equivalentes a lo que ya hemos empleado con sklearn. Eso nos permitirá introducir las capas de Embedding y de ahí pasar al procesado de lenguaje natural empleando DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enalapril</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>management of congestive heart failure</td>\n",
       "      <td>slowed the progression of left ventricular dys...</td>\n",
       "      <td>cough, hypotension , proteinuria, impotence , ...</td>\n",
       "      <td>monitor blood pressure , weight and asses for ...</td>\n",
       "      <td>318440</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ortho-tri-cyclen</td>\n",
       "      <td>1</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>birth prevention</td>\n",
       "      <td>Although this type of birth control has more c...</td>\n",
       "      <td>Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...</td>\n",
       "      <td>I Hate This Birth Control, I Would Not Suggest...</td>\n",
       "      <td>888949</td>\n",
       "      <td>909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ponstel</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>menstrual cramps</td>\n",
       "      <td>I was used to having cramps so badly that they...</td>\n",
       "      <td>Heavier bleeding and clotting than normal.</td>\n",
       "      <td>I took 2 pills at the onset of my menstrual cr...</td>\n",
       "      <td>264077</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prilosec</td>\n",
       "      <td>3</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>acid reflux</td>\n",
       "      <td>The acid reflux went away for a few months aft...</td>\n",
       "      <td>Constipation, dry mouth and some mild dizzines...</td>\n",
       "      <td>I was given Prilosec prescription at a dose of...</td>\n",
       "      <td>542110</td>\n",
       "      <td>602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lyrica</td>\n",
       "      <td>2</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>fibromyalgia</td>\n",
       "      <td>I think that the Lyrica was starting to help w...</td>\n",
       "      <td>I felt extremely drugged and dopey.  Could not...</td>\n",
       "      <td>See above</td>\n",
       "      <td>83761</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        urlDrugName  rating         effectiveness          sideEffects  \\\n",
       "0         enalapril       4      Highly Effective    Mild Side Effects   \n",
       "1  ortho-tri-cyclen       1      Highly Effective  Severe Side Effects   \n",
       "2           ponstel      10      Highly Effective      No Side Effects   \n",
       "3          prilosec       3  Marginally Effective    Mild Side Effects   \n",
       "4            lyrica       2  Marginally Effective  Severe Side Effects   \n",
       "\n",
       "                                condition  \\\n",
       "0  management of congestive heart failure   \n",
       "1                        birth prevention   \n",
       "2                        menstrual cramps   \n",
       "3                             acid reflux   \n",
       "4                            fibromyalgia   \n",
       "\n",
       "                                      benefitsReview  \\\n",
       "0  slowed the progression of left ventricular dys...   \n",
       "1  Although this type of birth control has more c...   \n",
       "2  I was used to having cramps so badly that they...   \n",
       "3  The acid reflux went away for a few months aft...   \n",
       "4  I think that the Lyrica was starting to help w...   \n",
       "\n",
       "                                   sideEffectsReview  \\\n",
       "0  cough, hypotension , proteinuria, impotence , ...   \n",
       "1  Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...   \n",
       "2         Heavier bleeding and clotting than normal.   \n",
       "3  Constipation, dry mouth and some mild dizzines...   \n",
       "4  I felt extremely drugged and dopey.  Could not...   \n",
       "\n",
       "                                      commentsReview   Sales  Production  \n",
       "0  monitor blood pressure , weight and asses for ...  318440       398.0  \n",
       "1  I Hate This Birth Control, I Would Not Suggest...  888949       909.0  \n",
       "2  I took 2 pills at the onset of my menstrual cr...  264077       465.0  \n",
       "3  I was given Prilosec prescription at a dose of...  542110       602.0  \n",
       "4                                          See above   83761       124.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/pharma_full.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3107 entries, 0 to 3106\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   urlDrugName        3107 non-null   object \n",
      " 1   rating             3107 non-null   int64  \n",
      " 2   effectiveness      3107 non-null   object \n",
      " 3   sideEffects        3107 non-null   object \n",
      " 4   condition          3106 non-null   object \n",
      " 5   benefitsReview     3107 non-null   object \n",
      " 6   sideEffectsReview  3105 non-null   object \n",
      " 7   commentsReview     3099 non-null   object \n",
      " 8   Sales              3107 non-null   int64  \n",
      " 9   Production         3107 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 242.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las prepararemos un poco para que podamos emplear todos los tipos de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los missings seguiremos tratándolos, por ahora, a parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.fillna(\"No Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3107 entries, 0 to 3106\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   urlDrugName        3107 non-null   object \n",
      " 1   rating             3107 non-null   int64  \n",
      " 2   effectiveness      3107 non-null   object \n",
      " 3   sideEffects        3107 non-null   object \n",
      " 4   condition          3107 non-null   object \n",
      " 5   benefitsReview     3107 non-null   object \n",
      " 6   sideEffectsReview  3107 non-null   object \n",
      " 7   commentsReview     3107 non-null   object \n",
      " 8   Sales              3107 non-null   int64  \n",
      " 9   Production         3107 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 242.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\glezr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk as nl\n",
    "nl.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [col for col in df_clean.columns if \"Review\" in col]:\n",
    "    df_clean[col + \"_wc\"] = df_clean[col].apply(lambda value: len(nl.tokenize.word_tokenize(value)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Production</th>\n",
       "      <th>benefitsReview_wc</th>\n",
       "      <th>sideEffectsReview_wc</th>\n",
       "      <th>commentsReview_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enalapril</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>management of congestive heart failure</td>\n",
       "      <td>slowed the progression of left ventricular dys...</td>\n",
       "      <td>cough, hypotension , proteinuria, impotence , ...</td>\n",
       "      <td>monitor blood pressure , weight and asses for ...</td>\n",
       "      <td>318440</td>\n",
       "      <td>398.0</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ortho-tri-cyclen</td>\n",
       "      <td>1</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>birth prevention</td>\n",
       "      <td>Although this type of birth control has more c...</td>\n",
       "      <td>Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...</td>\n",
       "      <td>I Hate This Birth Control, I Would Not Suggest...</td>\n",
       "      <td>888949</td>\n",
       "      <td>909.0</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ponstel</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>menstrual cramps</td>\n",
       "      <td>I was used to having cramps so badly that they...</td>\n",
       "      <td>Heavier bleeding and clotting than normal.</td>\n",
       "      <td>I took 2 pills at the onset of my menstrual cr...</td>\n",
       "      <td>264077</td>\n",
       "      <td>465.0</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prilosec</td>\n",
       "      <td>3</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>acid reflux</td>\n",
       "      <td>The acid reflux went away for a few months aft...</td>\n",
       "      <td>Constipation, dry mouth and some mild dizzines...</td>\n",
       "      <td>I was given Prilosec prescription at a dose of...</td>\n",
       "      <td>542110</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lyrica</td>\n",
       "      <td>2</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>fibromyalgia</td>\n",
       "      <td>I think that the Lyrica was starting to help w...</td>\n",
       "      <td>I felt extremely drugged and dopey.  Could not...</td>\n",
       "      <td>See above</td>\n",
       "      <td>83761</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>vyvanse</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>adhd</td>\n",
       "      <td>Increased focus, attention, productivity. Bett...</td>\n",
       "      <td>Restless legs at night, insomnia, headache (so...</td>\n",
       "      <td>I took adderall once as a child, and it made m...</td>\n",
       "      <td>270483</td>\n",
       "      <td>470.0</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>zoloft</td>\n",
       "      <td>1</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>Extremely Severe Side Effects</td>\n",
       "      <td>depression</td>\n",
       "      <td>Emotions were somewhat blunted. Less moodiness.</td>\n",
       "      <td>Weight gain, extreme tiredness during the day,...</td>\n",
       "      <td>I was on Zoloft for about 2 years total. I am ...</td>\n",
       "      <td>504277</td>\n",
       "      <td>524.0</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>climara</td>\n",
       "      <td>2</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>total hysterctomy</td>\n",
       "      <td>---</td>\n",
       "      <td>Constant issues with the patch not staying on....</td>\n",
       "      <td>---</td>\n",
       "      <td>127063</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>trileptal</td>\n",
       "      <td>8</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>epilepsy</td>\n",
       "      <td>Controlled complex partial seizures.</td>\n",
       "      <td>Dizziness, fatigue, nausea</td>\n",
       "      <td>Started at 2 doses of 300 mg a day and worked ...</td>\n",
       "      <td>342695</td>\n",
       "      <td>502.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>micardis</td>\n",
       "      <td>4</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>high blood pressure</td>\n",
       "      <td>The drug Micardis did seem to alleviate my hig...</td>\n",
       "      <td>I find when I am taking Micardis that I tend t...</td>\n",
       "      <td>I take Micardis in pill form once daily.</td>\n",
       "      <td>620876</td>\n",
       "      <td>701.0</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3107 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           urlDrugName  rating           effectiveness  \\\n",
       "0            enalapril       4        Highly Effective   \n",
       "1     ortho-tri-cyclen       1        Highly Effective   \n",
       "2              ponstel      10        Highly Effective   \n",
       "3             prilosec       3    Marginally Effective   \n",
       "4               lyrica       2    Marginally Effective   \n",
       "...                ...     ...                     ...   \n",
       "3102           vyvanse      10        Highly Effective   \n",
       "3103            zoloft       1             Ineffective   \n",
       "3104           climara       2    Marginally Effective   \n",
       "3105         trileptal       8  Considerably Effective   \n",
       "3106          micardis       4    Moderately Effective   \n",
       "\n",
       "                        sideEffects                               condition  \\\n",
       "0                 Mild Side Effects  management of congestive heart failure   \n",
       "1               Severe Side Effects                        birth prevention   \n",
       "2                   No Side Effects                        menstrual cramps   \n",
       "3                 Mild Side Effects                             acid reflux   \n",
       "4               Severe Side Effects                            fibromyalgia   \n",
       "...                             ...                                     ...   \n",
       "3102              Mild Side Effects                                    adhd   \n",
       "3103  Extremely Severe Side Effects                              depression   \n",
       "3104          Moderate Side Effects                       total hysterctomy   \n",
       "3105              Mild Side Effects                                epilepsy   \n",
       "3106          Moderate Side Effects                     high blood pressure   \n",
       "\n",
       "                                         benefitsReview  \\\n",
       "0     slowed the progression of left ventricular dys...   \n",
       "1     Although this type of birth control has more c...   \n",
       "2     I was used to having cramps so badly that they...   \n",
       "3     The acid reflux went away for a few months aft...   \n",
       "4     I think that the Lyrica was starting to help w...   \n",
       "...                                                 ...   \n",
       "3102  Increased focus, attention, productivity. Bett...   \n",
       "3103    Emotions were somewhat blunted. Less moodiness.   \n",
       "3104                                                ---   \n",
       "3105               Controlled complex partial seizures.   \n",
       "3106  The drug Micardis did seem to alleviate my hig...   \n",
       "\n",
       "                                      sideEffectsReview  \\\n",
       "0     cough, hypotension , proteinuria, impotence , ...   \n",
       "1     Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...   \n",
       "2            Heavier bleeding and clotting than normal.   \n",
       "3     Constipation, dry mouth and some mild dizzines...   \n",
       "4     I felt extremely drugged and dopey.  Could not...   \n",
       "...                                                 ...   \n",
       "3102  Restless legs at night, insomnia, headache (so...   \n",
       "3103  Weight gain, extreme tiredness during the day,...   \n",
       "3104  Constant issues with the patch not staying on....   \n",
       "3105                         Dizziness, fatigue, nausea   \n",
       "3106  I find when I am taking Micardis that I tend t...   \n",
       "\n",
       "                                         commentsReview   Sales  Production  \\\n",
       "0     monitor blood pressure , weight and asses for ...  318440       398.0   \n",
       "1     I Hate This Birth Control, I Would Not Suggest...  888949       909.0   \n",
       "2     I took 2 pills at the onset of my menstrual cr...  264077       465.0   \n",
       "3     I was given Prilosec prescription at a dose of...  542110       602.0   \n",
       "4                                             See above   83761       124.0   \n",
       "...                                                 ...     ...         ...   \n",
       "3102  I took adderall once as a child, and it made m...  270483       470.0   \n",
       "3103  I was on Zoloft for about 2 years total. I am ...  504277       524.0   \n",
       "3104                                                ---  127063       167.0   \n",
       "3105  Started at 2 doses of 300 mg a day and worked ...  342695       502.0   \n",
       "3106           I take Micardis in pill form once daily.  620876       701.0   \n",
       "\n",
       "      benefitsReview_wc  sideEffectsReview_wc  commentsReview_wc  \n",
       "0                    26                    29                 11  \n",
       "1                    38                    58                 14  \n",
       "2                    52                     7                 81  \n",
       "3                   135                    21                 31  \n",
       "4                    23                    31                  2  \n",
       "...                 ...                   ...                ...  \n",
       "3102                 41                    52                124  \n",
       "3103                  8                    24                468  \n",
       "3104                  2                   161                  2  \n",
       "3105                  5                     5                 66  \n",
       "3106                 74                    20                  9  \n",
       "\n",
       "[3107 rows x 13 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df[[\"rating\"]]-1 # Cositas del Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3107 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating\n",
       "0          3\n",
       "1          0\n",
       "2          9\n",
       "3          2\n",
       "4          1\n",
       "...      ...\n",
       "3102       9\n",
       "3103       0\n",
       "3104       1\n",
       "3105       7\n",
       "3106       3\n",
       "\n",
       "[3107 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "9         742\n",
       "7         558\n",
       "8         480\n",
       "6         350\n",
       "0         305\n",
       "4         159\n",
       "5         157\n",
       "2         146\n",
       "3         107\n",
       "1         103\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_clean.drop(\"rating\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas = [col for col in df_X.columns if df_X[col].dtype != \"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado usando Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = df_X[numericas]\n",
    "y_num = df_target.copy()\n",
    "X_train = X_num[:2400]\n",
    "y_train = y_num[:2400]\n",
    "X_valid = X_num[2400:]\n",
    "y_valid = y_num[2400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3),\\\n",
    "              metrics =[\"acc\"])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.307729e+08</td>\n",
       "      <td>0.221250</td>\n",
       "      <td>2.296485</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.315079e+00</td>\n",
       "      <td>0.237083</td>\n",
       "      <td>2.290218</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.306194e+00</td>\n",
       "      <td>0.237083</td>\n",
       "      <td>2.284142</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.297484e+00</td>\n",
       "      <td>0.236667</td>\n",
       "      <td>2.278260</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.289187e+00</td>\n",
       "      <td>0.236667</td>\n",
       "      <td>2.272562</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2.078734e+00</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>2.113286</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2.078717e+00</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>2.113297</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2.078701e+00</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>2.113309</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2.078690e+00</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>2.113320</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2.078679e+00</td>\n",
       "      <td>0.237917</td>\n",
       "      <td>2.113332</td>\n",
       "      <td>0.24611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss       acc  val_loss  val_acc\n",
       "0    1.307729e+08  0.221250  2.296485  0.24611\n",
       "1    2.315079e+00  0.237083  2.290218  0.24611\n",
       "2    2.306194e+00  0.237083  2.284142  0.24611\n",
       "3    2.297484e+00  0.236667  2.278260  0.24611\n",
       "4    2.289187e+00  0.236667  2.272562  0.24611\n",
       "..            ...       ...       ...      ...\n",
       "295  2.078734e+00  0.237917  2.113286  0.24611\n",
       "296  2.078717e+00  0.237917  2.113297  0.24611\n",
       "297  2.078701e+00  0.237917  2.113309  0.24611\n",
       "298  2.078690e+00  0.237917  2.113320  0.24611\n",
       "299  2.078679e+00  0.237917  2.113332  0.24611\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "model = tf.keras.models.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3),\\\n",
    "              metrics =[\"acc\"])\n",
    "norm_layer.adapt(X_train)  # computes the mean and variance of every feature\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.387116</td>\n",
       "      <td>0.124583</td>\n",
       "      <td>2.375459</td>\n",
       "      <td>0.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.361022</td>\n",
       "      <td>0.162917</td>\n",
       "      <td>2.350753</td>\n",
       "      <td>0.178218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.337331</td>\n",
       "      <td>0.187083</td>\n",
       "      <td>2.328239</td>\n",
       "      <td>0.196605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.315755</td>\n",
       "      <td>0.194167</td>\n",
       "      <td>2.307621</td>\n",
       "      <td>0.199434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.295938</td>\n",
       "      <td>0.200833</td>\n",
       "      <td>2.288679</td>\n",
       "      <td>0.210750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1.600010</td>\n",
       "      <td>0.383750</td>\n",
       "      <td>1.618311</td>\n",
       "      <td>0.398868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.598243</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>1.616507</td>\n",
       "      <td>0.398868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1.596454</td>\n",
       "      <td>0.384583</td>\n",
       "      <td>1.614857</td>\n",
       "      <td>0.398868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1.594712</td>\n",
       "      <td>0.385833</td>\n",
       "      <td>1.613164</td>\n",
       "      <td>0.398868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.592955</td>\n",
       "      <td>0.386250</td>\n",
       "      <td>1.611441</td>\n",
       "      <td>0.400283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss   val_acc\n",
       "0    2.387116  0.124583  2.375459  0.138614\n",
       "1    2.361022  0.162917  2.350753  0.178218\n",
       "2    2.337331  0.187083  2.328239  0.196605\n",
       "3    2.315755  0.194167  2.307621  0.199434\n",
       "4    2.295938  0.200833  2.288679  0.210750\n",
       "..        ...       ...       ...       ...\n",
       "295  1.600010  0.383750  1.618311  0.398868\n",
       "296  1.598243  0.385000  1.616507  0.398868\n",
       "297  1.596454  0.384583  1.614857  0.398868\n",
       "298  1.594712  0.385833  1.613164  0.398868\n",
       "299  1.592955  0.386250  1.611441  0.400283\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding y Onehot Encoding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ocurría con pyspark, primero tenemos que hacer un String encoding (StringIndexer), es decir un OrdinalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinalEncoding = tf.keras.layers.StringLookup()\n",
    "ordinalEncoding.adapt(df_X[\"effectiveness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X[\"effec_coded\"] = ordinalEncoding(df_X[\"effectiveness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Sales', 'Production', 'benefitsReview_wc', 'sideEffectsReview_wc', 'commentsReview_wc', 'effec_coded']]\n"
     ]
    }
   ],
   "source": [
    "numericas = [col for col in df_X.columns if df_X[col].dtype != \"object\"]\n",
    "print([numericas])\n",
    "X_num = df_X[numericas]\n",
    "y_num = df_target.copy()\n",
    "X_train = X_num[:2400]\n",
    "y_train = y_num[:2400]\n",
    "X_valid = X_num[2400:]\n",
    "y_valid = y_num[2400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "model = tf.keras.models.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3),\\\n",
    "              metrics =[\"acc\"])\n",
    "norm_layer.adapt(X_train)  # computes the mean and variance of every feature\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.392560</td>\n",
       "      <td>0.068333</td>\n",
       "      <td>2.350723</td>\n",
       "      <td>0.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.351232</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>2.311529</td>\n",
       "      <td>0.114569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.313275</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>2.275472</td>\n",
       "      <td>0.171146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.278324</td>\n",
       "      <td>0.177917</td>\n",
       "      <td>2.242112</td>\n",
       "      <td>0.198020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.245965</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>2.211182</td>\n",
       "      <td>0.247525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1.490166</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>1.522711</td>\n",
       "      <td>0.422914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1.489538</td>\n",
       "      <td>0.451250</td>\n",
       "      <td>1.522182</td>\n",
       "      <td>0.424328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.452083</td>\n",
       "      <td>1.521581</td>\n",
       "      <td>0.424328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1.488300</td>\n",
       "      <td>0.451667</td>\n",
       "      <td>1.521076</td>\n",
       "      <td>0.424328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.487690</td>\n",
       "      <td>0.452083</td>\n",
       "      <td>1.520543</td>\n",
       "      <td>0.424328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss   val_acc\n",
       "0    2.392560  0.068333  2.350723  0.089109\n",
       "1    2.351232  0.095000  2.311529  0.114569\n",
       "2    2.313275  0.135000  2.275472  0.171146\n",
       "3    2.278324  0.177917  2.242112  0.198020\n",
       "4    2.245965  0.215000  2.211182  0.247525\n",
       "..        ...       ...       ...       ...\n",
       "285  1.490166  0.451667  1.522711  0.422914\n",
       "286  1.489538  0.451250  1.522182  0.424328\n",
       "287  1.488901  0.452083  1.521581  0.424328\n",
       "288  1.488300  0.451667  1.521076  0.424328\n",
       "289  1.487690  0.452083  1.520543  0.424328\n",
       "\n",
       "[290 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).head(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero podemos hacer el onehot encoding de una vez configurando la StringLookup layer debidamente.  Además ahora usaremos la functional API para incluir la capa dentro del modelo (y no tener que hacer la conversión por fuera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.drop(\"effec_coded\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Sales', 'Production', 'benefitsReview_wc', 'sideEffectsReview_wc', 'commentsReview_wc']]\n"
     ]
    }
   ],
   "source": [
    "numericas = [col for col in df_X.columns if df_X[col].dtype != \"object\"]\n",
    "print([numericas])\n",
    "X_train = df_X[numericas]\n",
    "y_train = df_target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107, 5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eff = df_X[[\"effectiveness\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Highly Effective          1330\n",
       "Considerably Effective     928\n",
       "Moderately Effective       415\n",
       "Ineffective                247\n",
       "Marginally Effective       187\n",
       "Name: effectiveness, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_eff.effectiveness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "codingLayer = tf.keras.layers.StringLookup(output_mode = \"one_hot\", )\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "\n",
    "\n",
    "normalization_layer.adapt(X_train)\n",
    "codingLayer.adapt(X_eff)\n",
    "\n",
    "\n",
    "input_num = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "input_cat = tf.keras.layers.Input(shape=X_eff.shape[1:], dtype = tf.string)\n",
    "normalized = normalization_layer(input_num)\n",
    "encoded = codingLayer(input_cat)\n",
    "concat = concat_layer([normalized,encoded])\n",
    "hidden1 = hidden_layer1(concat)\n",
    "output = output_layer(hidden1)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_num,input_cat], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer.adapt(X_train)\n",
    "codingLayer.adapt(X_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3),\\\n",
    "              metrics =[\"acc\"])\n",
    "history = model.fit((X_train,X_eff),y_train, epochs=200, verbose = 0, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.501737</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>1.574187</td>\n",
       "      <td>0.419614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.500772</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>1.573279</td>\n",
       "      <td>0.419614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.499824</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>1.572450</td>\n",
       "      <td>0.419614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.498845</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>1.571551</td>\n",
       "      <td>0.419614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.497899</td>\n",
       "      <td>0.456740</td>\n",
       "      <td>1.570680</td>\n",
       "      <td>0.419614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       acc  val_loss   val_acc\n",
       "195  1.501737  0.457143  1.574187  0.419614\n",
       "196  1.500772  0.457143  1.573279  0.419614\n",
       "197  1.499824  0.457143  1.572450  0.419614\n",
       "198  1.498845  0.457143  1.571551  0.419614\n",
       "199  1.497899  0.456740  1.570680  0.419614"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capas de Vectorizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El equivalente al CountVectorizer y al TfidfVectorizer de sklearn es la capa TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer_count = tf.keras.layers.TextVectorization(output_mode = \"count\") # output_mode = \"count\" -> Countvectorizer\n",
    "text_vec_layer_count.adapt(df_X[[\"sideEffectsReview\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', 'i', 'the', 'and', 'to', 'a', 'of', 'my', 'it', 'was']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_count.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Heavier bleeding and clotting than normal.']\n"
     ]
    }
   ],
   "source": [
    "texto = df_X[\"sideEffectsReview\"][2:3].values\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer_tfidf = tf.keras.layers.TextVectorization(output_mode= \"tf_idf\") # output_mode = \"tf_idf\" -> TfIdfVectorizer, existe un tercer modo (el que viene por defecto que veremos un poco más adelante)\n",
    "text_vec_layer_tfidf.adapt(df_X[\"sideEffectsReview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = text_vec_layer_count(df_X[\"sideEffectsReview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3107, 7441), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 2., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 7., 5., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 3., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame(vectors.numpy(),\\\n",
    "                          columns= text_vec_layer_count.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[UNK]</th>\n",
       "      <th>i</th>\n",
       "      <th>the</th>\n",
       "      <th>and</th>\n",
       "      <th>to</th>\n",
       "      <th>a</th>\n",
       "      <th>of</th>\n",
       "      <th>my</th>\n",
       "      <th>it</th>\n",
       "      <th>was</th>\n",
       "      <th>...</th>\n",
       "      <th>10142008</th>\n",
       "      <th>1014</th>\n",
       "      <th>1012</th>\n",
       "      <th>100mgthe</th>\n",
       "      <th>100mgs</th>\n",
       "      <th>100mgdoses</th>\n",
       "      <th>100110</th>\n",
       "      <th>1000mg</th>\n",
       "      <th>10000</th>\n",
       "      <th>072009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3107 rows × 7441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      [UNK]    i  the  and   to    a   of   my   it  was  ...  10142008  1014  \\\n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0   0.0   \n",
       "1       0.0  0.0  2.0  0.0  2.0  1.0  1.0  1.0  0.0  0.0  ...       0.0   0.0   \n",
       "2       0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0   0.0   \n",
       "3       0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...       0.0   0.0   \n",
       "4       0.0  1.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0   0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   ...   \n",
       "3102    0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  2.0  0.0  ...       0.0   0.0   \n",
       "3103    0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0   0.0   \n",
       "3104    0.0  7.0  5.0  5.0  5.0  1.0  2.0  5.0  3.0  0.0  ...       0.0   0.0   \n",
       "3105    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       0.0   0.0   \n",
       "3106    0.0  3.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  ...       0.0   0.0   \n",
       "\n",
       "      1012  100mgthe  100mgs  100mgdoses  100110  1000mg  10000  072009  \n",
       "0      0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "1      0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "2      0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "3      0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "4      0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "...    ...       ...     ...         ...     ...     ...    ...     ...  \n",
       "3102   0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "3103   0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "3104   0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "3105   0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "3106   0.0       0.0     0.0         0.0     0.0     0.0    0.0     0.0  \n",
       "\n",
       "[3107 rows x 7441 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendremos que hacer la normalización/limpieza del texto..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescatando la que hicimos para la IMDB Reviews\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "replace_no_space = \"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\"\n",
    "REPLACE_NO_SPACE = re.compile(replace_no_space)\n",
    "replace_with_space = \"(<br \\s*/><br\\s*/>)|(\\-)|(\\/)\"\n",
    "REPLACE_WITH_SPACE = re.compile(replace_with_space)\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "dictionary = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def clean(row):\n",
    "    # Limpio signos y convierto a minúsculas\n",
    "    dato = REPLACE_NO_SPACE.sub(NO_SPACE, row.lower())\n",
    "    # Convierto los retornos de carro <br /><br /> en espacios y los guiones (\"-\")\n",
    "    dato = REPLACE_WITH_SPACE.sub(SPACE, dato)\n",
    "    # Quito cualquier link\n",
    "    dato = \" \".join([word for word in dato.split() if \"http\" not in word])\n",
    "    # Quito los stopwords\n",
    "    dato = \" \".join([word for word in dato.split(\" \") if word not in dictionary])\n",
    "    return dato\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos formas:  \n",
    "    1. Por fuera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_clean = df_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_clean[\"sideEffectsReview\"] = df_X_clean.sideEffectsReview.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Production</th>\n",
       "      <th>benefitsReview_wc</th>\n",
       "      <th>sideEffectsReview_wc</th>\n",
       "      <th>commentsReview_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enalapril</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>management of congestive heart failure</td>\n",
       "      <td>slowed the progression of left ventricular dys...</td>\n",
       "      <td>cough hypotension proteinuria impotence renal ...</td>\n",
       "      <td>monitor blood pressure , weight and asses for ...</td>\n",
       "      <td>318440</td>\n",
       "      <td>398.0</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ortho-tri-cyclen</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>birth prevention</td>\n",
       "      <td>Although this type of birth control has more c...</td>\n",
       "      <td>heavy cycle cramps hot flashes fatigue long la...</td>\n",
       "      <td>I Hate This Birth Control, I Would Not Suggest...</td>\n",
       "      <td>888949</td>\n",
       "      <td>909.0</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ponstel</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>menstrual cramps</td>\n",
       "      <td>I was used to having cramps so badly that they...</td>\n",
       "      <td>heavier bleeding clotting normal</td>\n",
       "      <td>I took 2 pills at the onset of my menstrual cr...</td>\n",
       "      <td>264077</td>\n",
       "      <td>465.0</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prilosec</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>acid reflux</td>\n",
       "      <td>The acid reflux went away for a few months aft...</td>\n",
       "      <td>constipation dry mouth mild dizziness would go...</td>\n",
       "      <td>I was given Prilosec prescription at a dose of...</td>\n",
       "      <td>542110</td>\n",
       "      <td>602.0</td>\n",
       "      <td>135</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lyrica</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>fibromyalgia</td>\n",
       "      <td>I think that the Lyrica was starting to help w...</td>\n",
       "      <td>felt extremely drugged dopey could drive med a...</td>\n",
       "      <td>See above</td>\n",
       "      <td>83761</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>vyvanse</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>adhd</td>\n",
       "      <td>Increased focus, attention, productivity. Bett...</td>\n",
       "      <td>restless legs night insomnia headache sometime...</td>\n",
       "      <td>I took adderall once as a child, and it made m...</td>\n",
       "      <td>270483</td>\n",
       "      <td>470.0</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>zoloft</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>Extremely Severe Side Effects</td>\n",
       "      <td>depression</td>\n",
       "      <td>Emotions were somewhat blunted. Less moodiness.</td>\n",
       "      <td>weight gain extreme tiredness day insomnia nig...</td>\n",
       "      <td>I was on Zoloft for about 2 years total. I am ...</td>\n",
       "      <td>504277</td>\n",
       "      <td>524.0</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>climara</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>total hysterctomy</td>\n",
       "      <td>---</td>\n",
       "      <td>constant issues patch staying called manufactu...</td>\n",
       "      <td>---</td>\n",
       "      <td>127063</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>trileptal</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>epilepsy</td>\n",
       "      <td>Controlled complex partial seizures.</td>\n",
       "      <td>dizziness fatigue nausea</td>\n",
       "      <td>Started at 2 doses of 300 mg a day and worked ...</td>\n",
       "      <td>342695</td>\n",
       "      <td>502.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>micardis</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>Moderate Side Effects</td>\n",
       "      <td>high blood pressure</td>\n",
       "      <td>The drug Micardis did seem to alleviate my hig...</td>\n",
       "      <td>find taking micardis tend tired libido decreased</td>\n",
       "      <td>I take Micardis in pill form once daily.</td>\n",
       "      <td>620876</td>\n",
       "      <td>701.0</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3107 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           urlDrugName           effectiveness                    sideEffects  \\\n",
       "0            enalapril        Highly Effective              Mild Side Effects   \n",
       "1     ortho-tri-cyclen        Highly Effective            Severe Side Effects   \n",
       "2              ponstel        Highly Effective                No Side Effects   \n",
       "3             prilosec    Marginally Effective              Mild Side Effects   \n",
       "4               lyrica    Marginally Effective            Severe Side Effects   \n",
       "...                ...                     ...                            ...   \n",
       "3102           vyvanse        Highly Effective              Mild Side Effects   \n",
       "3103            zoloft             Ineffective  Extremely Severe Side Effects   \n",
       "3104           climara    Marginally Effective          Moderate Side Effects   \n",
       "3105         trileptal  Considerably Effective              Mild Side Effects   \n",
       "3106          micardis    Moderately Effective          Moderate Side Effects   \n",
       "\n",
       "                                   condition  \\\n",
       "0     management of congestive heart failure   \n",
       "1                           birth prevention   \n",
       "2                           menstrual cramps   \n",
       "3                                acid reflux   \n",
       "4                               fibromyalgia   \n",
       "...                                      ...   \n",
       "3102                                    adhd   \n",
       "3103                              depression   \n",
       "3104                       total hysterctomy   \n",
       "3105                                epilepsy   \n",
       "3106                     high blood pressure   \n",
       "\n",
       "                                         benefitsReview  \\\n",
       "0     slowed the progression of left ventricular dys...   \n",
       "1     Although this type of birth control has more c...   \n",
       "2     I was used to having cramps so badly that they...   \n",
       "3     The acid reflux went away for a few months aft...   \n",
       "4     I think that the Lyrica was starting to help w...   \n",
       "...                                                 ...   \n",
       "3102  Increased focus, attention, productivity. Bett...   \n",
       "3103    Emotions were somewhat blunted. Less moodiness.   \n",
       "3104                                                ---   \n",
       "3105               Controlled complex partial seizures.   \n",
       "3106  The drug Micardis did seem to alleviate my hig...   \n",
       "\n",
       "                                      sideEffectsReview  \\\n",
       "0     cough hypotension proteinuria impotence renal ...   \n",
       "1     heavy cycle cramps hot flashes fatigue long la...   \n",
       "2                      heavier bleeding clotting normal   \n",
       "3     constipation dry mouth mild dizziness would go...   \n",
       "4     felt extremely drugged dopey could drive med a...   \n",
       "...                                                 ...   \n",
       "3102  restless legs night insomnia headache sometime...   \n",
       "3103  weight gain extreme tiredness day insomnia nig...   \n",
       "3104  constant issues patch staying called manufactu...   \n",
       "3105                           dizziness fatigue nausea   \n",
       "3106   find taking micardis tend tired libido decreased   \n",
       "\n",
       "                                         commentsReview   Sales  Production  \\\n",
       "0     monitor blood pressure , weight and asses for ...  318440       398.0   \n",
       "1     I Hate This Birth Control, I Would Not Suggest...  888949       909.0   \n",
       "2     I took 2 pills at the onset of my menstrual cr...  264077       465.0   \n",
       "3     I was given Prilosec prescription at a dose of...  542110       602.0   \n",
       "4                                             See above   83761       124.0   \n",
       "...                                                 ...     ...         ...   \n",
       "3102  I took adderall once as a child, and it made m...  270483       470.0   \n",
       "3103  I was on Zoloft for about 2 years total. I am ...  504277       524.0   \n",
       "3104                                                ---  127063       167.0   \n",
       "3105  Started at 2 doses of 300 mg a day and worked ...  342695       502.0   \n",
       "3106           I take Micardis in pill form once daily.  620876       701.0   \n",
       "\n",
       "      benefitsReview_wc  sideEffectsReview_wc  commentsReview_wc  \n",
       "0                    26                    29                 11  \n",
       "1                    38                    58                 14  \n",
       "2                    52                     7                 81  \n",
       "3                   135                    21                 31  \n",
       "4                    23                    31                  2  \n",
       "...                 ...                   ...                ...  \n",
       "3102                 41                    52                124  \n",
       "3103                  8                    24                468  \n",
       "3104                  2                   161                  2  \n",
       "3105                  5                     5                 66  \n",
       "3106                 74                    20                  9  \n",
       "\n",
       "[3107 rows x 12 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant issues patch staying called manufacture bayer took lot number said sorry said going send new box local pharmacy charge checked every week last three weeks nothing yeah great way follow throughout patch noticed large acne face lack energy libido vaginal dryness daily hot flashes extreme moodiness sorry husband even though great know three months body trying adjust could take anymore contacted gyn prescribed estratest cross fingers hope works\n",
      "\n",
      "dizziness fatigue nausea\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join(df_X_clean[\"sideEffectsReview\"][3104:3106].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_vec_layer_count = tf.keras.layers.TextVectorization(output_mode=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_vec_layer_count.adapt(df_X_clean.sideEffectsReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors_clean = pd.DataFrame(new_text_vec_layer_count(df_X_clean.sideEffectsReview).numpy(),\\\n",
    "                                columns= new_text_vec_layer_count.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[UNK]</th>\n",
       "      <th>side</th>\n",
       "      <th>effects</th>\n",
       "      <th>taking</th>\n",
       "      <th>none</th>\n",
       "      <th>also</th>\n",
       "      <th>drug</th>\n",
       "      <th>day</th>\n",
       "      <th>skin</th>\n",
       "      <th>medication</th>\n",
       "      <th>...</th>\n",
       "      <th>abslutly</th>\n",
       "      <th>abscense</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>aboveand</th>\n",
       "      <th>abnormalities</th>\n",
       "      <th>abilify</th>\n",
       "      <th>abfter</th>\n",
       "      <th>abbsessed</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3107 rows × 6878 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      [UNK]  side  effects  taking  none  also  drug  day  skin  medication  \\\n",
       "0       0.0   0.0      0.0     0.0   0.0   0.0   0.0  0.0   0.0         0.0   \n",
       "1       0.0   0.0      0.0     0.0   0.0   0.0   0.0  0.0   0.0         0.0   \n",
       "2       0.0   0.0      0.0     0.0   0.0   0.0   0.0  0.0   0.0         0.0   \n",
       "3       0.0   0.0      0.0     0.0   0.0   0.0   0.0  0.0   0.0         1.0   \n",
       "4       0.0   0.0      0.0     0.0   0.0   1.0   0.0  0.0   0.0         0.0   \n",
       "...     ...   ...      ...     ...   ...   ...   ...  ...   ...         ...   \n",
       "3102    0.0   0.0      0.0     0.0   0.0   1.0   0.0  0.0   0.0         0.0   \n",
       "3103    0.0   0.0      0.0     0.0   0.0   0.0   0.0  1.0   0.0         0.0   \n",
       "3104    0.0   0.0      0.0     0.0   0.0   0.0   0.0  0.0   0.0         0.0   \n",
       "3105    0.0   0.0      0.0     0.0   0.0   0.0   0.0  0.0   0.0         0.0   \n",
       "3106    0.0   0.0      0.0     1.0   0.0   0.0   0.0  0.0   0.0         0.0   \n",
       "\n",
       "      ...  abslutly  abscense  abruptly  aboveand  abnormalities  abilify  \\\n",
       "0     ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "1     ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "2     ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "3     ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "4     ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "...   ...       ...       ...       ...       ...            ...      ...   \n",
       "3102  ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "3103  ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "3104  ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "3105  ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "3106  ...       0.0       0.0       0.0       0.0            0.0      0.0   \n",
       "\n",
       "      abfter  abbsessed  abandoning  abandon  \n",
       "0        0.0        0.0         0.0      0.0  \n",
       "1        0.0        0.0         0.0      0.0  \n",
       "2        0.0        0.0         0.0      0.0  \n",
       "3        0.0        0.0         0.0      0.0  \n",
       "4        0.0        0.0         0.0      0.0  \n",
       "...      ...        ...         ...      ...  \n",
       "3102     0.0        0.0         0.0      0.0  \n",
       "3103     0.0        0.0         0.0      0.0  \n",
       "3104     0.0        0.0         0.0      0.0  \n",
       "3105     0.0        0.0         0.0      0.0  \n",
       "3106     0.0        0.0         0.0      0.0  \n",
       "\n",
       "[3107 rows x 6878 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectors_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Segunda forma, incorporarlo a la capa en su instanciación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tensors(in_tensor):\n",
    "    \n",
    "    re_expression = \"|\".join([f\"([\\.,;: ]{word} )\" for word in dictionary]) + \"|\" + \"|\".join([f\"^{word} \" for word in dictionary])\n",
    "    #print(re_expression)\n",
    "    lowercase = tf.strings.lower(in_tensor) # Lo pone en minúsculas\n",
    "    cleaned_one = tf.strings.regex_replace(lowercase, replace_no_space, NO_SPACE) # Limpia los signos de puntuacion\n",
    "    print(cleaned_one[0])\n",
    "    cleaned_two = tf.strings.regex_replace(cleaned_one, replace_with_space, SPACE) # quita caracteres raros\n",
    "    print(cleaned_two[0])\n",
    "    cleaned_three = tf.strings.regex_replace(cleaned_two, re_expression,SPACE) # \"quita\" las stopwords\n",
    "    #print(cleaned_three[0])\n",
    "    return cleaned_three\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_vec_layer_tf_idf = tf.keras.layers.TextVectorization(output_mode=\"count\", standardize = clean_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(1,), dtype=string)\n",
      "Tensor(\"strided_slice_1:0\", shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "clean_text_vec_layer_tf_idf.adapt(df_X.sideEffectsReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'cough hypotension  proteinuria impotence  renal failure  angina pectoris  tachycardia  eosinophilic pneumonitis tastes disturbances  anusease anorecia  weakness fatigue insominca weakness', shape=(), dtype=string)\n",
      "tf.Tensor(b'cough hypotension  proteinuria impotence  renal failure  angina pectoris  tachycardia  eosinophilic pneumonitis tastes disturbances  anusease anorecia  weakness fatigue insominca weakness', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "vectors = clean_text_vec_layer_tf_idf(df_X.sideEffectsReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       cough, hypotension , proteinuria, impotence , ...\n",
       "1       Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...\n",
       "2              Heavier bleeding and clotting than normal.\n",
       "3       Constipation, dry mouth and some mild dizzines...\n",
       "4       I felt extremely drugged and dopey.  Could not...\n",
       "                              ...                        \n",
       "3102    Restless legs at night, insomnia, headache (so...\n",
       "3103    Weight gain, extreme tiredness during the day,...\n",
       "3104    Constant issues with the patch not staying on....\n",
       "3105                           Dizziness, fatigue, nausea\n",
       "3106    I find when I am taking Micardis that I tend t...\n",
       "Name: sideEffectsReview, Length: 3107, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.sideEffectsReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame(vectors.numpy(), columns= clean_text_vec_layer_tf_idf.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[UNK]</th>\n",
       "      <th>the</th>\n",
       "      <th>i</th>\n",
       "      <th>side</th>\n",
       "      <th>effects</th>\n",
       "      <th>a</th>\n",
       "      <th>my</th>\n",
       "      <th>was</th>\n",
       "      <th>taking</th>\n",
       "      <th>have</th>\n",
       "      <th>...</th>\n",
       "      <th>'emerging</th>\n",
       "      <th>'effective'</th>\n",
       "      <th>'coursing'</th>\n",
       "      <th>'cool'</th>\n",
       "      <th>'buzz'</th>\n",
       "      <th>'bug'</th>\n",
       "      <th>'blah'</th>\n",
       "      <th>'asshole'</th>\n",
       "      <th>$million</th>\n",
       "      <th>#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3107 rows × 7083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      [UNK]  the    i  side  effects    a   my  was  taking  have  ...  \\\n",
       "0       0.0  0.0  0.0   0.0      0.0  0.0  0.0  0.0     0.0   0.0  ...   \n",
       "1       0.0  2.0  0.0   0.0      0.0  1.0  0.0  0.0     0.0   0.0  ...   \n",
       "2       0.0  0.0  0.0   0.0      0.0  0.0  0.0  0.0     0.0   0.0  ...   \n",
       "3       0.0  0.0  0.0   0.0      0.0  1.0  0.0  0.0     0.0   0.0  ...   \n",
       "4       0.0  0.0  0.0   0.0      0.0  0.0  0.0  0.0     0.0   0.0  ...   \n",
       "...     ...  ...  ...   ...      ...  ...  ...  ...     ...   ...  ...   \n",
       "3102    0.0  0.0  0.0   0.0      0.0  0.0  0.0  0.0     0.0   0.0  ...   \n",
       "3103    0.0  1.0  0.0   0.0      0.0  0.0  0.0  0.0     0.0   0.0  ...   \n",
       "3104    0.0  3.0  1.0   0.0      0.0  0.0  4.0  0.0     0.0   1.0  ...   \n",
       "3105    0.0  0.0  0.0   0.0      0.0  0.0  0.0  0.0     0.0   0.0  ...   \n",
       "3106    0.0  0.0  2.0   0.0      0.0  0.0  1.0  0.0     1.0   0.0  ...   \n",
       "\n",
       "      'emerging  'effective'  'coursing'  'cool'  'buzz'  'bug'  'blah'  \\\n",
       "0           0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "1           0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "2           0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "3           0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "4           0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "...         ...          ...         ...     ...     ...    ...     ...   \n",
       "3102        0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "3103        0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "3104        0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "3105        0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "3106        0.0          0.0         0.0     0.0     0.0    0.0     0.0   \n",
       "\n",
       "      'asshole'  $million    #  \n",
       "0           0.0       0.0  0.0  \n",
       "1           0.0       0.0  0.0  \n",
       "2           0.0       0.0  0.0  \n",
       "3           0.0       0.0  0.0  \n",
       "4           0.0       0.0  0.0  \n",
       "...         ...       ...  ...  \n",
       "3102        0.0       0.0  0.0  \n",
       "3103        0.0       0.0  0.0  \n",
       "3104        0.0       0.0  0.0  \n",
       "3105        0.0       0.0  0.0  \n",
       "3106        0.0       0.0  0.0  \n",
       "\n",
       "[3107 rows x 7083 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = df_vectors.copy()\n",
    "y_train_vectors = df_target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\", input_shape = X_train_vectors.shape[1:]),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate= 1e-3, momentum = 0.09, nesterov = True),\\\n",
    "              metrics =[\"acc\"])\n",
    "history = model.fit(X_train_vectors.to_numpy(), y_train_vectors.to_numpy(), validation_split = 0.2, epochs=100, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.961522</td>\n",
       "      <td>0.308652</td>\n",
       "      <td>2.049788</td>\n",
       "      <td>0.273312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.959983</td>\n",
       "      <td>0.308250</td>\n",
       "      <td>2.048953</td>\n",
       "      <td>0.276527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.958426</td>\n",
       "      <td>0.309054</td>\n",
       "      <td>2.048133</td>\n",
       "      <td>0.276527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.956905</td>\n",
       "      <td>0.309457</td>\n",
       "      <td>2.047332</td>\n",
       "      <td>0.276527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.955366</td>\n",
       "      <td>0.309457</td>\n",
       "      <td>2.046525</td>\n",
       "      <td>0.276527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       acc  val_loss   val_acc\n",
       "95  1.961522  0.308652  2.049788  0.273312\n",
       "96  1.959983  0.308250  2.048953  0.276527\n",
       "97  1.958426  0.309054  2.048133  0.276527\n",
       "98  1.956905  0.309457  2.047332  0.276527\n",
       "99  1.955366  0.309457  2.046525  0.276527"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3107, 7083)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Sales', 'Production', 'benefitsReview_wc', 'sideEffectsReview_wc', 'commentsReview_wc']]\n"
     ]
    }
   ],
   "source": [
    "numericas = [col for col in df_X.columns if df_X[col].dtype != \"object\"]\n",
    "print([numericas])\n",
    "X_num = pd.concat([df_X[numericas].reset_index(),df_vectors], axis = 1)\n",
    "y_train = df_target.copy()\n",
    "X_train = X_num[:2400].to_numpy()\n",
    "y_train = y_num[:2400].to_numpy()\n",
    "X_valid = X_num[2400:].to_numpy()\n",
    "y_valid = y_num[2400:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 3.18440e+05, 3.98000e+02, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [1.00000e+00, 8.88949e+05, 9.09000e+02, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [2.00000e+00, 2.64077e+05, 4.65000e+02, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [2.39700e+03, 6.07030e+05, 7.47000e+02, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [2.39800e+03, 7.89800e+03, 6.80000e+01, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [2.39900e+03, 9.78193e+05, 1.03800e+03, ..., 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "model = tf.keras.models.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \\\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate= 1e-3, momentum = 0.09, nesterov = True),\\\n",
    "              metrics =[\"acc\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train,validation_data=(X_valid, y_valid), epochs=100, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.400767</td>\n",
       "      <td>0.892917</td>\n",
       "      <td>314135.25000</td>\n",
       "      <td>0.233380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.399127</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>314437.87500</td>\n",
       "      <td>0.233380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.397523</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>314738.71875</td>\n",
       "      <td>0.233380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.395928</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>315038.28125</td>\n",
       "      <td>0.233380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.394372</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>315336.37500</td>\n",
       "      <td>0.231966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       acc      val_loss   val_acc\n",
       "95  0.400767  0.892917  314135.25000  0.233380\n",
       "96  0.399127  0.893750  314437.87500  0.233380\n",
       "97  0.397523  0.893750  314738.71875  0.233380\n",
       "98  0.395928  0.894167  315038.28125  0.233380\n",
       "99  0.394372  0.893750  315336.37500  0.231966"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Demasiadas dimensiones? (7000+), quizás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, un embedding es una representación compacta de un conjunto de datos de mayor dimensionalidad pero dispersos. Por ejemlo un one_hot encoding de una categorica con las capitales del mundo daría vectores de 195 dimesniones, con únicamente un 1 y 194 ceros... Podríamos intentar convertir cada capital en un vector de dos dimensiones (eso sería hacerle un embedding. Pero veamoslo aplicado al lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secuencias de índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La representación de frases de texto con la vectorización que hemos visto hasta ahora tiene dos inconvenientes:  \n",
    "\n",
    "1. En función del tamaño del vocabulario, resulta un representación muy dispersa.\n",
    "2. No conserva información de orden.\n",
    "\n",
    "Una posible forma de representar frases, que no vimos cuando tratamos NLP tradicional (que cucos), es convertir cada palabra de un vocabulario en un indice y cada frase en una secuencia de indices de ese vocabulario:\n",
    "\n",
    "Suponiendo un vocabulario con 1000 palabras en el que:   \n",
    "Me -> es la palabra 734  \n",
    "llamo -> es la palabra 124,  \n",
    "Iñigo -> es la palabra 343,  \n",
    "Montoya -> es la palabra 99,  \n",
    "tú -> es la palabra 2,  \n",
    "mataste -> la 643,  \n",
    "a -> la 1,  \n",
    "mi -> la 23,  \n",
    "padre -> la 15  \n",
    "  \n",
    "* \"Me llamo Iñigo Montoya\" se transformaría en [734 \"Me\",124 \"llamo\" ,343 \"Iñigo\" ,99 \"Montoya\"]  (longitud = 4)\n",
    "* \"Tú mataste a mi padre\" se transformaría en [2,643,1,23,15] (longitud = 5)\n",
    "\n",
    "  \n",
    "Con esta \"codificación\"/vectorización, ya lo tendríamos todo, ¿no?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La representación anterior tiene dos problemas (relacionados):\n",
    "    1. No existe relación entre los indices y las palabras (o puede existirlo pero sólo tenemo una dimensión para representarla) \n",
    "    2. Al no existir esta relación un regresor (una neurona en una capa DL, por ejemplo), aplicaría un único peso para todas las palabras (están representadas por una única feature)\n",
    "    \n",
    "Una solución es convertir las palabras en vectores y crear esa representación en vectores de forma que palabras parecidas o que tengan relación (por ejemplo sinónimos, palabras que pertenecen a un mismo campo semántico, etc) generasen vectores que tuvieran relación (en general, estuvieran próximos, a más dimensiones más formas de estar próximos :-).\n",
    "\n",
    "Nuestras frases se converterían en secuencias (multivariantes, sí) del tipo:  \n",
    "\"Me llamo Iñigo Montoya\" -> [ [12,3,12] \"Me\" , [0, -12,1,-123] \"llamo\", [111,0,111,1] \"Iñigo\", [-1,-1,-2,112] \"Montoya\"]\n",
    "\n",
    "Los word embeddings son la forma de conseguirlo. Pero, ¿cómo construir un word embedding? (O sea que Iñigo pase de ser el 343 a un vector como [111,0,111,1].. Que lo aprenda la red :-)\n",
    "\n",
    "Una capa de embedding es una capa que se coloca al principio con pesos inicializados alaetoriamente y cuya salida es la representación de cada palabra en un vector de dimensión que se le da de entrada (es un hiperparámetro). De esta forma aprende la representación más adecuada para el problema en cuestión. Pero...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2013 (Efficient Estimation of Word Representations in Vector Space)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde 1960 que se plantean mecanismos para convertir la representación de palabras en vectores, pero la cosa de verdad estalló en 2013 cuando unos investigadores de (adivina,sí, Google) propusieron una forma de construir esos embeddings.  \n",
    "Básicamente entrenaron una red neuronal sobre un dataset muy grande de texto. El objetivo predecir que palabras acompañaban (por delante y detrás) a otra. Las capas dedicadas aprendieron representaciones de las palabras bastante espectaculares. Habían conseguido un embedding muy potente, y... como son capas podemos incluirlos en nuestros modelos gracias al transfer learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/embeddings.png\" alt=\"Diagram of one-hot encodings\" width=\"1000\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo operando los vectores obtenidos con King,Man y Woman como Vking - VMan + VWoman el resultado es un vector que está muy próximo al vector obtenido con Queen.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera haciéndolo con Madrid - Spain + France, el resultado es un vector muy próximo al vector que produce ... Paris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde ese momento, el uso de embeddings en las tareas de NLP con DL viene por defecto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KERAS EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras proporciona una capa de Embeddings (entrenable), aunque también es posible bajarse embeddings preentrenados y adaptarlos a nuestro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer un pequeño ejemplo de como funciona, y en el siguiente notebook construiremos el modelo de predicción que ya hicimos con NLP tradicional sobre la base de datos de reviews de Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_ejemplo = [\"Me\",\"llamo\",\"Iñigo\",\"Montoya\",\"soy\",\"tú\",\"mataste\",\"a\",\"mi\",\"padre\"]\n",
    "pre_conversion = tf.keras.layers.StringLookup() # Hay que convertir nuestro vocabulario a indices\n",
    "pre_conversion.adapt(categorias_ejemplo)\n",
    "lookup_y_embedding = tf.keras.Sequential([\\\n",
    "                                          tf.keras.layers.InputLayer(input_shape=[], dtype=tf.string), \n",
    "                                          pre_conversion,\n",
    "                                          tf.keras.layers.Embedding(input_dim = pre_conversion.vocabulary_size(),\n",
    "                                                                   output_dim = 2)])\n",
    "# input_dim -> Tamaño del vocabulario a convertir en vectores de output_dim dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 2), dtype=float32, numpy=\n",
       "array([[[ 0.04604291, -0.02598288],\n",
       "        [ 0.04039853, -0.03119655],\n",
       "        [-0.00592728,  0.04219984],\n",
       "        [ 0.03060097, -0.034375  ],\n",
       "        [ 0.0383018 ,  0.02832749],\n",
       "        [ 0.00023763, -0.00343919],\n",
       "        [-0.03366919,  0.02914692],\n",
       "        [-0.00399958, -0.04371947],\n",
       "        [-0.00220978,  0.00620984],\n",
       "        [-0.01796765, -0.03476111]]], dtype=float32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_y_embedding(np.array([categorias_ejemplo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 2), dtype=float32, numpy=\n",
       "array([[[ 0.04604291, -0.02598288],\n",
       "        [ 0.04039853, -0.03119655],\n",
       "        [-0.00592728,  0.04219984],\n",
       "        [ 0.03060097, -0.034375  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = \"Me llamo Iñigo Montoya\"\n",
    "lookup_y_embedding(np.array([frase.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AJUSTANDO REDES DL PARA NLP DE CLASIFICACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga la información de reviews de IMDB tal y como hemos hecho en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../aclImdb/train\"\n",
    "shutil.rmtree(dataset_dir + \"/unsup\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye los datasets de train, validation y test igual que en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "seed = 123\n",
    "\n",
    "\n",
    "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation', # Esto y la semilla permiten que las muestras con train no se superpongan\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye la capa de vectorización para que ahora extraiga ella el tamaño de la secuencia a partir del dataset de entrada.\n",
    "Adaptala al dataset de entrada, recuerda que tienes que crearte otro que no tenga el target incluido (en el notebook de clase tienes cómo hacerlo con una función lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\glezr\\Deep_Learning\\BootCamp\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data) # lo convierte a mayúsculas\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ') # le quita los codigos de cambio de línea\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '') #le quita los signos de puntuación\n",
    "\n",
    "\n",
    "vocab_size = 10000 \n",
    "\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int')\n",
    "    #output_sequence_length=sequence_length)\n",
    "\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye el modelo sin recurrentes que vimos en clase, pero haz que el número de neuronas de la capa densa que hace la regresión dependa de una variable (por ejemplo num_dense_neurons). Inicializa esta variable igualandola al número de dimensiones del embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=16\n",
    "tune_parameter = 1\n",
    "num_dense_neurons = embedding_dim * tune_parameter\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "  vectorize_layer, # 100 [1, 3, 4, 4, 90, ...]\n",
    "  Embedding(vocab_size, embedding_dim, name=\"embedding\"), # 10.000 x 16 --> [[], [], [] ...] 100x16\n",
    "  GlobalAveragePooling1D(), # [] 16\n",
    "  Dense(num_dense_neurons, activation='relu'), # \n",
    "  Dense(1) # originalmente no tiene activacion\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compila y entrena con la misma configuración de dimensiones de embedding y tamaño de vocabulario que en clase (10000), y el mismo número de épocas (15). Pista: Es posible que el tamaño de la secuencia le afecte, si es así tendrás que añadir algo a la definición del modelo y volver a compilar y entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              # binary_crossentropy\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 15s 742ms/step - loss: 0.6930 - accuracy: 0.5028 - val_loss: 0.6930 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 5s 276ms/step - loss: 0.6927 - accuracy: 0.5028 - val_loss: 0.6925 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 5s 268ms/step - loss: 0.6920 - accuracy: 0.5028 - val_loss: 0.6913 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 5s 264ms/step - loss: 0.6909 - accuracy: 0.5028 - val_loss: 0.6897 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 5s 263ms/step - loss: 0.6891 - accuracy: 0.5028 - val_loss: 0.6872 - val_accuracy: 0.4886\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 6s 281ms/step - loss: 0.6865 - accuracy: 0.5028 - val_loss: 0.6835 - val_accuracy: 0.4886\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 6s 291ms/step - loss: 0.6825 - accuracy: 0.5028 - val_loss: 0.6779 - val_accuracy: 0.4886\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 5s 275ms/step - loss: 0.6768 - accuracy: 0.5029 - val_loss: 0.6702 - val_accuracy: 0.4888\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 5s 267ms/step - loss: 0.6691 - accuracy: 0.5036 - val_loss: 0.6602 - val_accuracy: 0.4924\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 6s 279ms/step - loss: 0.6593 - accuracy: 0.5105 - val_loss: 0.6477 - val_accuracy: 0.5044\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 6s 287ms/step - loss: 0.6472 - accuracy: 0.5245 - val_loss: 0.6326 - val_accuracy: 0.5224\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 5s 278ms/step - loss: 0.6330 - accuracy: 0.5391 - val_loss: 0.6155 - val_accuracy: 0.5476\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 6s 284ms/step - loss: 0.6170 - accuracy: 0.5580 - val_loss: 0.5968 - val_accuracy: 0.5810\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 6s 303ms/step - loss: 0.5997 - accuracy: 0.5817 - val_loss: 0.5773 - val_accuracy: 0.6202\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 6s 278ms/step - loss: 0.5814 - accuracy: 0.6052 - val_loss: 0.5575 - val_accuracy: 0.6514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22cd600e740>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "  vectorize_layer, # 100 [1, 3, 4, 4, 90, ...]\n",
    "  Embedding(vocab_size, embedding_dim, name=\"embedding\", mask_zero = True), # 10.000 x 16 --> [[], [], [] ...] 100x16\n",
    "  GlobalAveragePooling1D(), # [] 16\n",
    "  Dense(num_dense_neurons, activation='relu'), # \n",
    "  Dense(1) # originalmente no tiene activacion\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              # binary_crossentropy\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 7s 301ms/step - loss: 0.6917 - accuracy: 0.5028 - val_loss: 0.6895 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 6s 284ms/step - loss: 0.6862 - accuracy: 0.5028 - val_loss: 0.6825 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 6s 292ms/step - loss: 0.6768 - accuracy: 0.5028 - val_loss: 0.6704 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 6s 296ms/step - loss: 0.6607 - accuracy: 0.5028 - val_loss: 0.6515 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 6s 303ms/step - loss: 0.6375 - accuracy: 0.5030 - val_loss: 0.6257 - val_accuracy: 0.4894\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 6s 300ms/step - loss: 0.6072 - accuracy: 0.5252 - val_loss: 0.5937 - val_accuracy: 0.5506\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 6s 284ms/step - loss: 0.5710 - accuracy: 0.6169 - val_loss: 0.5573 - val_accuracy: 0.6316\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 6s 297ms/step - loss: 0.5313 - accuracy: 0.6970 - val_loss: 0.5192 - val_accuracy: 0.6976\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.4909 - accuracy: 0.7550 - val_loss: 0.4823 - val_accuracy: 0.7470\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 6s 296ms/step - loss: 0.4523 - accuracy: 0.7953 - val_loss: 0.4485 - val_accuracy: 0.7800\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 6s 288ms/step - loss: 0.4174 - accuracy: 0.8213 - val_loss: 0.4189 - val_accuracy: 0.8032\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.3866 - accuracy: 0.8383 - val_loss: 0.3938 - val_accuracy: 0.8206\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 6s 299ms/step - loss: 0.3600 - accuracy: 0.8528 - val_loss: 0.3728 - val_accuracy: 0.8348\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 6s 281ms/step - loss: 0.3370 - accuracy: 0.8632 - val_loss: 0.3553 - val_accuracy: 0.8442\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 6s 303ms/step - loss: 0.3171 - accuracy: 0.8730 - val_loss: 0.3408 - val_accuracy: 0.8496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22cd7512470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalua el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    train_dir.replace(\"train\",\"test\"),\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 32s 942ms/step - loss: 0.3595 - accuracy: 0.8339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3594972789287567, 0.8339499831199646]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora juega con las dimensiones de salida de la capa de embedding y con el número de neuronas de la capa densa (siempre como un factor de las dimensiones de emmbeding) y logra que el modelo tenga una accuracy superior al 85% en validación en test. NO JUEGUES CON LAS EPOCAS, todavía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Model_e_16_neurons_16\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 7s 298ms/step - loss: 0.6923 - accuracy: 0.5028 - val_loss: 0.6911 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 6s 287ms/step - loss: 0.6886 - accuracy: 0.5028 - val_loss: 0.6863 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 6s 295ms/step - loss: 0.6821 - accuracy: 0.5028 - val_loss: 0.6783 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 6s 301ms/step - loss: 0.6712 - accuracy: 0.5028 - val_loss: 0.6647 - val_accuracy: 0.4886\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 6s 293ms/step - loss: 0.6538 - accuracy: 0.5028 - val_loss: 0.6449 - val_accuracy: 0.4886\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 6s 294ms/step - loss: 0.6297 - accuracy: 0.5028 - val_loss: 0.6189 - val_accuracy: 0.4886\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 6s 301ms/step - loss: 0.5996 - accuracy: 0.5102 - val_loss: 0.5876 - val_accuracy: 0.5278\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 5s 275ms/step - loss: 0.5639 - accuracy: 0.6037 - val_loss: 0.5512 - val_accuracy: 0.6226\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 6s 286ms/step - loss: 0.5239 - accuracy: 0.6894 - val_loss: 0.5131 - val_accuracy: 0.6872\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 6s 292ms/step - loss: 0.4835 - accuracy: 0.7484 - val_loss: 0.4763 - val_accuracy: 0.7410\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 6s 282ms/step - loss: 0.4454 - accuracy: 0.7904 - val_loss: 0.4430 - val_accuracy: 0.7742\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 6s 287ms/step - loss: 0.4110 - accuracy: 0.8201 - val_loss: 0.4140 - val_accuracy: 0.8016\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 6s 289ms/step - loss: 0.3808 - accuracy: 0.8385 - val_loss: 0.3894 - val_accuracy: 0.8206\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 6s 291ms/step - loss: 0.3546 - accuracy: 0.8538 - val_loss: 0.3688 - val_accuracy: 0.8356\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.3320 - accuracy: 0.8652 - val_loss: 0.3517 - val_accuracy: 0.8448\n",
      "20/20 [==============================] - 6s 183ms/step - loss: 0.3691 - accuracy: 0.8276\n",
      "Accuaracy: 0.8276000022888184\n",
      "Modelo Model_e_32_neurons_32\n",
      "Epoch 1/15\n",
      "20/20 [==============================] - 8s 351ms/step - loss: 0.6911 - accuracy: 0.5028 - val_loss: 0.6877 - val_accuracy: 0.4886\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 7s 335ms/step - loss: 0.6817 - accuracy: 0.5028 - val_loss: 0.6740 - val_accuracy: 0.4886\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 7s 344ms/step - loss: 0.6622 - accuracy: 0.5028 - val_loss: 0.6486 - val_accuracy: 0.4886\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 7s 327ms/step - loss: 0.6288 - accuracy: 0.5056 - val_loss: 0.6092 - val_accuracy: 0.5130\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 7s 339ms/step - loss: 0.5814 - accuracy: 0.5983 - val_loss: 0.5583 - val_accuracy: 0.6348\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 7s 334ms/step - loss: 0.5244 - accuracy: 0.7135 - val_loss: 0.5026 - val_accuracy: 0.7248\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 7s 348ms/step - loss: 0.4656 - accuracy: 0.7841 - val_loss: 0.4499 - val_accuracy: 0.7802\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 6s 327ms/step - loss: 0.4122 - accuracy: 0.8243 - val_loss: 0.4058 - val_accuracy: 0.8140\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 7s 332ms/step - loss: 0.3679 - accuracy: 0.8478 - val_loss: 0.3717 - val_accuracy: 0.8374\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 7s 349ms/step - loss: 0.3325 - accuracy: 0.8658 - val_loss: 0.3460 - val_accuracy: 0.8484\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 7s 348ms/step - loss: 0.3040 - accuracy: 0.8775 - val_loss: 0.3266 - val_accuracy: 0.8564\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 7s 352ms/step - loss: 0.2806 - accuracy: 0.8882 - val_loss: 0.3118 - val_accuracy: 0.8634\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 7s 343ms/step - loss: 0.2609 - accuracy: 0.8971 - val_loss: 0.3004 - val_accuracy: 0.8688\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 7s 347ms/step - loss: 0.2440 - accuracy: 0.9055 - val_loss: 0.2915 - val_accuracy: 0.8724\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 7s 342ms/step - loss: 0.2293 - accuracy: 0.9126 - val_loss: 0.2846 - val_accuracy: 0.8772\n",
      "20/20 [==============================] - 6s 219ms/step - loss: 0.3060 - accuracy: 0.8625\n",
      "Accuaracy: 0.862500011920929\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'opt_embedding_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m acc_test \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m desired_acc:\n\u001b[0;32m     29\u001b[0m     opt_embedding_dims \u001b[39m=\u001b[39m embedding_dims \n\u001b[1;32m---> 30\u001b[0m     opt_num_neurons \u001b[39m=\u001b[39m opt_embedding_dim \u001b[39m*\u001b[39m tune_parameters\n\u001b[0;32m     31\u001b[0m     end \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'opt_embedding_dim' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_dims = 16\n",
    "tune_parameter = 1\n",
    "num_dense_neurons = embedding_dim * tune_parameter\n",
    "desired_acc = 0.85\n",
    "\n",
    "end = False\n",
    "for tune_parameters in range(1,2,4):\n",
    "  for embeddings in [embedding_dim * i for i in [1,2,4]]:\n",
    "      index = \"Model_e_%d_neurons_%d\" %(embeddings, tune_parameter * embeddings)\n",
    "      print(\"Modelo %s\" %(index))\n",
    "      num_dense_neurons = embeddings * tune_parameters\n",
    "      model = Sequential([\n",
    "        vectorize_layer, # 100 [1, 3, 4, 4, 90, ...]\n",
    "        Embedding(vocab_size, embeddings, name=\"embedding\", mask_zero = True), # 10.000 x 16 --> [[], [], [] ...] 100x16\n",
    "        GlobalAveragePooling1D(), # [] 16\n",
    "        Dense(num_dense_neurons, activation='relu'), # \n",
    "        Dense(1) # originalmente no tiene activacion\n",
    "      ])\n",
    "      model.compile(optimizer='adam',\n",
    "            # binary_crossentropy\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "      model.fit( train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=15)            \n",
    "      loss_test, acc_test = model.evaluate(test_ds) \n",
    "      print(\"Accuracy:\",acc_test)   \n",
    "      if acc_test >= desired_acc:\n",
    "          opt_embedding_dims = embedding_dims \n",
    "          opt_num_neurons = opt_embedding_dims * tune_parameters\n",
    "          end = True\n",
    "          break\n",
    "  if end:\n",
    "     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_num_neurons = opt_embedding_dims * tune_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumenta el número de épocas hasta conseguir la mejor accuracy posible con la configuración de embeddings y neuronas del paso anterior. Hazlo en un solo entrenamiento (pista, tendrás que usar un callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "20/20 [==============================] - 4s 160ms/step - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6929 - val_accuracy: 0.4886\n",
      "Epoch 2/1500\n",
      "20/20 [==============================] - 3s 157ms/step - loss: 0.6923 - accuracy: 0.5028 - val_loss: 0.6919 - val_accuracy: 0.4886\n",
      "Epoch 3/1500\n",
      "20/20 [==============================] - 3s 154ms/step - loss: 0.6914 - accuracy: 0.5028 - val_loss: 0.6905 - val_accuracy: 0.4886\n",
      "Epoch 4/1500\n",
      "20/20 [==============================] - 3s 155ms/step - loss: 0.6900 - accuracy: 0.5028 - val_loss: 0.6887 - val_accuracy: 0.4886\n",
      "Epoch 5/1500\n",
      "20/20 [==============================] - 3s 155ms/step - loss: 0.6880 - accuracy: 0.5028 - val_loss: 0.6857 - val_accuracy: 0.4886\n",
      "Epoch 6/1500\n",
      "20/20 [==============================] - 3s 158ms/step - loss: 0.6849 - accuracy: 0.5028 - val_loss: 0.6814 - val_accuracy: 0.4886\n",
      "Epoch 7/1500\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.6805 - accuracy: 0.5028 - val_loss: 0.6756 - val_accuracy: 0.4886\n",
      "Epoch 8/1500\n",
      "20/20 [==============================] - 3s 159ms/step - loss: 0.6746 - accuracy: 0.5028 - val_loss: 0.6678 - val_accuracy: 0.4886\n",
      "Epoch 9/1500\n",
      "20/20 [==============================] - 3s 160ms/step - loss: 0.6669 - accuracy: 0.5028 - val_loss: 0.6580 - val_accuracy: 0.4888\n",
      "Epoch 10/1500\n",
      "20/20 [==============================] - 3s 157ms/step - loss: 0.6572 - accuracy: 0.5034 - val_loss: 0.6460 - val_accuracy: 0.4918\n",
      "Epoch 11/1500\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.6457 - accuracy: 0.5088 - val_loss: 0.6320 - val_accuracy: 0.5036\n",
      "Epoch 12/1500\n",
      "20/20 [==============================] - 3s 156ms/step - loss: 0.6325 - accuracy: 0.5286 - val_loss: 0.6161 - val_accuracy: 0.5296\n",
      "Epoch 13/1500\n",
      "20/20 [==============================] - 3s 162ms/step - loss: 0.6177 - accuracy: 0.5462 - val_loss: 0.5989 - val_accuracy: 0.5604\n",
      "Epoch 14/1500\n",
      "20/20 [==============================] - 3s 161ms/step - loss: 0.6018 - accuracy: 0.5682 - val_loss: 0.5808 - val_accuracy: 0.5934\n",
      "Epoch 15/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.5849 - accuracy: 0.5921 - val_loss: 0.5623 - val_accuracy: 0.6276\n",
      "Epoch 16/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.5675 - accuracy: 0.6166 - val_loss: 0.5438 - val_accuracy: 0.6578\n",
      "Epoch 17/1500\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.5498 - accuracy: 0.6423 - val_loss: 0.5253 - val_accuracy: 0.6852\n",
      "Epoch 18/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.5321 - accuracy: 0.6691 - val_loss: 0.5072 - val_accuracy: 0.7148\n",
      "Epoch 19/1500\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.5145 - accuracy: 0.6939 - val_loss: 0.4896 - val_accuracy: 0.7334\n",
      "Epoch 20/1500\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.4974 - accuracy: 0.7171 - val_loss: 0.4728 - val_accuracy: 0.7512\n",
      "Epoch 21/1500\n",
      "20/20 [==============================] - 4s 183ms/step - loss: 0.4808 - accuracy: 0.7388 - val_loss: 0.4569 - val_accuracy: 0.7686\n",
      "Epoch 22/1500\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.4649 - accuracy: 0.7577 - val_loss: 0.4419 - val_accuracy: 0.7802\n",
      "Epoch 23/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.4497 - accuracy: 0.7752 - val_loss: 0.4280 - val_accuracy: 0.7952\n",
      "Epoch 24/1500\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.4353 - accuracy: 0.7889 - val_loss: 0.4151 - val_accuracy: 0.8096\n",
      "Epoch 25/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.4216 - accuracy: 0.8012 - val_loss: 0.4031 - val_accuracy: 0.8194\n",
      "Epoch 26/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.4088 - accuracy: 0.8112 - val_loss: 0.3922 - val_accuracy: 0.8268\n",
      "Epoch 27/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.3967 - accuracy: 0.8201 - val_loss: 0.3822 - val_accuracy: 0.8314\n",
      "Epoch 28/1500\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.3854 - accuracy: 0.8280 - val_loss: 0.3730 - val_accuracy: 0.8352\n",
      "Epoch 29/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.3748 - accuracy: 0.8357 - val_loss: 0.3647 - val_accuracy: 0.8406\n",
      "Epoch 30/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.3648 - accuracy: 0.8429 - val_loss: 0.3571 - val_accuracy: 0.8466\n",
      "Epoch 31/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.3554 - accuracy: 0.8487 - val_loss: 0.3502 - val_accuracy: 0.8488\n",
      "Epoch 32/1500\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.3466 - accuracy: 0.8540 - val_loss: 0.3438 - val_accuracy: 0.8536\n",
      "Epoch 33/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.3382 - accuracy: 0.8594 - val_loss: 0.3381 - val_accuracy: 0.8556\n",
      "Epoch 34/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.3304 - accuracy: 0.8648 - val_loss: 0.3328 - val_accuracy: 0.8576\n",
      "Epoch 35/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.3229 - accuracy: 0.8684 - val_loss: 0.3279 - val_accuracy: 0.8600\n",
      "Epoch 36/1500\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.3158 - accuracy: 0.8727 - val_loss: 0.3235 - val_accuracy: 0.8616\n",
      "Epoch 37/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.3091 - accuracy: 0.8766 - val_loss: 0.3194 - val_accuracy: 0.8638\n",
      "Epoch 38/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.3027 - accuracy: 0.8792 - val_loss: 0.3157 - val_accuracy: 0.8668\n",
      "Epoch 39/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.2965 - accuracy: 0.8820 - val_loss: 0.3122 - val_accuracy: 0.8680\n",
      "Epoch 40/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2907 - accuracy: 0.8849 - val_loss: 0.3091 - val_accuracy: 0.8688\n",
      "Epoch 41/1500\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.2851 - accuracy: 0.8877 - val_loss: 0.3062 - val_accuracy: 0.8698\n",
      "Epoch 42/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.2797 - accuracy: 0.8903 - val_loss: 0.3035 - val_accuracy: 0.8706\n",
      "Epoch 43/1500\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.2746 - accuracy: 0.8931 - val_loss: 0.3010 - val_accuracy: 0.8708\n",
      "Epoch 44/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.2696 - accuracy: 0.8953 - val_loss: 0.2988 - val_accuracy: 0.8724\n",
      "Epoch 45/1500\n",
      "20/20 [==============================] - 3s 167ms/step - loss: 0.2648 - accuracy: 0.8974 - val_loss: 0.2967 - val_accuracy: 0.8750\n",
      "Epoch 46/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.2603 - accuracy: 0.8993 - val_loss: 0.2948 - val_accuracy: 0.8756\n",
      "Epoch 47/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2558 - accuracy: 0.9014 - val_loss: 0.2930 - val_accuracy: 0.8760\n",
      "Epoch 48/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.2515 - accuracy: 0.9039 - val_loss: 0.2914 - val_accuracy: 0.8770\n",
      "Epoch 49/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.2474 - accuracy: 0.9054 - val_loss: 0.2899 - val_accuracy: 0.8772\n",
      "Epoch 50/1500\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.2434 - accuracy: 0.9072 - val_loss: 0.2886 - val_accuracy: 0.8774\n",
      "Epoch 51/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2395 - accuracy: 0.9090 - val_loss: 0.2874 - val_accuracy: 0.8782\n",
      "Epoch 52/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.2357 - accuracy: 0.9107 - val_loss: 0.2863 - val_accuracy: 0.8808\n",
      "Epoch 53/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.2321 - accuracy: 0.9117 - val_loss: 0.2853 - val_accuracy: 0.8804\n",
      "Epoch 54/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2285 - accuracy: 0.9136 - val_loss: 0.2844 - val_accuracy: 0.8816\n",
      "Epoch 55/1500\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 0.2251 - accuracy: 0.9151 - val_loss: 0.2836 - val_accuracy: 0.8810\n",
      "Epoch 56/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.2217 - accuracy: 0.9170 - val_loss: 0.2829 - val_accuracy: 0.8816\n",
      "Epoch 57/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.2184 - accuracy: 0.9184 - val_loss: 0.2822 - val_accuracy: 0.8822\n",
      "Epoch 58/1500\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.2153 - accuracy: 0.9201 - val_loss: 0.2817 - val_accuracy: 0.8828\n",
      "Epoch 59/1500\n",
      "20/20 [==============================] - 3s 166ms/step - loss: 0.2122 - accuracy: 0.9211 - val_loss: 0.2812 - val_accuracy: 0.8828\n",
      "Epoch 60/1500\n",
      "20/20 [==============================] - 3s 171ms/step - loss: 0.2091 - accuracy: 0.9225 - val_loss: 0.2808 - val_accuracy: 0.8832\n",
      "Epoch 61/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.2062 - accuracy: 0.9236 - val_loss: 0.2805 - val_accuracy: 0.8830\n",
      "Epoch 62/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.2033 - accuracy: 0.9247 - val_loss: 0.2803 - val_accuracy: 0.8840\n",
      "Epoch 63/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.2005 - accuracy: 0.9262 - val_loss: 0.2801 - val_accuracy: 0.8850\n",
      "Epoch 64/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1977 - accuracy: 0.9275 - val_loss: 0.2799 - val_accuracy: 0.8846\n",
      "Epoch 65/1500\n",
      "20/20 [==============================] - 4s 176ms/step - loss: 0.1950 - accuracy: 0.9288 - val_loss: 0.2798 - val_accuracy: 0.8854\n",
      "Epoch 66/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1924 - accuracy: 0.9299 - val_loss: 0.2798 - val_accuracy: 0.8854\n",
      "Epoch 67/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.1898 - accuracy: 0.9309 - val_loss: 0.2799 - val_accuracy: 0.8860\n",
      "Epoch 68/1500\n",
      "20/20 [==============================] - 3s 175ms/step - loss: 0.1873 - accuracy: 0.9323 - val_loss: 0.2800 - val_accuracy: 0.8868\n",
      "Epoch 69/1500\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.1848 - accuracy: 0.9334 - val_loss: 0.2801 - val_accuracy: 0.8880\n",
      "Epoch 70/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1823 - accuracy: 0.9348 - val_loss: 0.2803 - val_accuracy: 0.8876\n",
      "Epoch 71/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1799 - accuracy: 0.9360 - val_loss: 0.2806 - val_accuracy: 0.8874\n",
      "Epoch 72/1500\n",
      "20/20 [==============================] - 4s 177ms/step - loss: 0.1776 - accuracy: 0.9366 - val_loss: 0.2809 - val_accuracy: 0.8882\n",
      "Epoch 73/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1753 - accuracy: 0.9377 - val_loss: 0.2813 - val_accuracy: 0.8878\n",
      "Epoch 74/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.1731 - accuracy: 0.9385 - val_loss: 0.2817 - val_accuracy: 0.8878\n",
      "Epoch 75/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.1709 - accuracy: 0.9390 - val_loss: 0.2821 - val_accuracy: 0.8884\n",
      "Epoch 76/1500\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.1687 - accuracy: 0.9395 - val_loss: 0.2826 - val_accuracy: 0.8888\n",
      "Epoch 77/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.1666 - accuracy: 0.9404 - val_loss: 0.2832 - val_accuracy: 0.8886\n",
      "Epoch 78/1500\n",
      "20/20 [==============================] - 3s 168ms/step - loss: 0.1645 - accuracy: 0.9413 - val_loss: 0.2837 - val_accuracy: 0.8884\n",
      "Epoch 79/1500\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.1625 - accuracy: 0.9423 - val_loss: 0.2844 - val_accuracy: 0.8880\n",
      "Epoch 80/1500\n",
      "20/20 [==============================] - 3s 169ms/step - loss: 0.1605 - accuracy: 0.9434 - val_loss: 0.2850 - val_accuracy: 0.8876\n",
      "Epoch 81/1500\n",
      "20/20 [==============================] - 3s 170ms/step - loss: 0.1585 - accuracy: 0.9441 - val_loss: 0.2857 - val_accuracy: 0.8878\n",
      "Epoch 82/1500\n",
      "20/20 [==============================] - 3s 172ms/step - loss: 0.1566 - accuracy: 0.9449 - val_loss: 0.2864 - val_accuracy: 0.8880\n",
      "Epoch 83/1500\n",
      "20/20 [==============================] - 3s 174ms/step - loss: 0.1547 - accuracy: 0.9456 - val_loss: 0.2872 - val_accuracy: 0.8878\n",
      "Epoch 84/1500\n",
      "20/20 [==============================] - 4s 181ms/step - loss: 0.1529 - accuracy: 0.9463 - val_loss: 0.2880 - val_accuracy: 0.8884\n",
      "Epoch 85/1500\n",
      "20/20 [==============================] - 3s 173ms/step - loss: 0.1511 - accuracy: 0.9468 - val_loss: 0.2888 - val_accuracy: 0.8886\n",
      "Epoch 86/1500\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 0.1493 - accuracy: 0.9474 - val_loss: 0.2897 - val_accuracy: 0.8882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ce2716c20>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(patience = 10, monitor = \"val_accuracy\", restore_best_weights= True)\n",
    "model = Sequential([\n",
    "        vectorize_layer, # 100 [1, 3, 4, 4, 90, ...]\n",
    "        Embedding(vocab_size, opt_embedding_dims, name=\"embedding\"), # 10.000 x 16 --> [[], [], [] ...] 100x16\n",
    "        GlobalAveragePooling1D(), # [] 16\n",
    "        Dense(opt_num_neurons, activation='relu'), # \n",
    "        Dense(1) # originalmente no tiene activacion\n",
    "      ])\n",
    "model.compile(optimizer='adam',\n",
    "      # binary_crossentropy\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "      metrics=['accuracy'])\n",
    "model.fit( train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=1500,\n",
    "            callbacks=[early_stop])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalúalo contra test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 139ms/step - loss: 0.3115 - accuracy: 0.8728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31152093410491943, 0.8727999925613403]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOLUNTARIO\n",
    "Haz el mismo ejercicio utilizando una red recurrente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOL Breve: Cambiar la capa de Pooling y la densa por una GRU o una LSTM en todas las definiciones de modelos con número de celdas dependiente del embedding con un factor 4 de partida"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BootCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

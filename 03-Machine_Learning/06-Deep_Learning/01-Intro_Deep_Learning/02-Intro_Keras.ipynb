{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pabma\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pabma\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pabma\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: keras in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: optree in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras) (4.10.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pabma\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pabma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPor defecto, keras no tira de GPU\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "'''\n",
    "Por defecto, keras no tira de GPU\n",
    "'''\n",
    "#https://playground.tensorflow.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar y abrir VS Code si hace falta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[25000,12,18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays). Aplano a una dimension cada imagen.\n",
    "# Escalamos ya que vamos a usar gradient descent, y le afecta mucho la escala de las features.\n",
    "# Ejecutar esta celda solo una vez. Sino reescalará\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Reserve 10,000 samples for validation. Entraran dentro del modelo para validar. No es validacion cruzada\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINICION/CONSTRUCCION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax.  \n",
    "\n",
    "Es decir vamos a volver a montar esta arquitectura:  \n",
    "<img src=\"./img/mlp_clasification.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "Un poco más sobre la activación softmax:    \n",
    "\n",
    "Fórmula:  \n",
    "<img src=\"./img/softmax_function.png\" alt=\"drawing\" width=\"150\"/>\n",
    "\n",
    "Función de transferencia:  \n",
    "<img src=\"./img/softmax_activation.png\" alt=\"drawing\" width=\"150\"/>\n",
    "\n",
    "Ejemplo de funcionamiento:  \n",
    "<img src=\"./img/softmax_example.png\" alt=\"drawing\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una manera de declarar la red neuronal\n",
    "\n",
    "# Siempre hay que declarar la capa sequential para empezar a declarar la red\n",
    "# Se trata de la API sequential\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten, aplana en un unico vector. Y especificamos el tamaño de la entrada\n",
    "# Es como si hiciese un .reshape(-1, 28*28)\n",
    "# \"kernel_initializer\" o \"bias_initializer\" No lo usamos pero seria para inicializar los pesos de otra manera\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Capas de la red. Dense es la capa de neuronas. Necesitamos numero y activacion\n",
    "model.add(keras.layers.Dense(units = 300, # Numero de neuronas de la capa\n",
    "                             activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(100,\n",
    "                             activation='relu'))\n",
    "\n",
    "# Capa de salida, con tamaño del número de clases\n",
    "# Suele ir aqui un softmax. Para multiclase guay. Si es binaria -> sigmoide\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jonatan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(300, activation='selu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "]\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y una forma mediante encademaniento de funciones (usando lo que se denomina la Functional API)\n",
    "input_layer = keras.layers.Input(shape = (28,28))\n",
    "flatten_layer = keras.layers.Flatten()(input_layer)\n",
    "hidden_1 = keras.layers.Dense(300, activation = \"relu\")(flatten_layer)\n",
    "hidden_2 = keras.layers.Dense(100, activation = \"relu\")(hidden_1)\n",
    "output = keras.layers.Dense(10, activation = \"softmax\")(hidden_2)\n",
    "model = keras.Model(inputs = [input_layer], outputs = [output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten_5, built=True>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=input_layer_5, built=True>,\n",
       " <Flatten name=flatten_5, built=True>,\n",
       " <Dense name=dense_15, built=True>,\n",
       " <Dense name=dense_16, built=True>,\n",
       " <Dense name=dense_17, built=True>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[1])\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[2]\n",
    "weights, biases = hidden1.get_weights()\n",
    "\n",
    "# 784 features (pixeles de las imagenes) x 300 neuronas\n",
    "# Los pesos están inicializados aleatoriamente\n",
    "weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicializadores:  \n",
    "- Los pesos inicializados a cero -> No aprendizaje\n",
    "- Desde siempre se inicializan \"aleatoriamente\", pero no sólo de forma uniforme (todos los valores con la misma probabilidad), sino que se emplean diferentes distribuciones de probabilidad con parámetros que dependen del número de entradas y salidas de la capa. El objetivo esintentar que las varianzas de las entradas sean similares a las de las salidas y evitar el problema del gradiente que se desvanece (\"Vanishing Gradient\" problem):  \n",
    "    *   Glorot inizialization (por defecto la de Keras, con función uniforme de distribución) -> Para cuando tienes funciones de activación (ninguna, tanh, sigmoid, softmax, aunque también se usa por defecto :-) para casi todo) [Xavier Glorot & Yoshua Bengio]\n",
    "    *   He inizialization, -> Para cuando tienes ReLU, Leaky ReLU, ELU, GELU, Swish, Mish [He Kaiming et al.]\n",
    "    *   LeCunn inizialization -> Para cuando tienes SELU [Jean LeCunn]\n",
    "- Es un hiperparámetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se especifica la configuración del entrenamiento (optimizador, pérdida, métricas):\n",
    "model.compile(\n",
    "    # Stocastic gradient descent. El algoritmo para minimizar la loss function\n",
    "    # El stocastic va haciendo muestreo en cada evaluacion, no usa todo el dataset\n",
    "    # Podemos modificar el learning rate(0.01 por defecto) mediante el parametro lr\n",
    "    optimizer=keras.optimizers.SGD(),  # Optimizer, con parámetros por defecto\n",
    "    \n",
    "    \n",
    "    # Loss function to minimize\n",
    "    # sparse_categorical_crossentropy cuando tenemos un label en nuna columna\n",
    "    # Si lo tuviesemos en varias tipo dummy, cogeriamos categorical_crossentropy\n",
    "    # binary_crossentropy si es una neurona, clasi binario\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente (... casi, los parámetros del optimizador serán los que tenga por defecto)\n",
    "model.compile(optimizer=\"sgd\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "# La primera hidden layer tiene 784 entradas x 300 salidas\n",
    "# Son los 235500 params = 783x300 + 300 (bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CAPAS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vayamos construyendo nuestra __lista de capas__ (para guardar en el \"Toolbox\"):\n",
    "\n",
    "__Entrenables__:  \n",
    "__* Dense__ -> Capa completamente conectada a las neuronas de la capa anterior y a la posterior  \n",
    "    Hiperparámetros asociados:     \n",
    "        * units: Number of neurons, dimensionality of the output space  \n",
    "        * activation: Activation function to use. If you don't specify anything, no activation is applied  \n",
    "        * kernel_initializer: Initializer for the kernel weights matrix.  \n",
    "        * bias_initializer: Initializer for the bias vector. (Suelen inicializarse a cero)\n",
    "        * Kernel_regularizar: Los clásicos (L1,L2,...)\n",
    " \n",
    "__Funcionales__:       \n",
    "__* Input__ -> Capa para definir la forma de la entrada (shape), que se puede pasar como input_shape\n",
    "__* Flatten__ -> Capa que aplana (convierte su entrada en un vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras funciones de activación interesantes: SELU (1.67*ELU) y Swish (también SiLU, o Sigmoid linear unit)... No entrar en pánico, vais a usar ReLU, Softmax y no-activation, y en algunos casos (quizás): sigmoid, tanh y las (x)LU (SELU, Siwsh,etc)\n",
    "\n",
    "<img src=\"./img/activation_functions.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTIMIZADORES\n",
    "\n",
    "##### Ejemplo \"sencillo\" https://medium.com/@axegggl/newtons-method-for-optimization-in-python-11ce261fcf98"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y también vamos completando lista de hiperparámetros, estos asociados al \"Optimizador\"/\"Modelo\":  \n",
    "Tipo de optimizador:  \n",
    "* __SGD__, Gradient descent \"genérico\" (puedes añadirle \"momento\", es decir que a la hora de descontar el gradiente tenga en cuenta el vector medio de gradientes pasados)\n",
    "  \n",
    "\n",
    "* __Adagrad__, Hace gradient descent pero ajusta el gradiente para compensar las componentes de mayor valor numérico (es como evitar irse por las pendientes más inclinadas)... Es decir evita irse a mínimos locales al precio de enlentecer el entrenamiento.    \n",
    "\n",
    "* __RMSprop__, Versión de AdaGrad, pero considera principalmente los últimos valores del gradiente. Es decir, busca lo bueno de Adagrad reduciendo sus peligros.    \n",
    "\n",
    "* __Adam__, _Adaptative Moment Estimation_, combina RMSProp y el uso de momento. Es el rey actual (junto con sus versiones) para grandes cantidades de datos.    \n",
    "\n",
    "* __AdamW, Nadam, AdaMax__, variantes del anterior. \n",
    "\n",
    "Comparativa, donde * es malo y *** bueno (extraído del \"Hands-on Machine Learning with....\" de Aurelien Geron, 3a Edicion)\n",
    "\n",
    "<img src=\"./img/Comparativa-optimizadores.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "Keras también permite:\n",
    "__Adadelta__ _(variante de Adagrad)_, __Adafactor__ y __Ftrl__\n",
    "\n",
    "      \n",
    "Hiperparámetros Genéricos:\n",
    "Learning Rate: Coeficiente aplicado al descenso de gradiente, como en otros modelos que ya hemos visto\n",
    "Asociados al Gradient Clipping: clipnorm, clipvalue, global_clipnorm\n",
    "\n",
    "Cada optimizador además puede tener sus propios hiperparámetros (ver: https://keras.io/api/optimizers/)\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuciones de pérdida y métricas\n",
    "__Función de perdida__: La función a minimizar durante el entrenamiento (son las mismas que en otros modelos no Deep)  \n",
    "- Clasificación: En clases Keras -> __BinaryCrossEntropy, CategoricalCrossEntropy, SparseCategoricalCrossEntropy__  \n",
    "- Regresión: En clases Keras -> __MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, CosineSimilarity__   \n",
    "\n",
    "__Métricas__:  \n",
    "- Regresión: __MAE, MSE, MAPE__ :-)  \n",
    "- Clasificación: __Accuracy, Precision, Recall, f1, AuRoC__  \n",
    "\n",
    "¿Cuál es la diferencia entre Categorical y Sparse? ¿Por qué las funciones de pérdida son diferentes a las métricas en Clasificación? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El __batch_size__ es la cantidad de muestras que utiliza el SGD, y las __epochs__ son las iteraciones que realiza en el entrenamiento. (Son hiperparámetros de entrenamiento)    \n",
    "\n",
    "En una epoch se entrenan tantos batches como sea necesario para recorrer todo el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6545 - loss: 1.3319 - val_accuracy: 0.8985 - val_loss: 0.3865\n",
      "Epoch 2/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.3886 - val_accuracy: 0.9082 - val_loss: 0.3159\n",
      "Epoch 3/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.3103 - val_accuracy: 0.9258 - val_loss: 0.2641\n",
      "Epoch 4/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2778 - val_accuracy: 0.9307 - val_loss: 0.2436\n",
      "Epoch 5/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.2543 - val_accuracy: 0.9373 - val_loss: 0.2237\n",
      "Epoch 6/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.2334 - val_accuracy: 0.9408 - val_loss: 0.2093\n",
      "Epoch 7/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.2170 - val_accuracy: 0.9469 - val_loss: 0.1951\n",
      "Epoch 8/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9431 - loss: 0.1986 - val_accuracy: 0.9479 - val_loss: 0.1865\n",
      "Epoch 9/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1902 - val_accuracy: 0.9514 - val_loss: 0.1761\n",
      "Epoch 10/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1744 - val_accuracy: 0.9546 - val_loss: 0.1662\n",
      "Epoch 11/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1691 - val_accuracy: 0.9560 - val_loss: 0.1601\n",
      "Epoch 12/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1567 - val_accuracy: 0.9580 - val_loss: 0.1542\n",
      "Epoch 13/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1463 - val_accuracy: 0.9596 - val_loss: 0.1510\n",
      "Epoch 14/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1439 - val_accuracy: 0.9582 - val_loss: 0.1454\n",
      "Epoch 15/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1411 - val_accuracy: 0.9596 - val_loss: 0.1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEn el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\\nSi vemos que ya no baja mas, no serán necesarias tantas epochs.\\nImprimera tantas lineas como epochs hayamos puesto\\n\\nTampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\\nUtil para datasets desbalanceados.\\n\\nEl loss que muestra es el categoricalcrossentropy\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo con un batch_size de 64 imágenes por cada iteración, 10 epochs y especificando cuál es el conjunto de validación.\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64, # numero de muestras empleadas en el entrenamiento de SGD\n",
    "    epochs=15, # 1 por defecto. Insuficiente. Numero de vueltas del backpropagation\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    # En vez de validation data podemos usar el argumento validation_split=0.1\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "'''\n",
    "En el entreanamiento solo hay que fijarse que el loss va para abajo, es bueno.\n",
    "Si vemos que ya no baja mas, no serán necesarias tantas epochs.\n",
    "Imprimera tantas lineas como epochs hayamos puesto\n",
    "\n",
    "Tampoco usamos el class_weight, que le da más peso a las clases con pocas muestras\n",
    "Util para datasets desbalanceados.\n",
    "\n",
    "El loss que muestra es el categoricalcrossentropy\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9641 - loss: 0.1281 - val_accuracy: 0.9641 - val_loss: 0.1289\n",
      "Epoch 2/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.1193 - val_accuracy: 0.9650 - val_loss: 0.1251\n",
      "Epoch 3/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1126 - val_accuracy: 0.9660 - val_loss: 0.1213\n",
      "Epoch 4/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.1100 - val_accuracy: 0.9669 - val_loss: 0.1186\n",
      "Epoch 5/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.1063 - val_accuracy: 0.9669 - val_loss: 0.1164\n",
      "Epoch 6/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.1007 - val_accuracy: 0.9684 - val_loss: 0.1152\n",
      "Epoch 7/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0987 - val_accuracy: 0.9694 - val_loss: 0.1123\n",
      "Epoch 8/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.0925 - val_accuracy: 0.9697 - val_loss: 0.1090\n",
      "Epoch 9/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0887 - val_accuracy: 0.9686 - val_loss: 0.1100\n",
      "Epoch 10/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0860 - val_accuracy: 0.9726 - val_loss: 0.1058\n",
      "Epoch 11/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0829 - val_accuracy: 0.9717 - val_loss: 0.1040\n",
      "Epoch 12/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0809 - val_accuracy: 0.9713 - val_loss: 0.1023\n",
      "Epoch 13/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0739 - val_accuracy: 0.9723 - val_loss: 0.0996\n",
      "Epoch 14/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0719 - val_accuracy: 0.9724 - val_loss: 0.0975\n",
      "Epoch 15/15\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0732 - val_accuracy: 0.9737 - val_loss: 0.0967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15e04ef51f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=15,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 'auto', 'epochs': 15, 'steps': 782}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.796019971370697,\n",
       "  0.8989599943161011,\n",
       "  0.9137600064277649,\n",
       "  0.9225599765777588,\n",
       "  0.9286999702453613,\n",
       "  0.9345399737358093,\n",
       "  0.939079999923706,\n",
       "  0.9431999921798706,\n",
       "  0.9467200040817261,\n",
       "  0.9495000243186951,\n",
       "  0.9528599977493286,\n",
       "  0.9548799991607666,\n",
       "  0.957539975643158,\n",
       "  0.9593200087547302,\n",
       "  0.9615600109100342],\n",
       " 'loss': [0.8481431007385254,\n",
       "  0.36702215671539307,\n",
       "  0.30729517340660095,\n",
       "  0.2740143835544586,\n",
       "  0.2501780390739441,\n",
       "  0.23028628528118134,\n",
       "  0.21352754533290863,\n",
       "  0.199251189827919,\n",
       "  0.1861763745546341,\n",
       "  0.17525318264961243,\n",
       "  0.1649859994649887,\n",
       "  0.15597370266914368,\n",
       "  0.14769050478935242,\n",
       "  0.14034545421600342,\n",
       "  0.13337542116641998],\n",
       " 'val_accuracy': [0.8985000252723694,\n",
       "  0.9082000255584717,\n",
       "  0.9258000254631042,\n",
       "  0.9307000041007996,\n",
       "  0.9373000264167786,\n",
       "  0.9408000111579895,\n",
       "  0.9469000101089478,\n",
       "  0.9478999972343445,\n",
       "  0.9513999819755554,\n",
       "  0.9545999765396118,\n",
       "  0.9559999704360962,\n",
       "  0.9580000042915344,\n",
       "  0.9595999717712402,\n",
       "  0.9581999778747559,\n",
       "  0.9595999717712402],\n",
       " 'val_loss': [0.3865177631378174,\n",
       "  0.3159047067165375,\n",
       "  0.2641015648841858,\n",
       "  0.2436288595199585,\n",
       "  0.2237372249364853,\n",
       "  0.2092878371477127,\n",
       "  0.19514602422714233,\n",
       "  0.18654629588127136,\n",
       "  0.17614997923374176,\n",
       "  0.1662082076072693,\n",
       "  0.16013582050800323,\n",
       "  0.154161736369133,\n",
       "  0.15099750459194183,\n",
       "  0.1453629732131958,\n",
       "  0.14002229273319244]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Podemos ver como evoluciona el entrenamiento, en funcion de los epochs\n",
    "# Validacion y training estan muy cerca, no hay overfitting!\n",
    "# Todavia no ha acabado de coverger ya que el loss en validacion sigue bajando,\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1619\n",
      "test loss, test acc: [0.14016400277614594, 0.9591000080108643]\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el \"score\" a partir del conjunto de test\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "\n",
    "# Metodo evaluate para que nos de el error vs las metricas elegidas en la funcion compile\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pabma\\AppData\\Local\\Temp\\ipykernel_11748\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "predictions shape: (1, 10)\n",
      "[0.    0.    0.002 0.004 0.    0.    0.    0.994 0.    0.   ]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Ojo aqui viene slicing xq presupone que le entran varios inputs\n",
    "Nos da las probabilidades de pertenecer a una clase u otra.\n",
    "'''\n",
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions[0])\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona.\n",
    "     \n",
    "Vamos a configurar una red como esta:  \n",
    "<img src=\"./img/mlp_regresion.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 1.2508 - loss: 1.6734 - val_RootMeanSquaredError: 0.7950 - val_loss: 0.6320\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 1.0955 - loss: 1.2407 - val_RootMeanSquaredError: 0.7219 - val_loss: 0.5212\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.7687 - loss: 0.5922 - val_RootMeanSquaredError: 0.6713 - val_loss: 0.4507\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6642 - loss: 0.4414 - val_RootMeanSquaredError: 0.6560 - val_loss: 0.4304\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6550 - loss: 0.4294 - val_RootMeanSquaredError: 0.6478 - val_loss: 0.4197\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6559 - loss: 0.4303 - val_RootMeanSquaredError: 0.6413 - val_loss: 0.4113\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6421 - loss: 0.4126 - val_RootMeanSquaredError: 0.6333 - val_loss: 0.4011\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6419 - loss: 0.4123 - val_RootMeanSquaredError: 0.6316 - val_loss: 0.3989\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6934 - loss: 0.4834 - val_RootMeanSquaredError: 0.6290 - val_loss: 0.3956\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6261 - loss: 0.3922 - val_RootMeanSquaredError: 0.6275 - val_loss: 0.3937\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6296 - loss: 0.3967 - val_RootMeanSquaredError: 0.6202 - val_loss: 0.3847\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6214 - loss: 0.3865 - val_RootMeanSquaredError: 0.6170 - val_loss: 0.3807\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6170 - loss: 0.3810 - val_RootMeanSquaredError: 0.6152 - val_loss: 0.3784\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6304 - loss: 0.3976 - val_RootMeanSquaredError: 0.6177 - val_loss: 0.3816\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6358 - loss: 0.4047 - val_RootMeanSquaredError: 0.6107 - val_loss: 0.3730\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6231 - loss: 0.3884 - val_RootMeanSquaredError: 0.6154 - val_loss: 0.3787\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6274 - loss: 0.3937 - val_RootMeanSquaredError: 0.6074 - val_loss: 0.3689\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6154 - loss: 0.3788 - val_RootMeanSquaredError: 0.6256 - val_loss: 0.3913\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6808 - loss: 0.4726 - val_RootMeanSquaredError: 0.6337 - val_loss: 0.4015\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6598 - loss: 0.4356 - val_RootMeanSquaredError: 0.6220 - val_loss: 0.3869\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6277 - loss: 0.3945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    keras.layers.Dense(30, activation=\"relu\",\n",
    "                       input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "    # Sin fun de activa. ReLu no iria mal si el output es positivo. Sigmoide si esta acotado.\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics = [\"RootMeanSquaredError\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: [0.3910943269729614, 0.6253753304481506]\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE:\",mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\normalization.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.9113 - RootMeanSquaredError: 1.2650 - loss: 1.7736 - val_MeanAbsoluteError: 0.5494 - val_RootMeanSquaredError: 0.7618 - val_loss: 0.5803\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.5542 - RootMeanSquaredError: 0.8029 - loss: 0.6466 - val_MeanAbsoluteError: 0.5139 - val_RootMeanSquaredError: 0.7102 - val_loss: 0.5043\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.5048 - RootMeanSquaredError: 0.6970 - loss: 0.4860 - val_MeanAbsoluteError: 0.4944 - val_RootMeanSquaredError: 0.6804 - val_loss: 0.4629\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4834 - RootMeanSquaredError: 0.6686 - loss: 0.4478 - val_MeanAbsoluteError: 0.4839 - val_RootMeanSquaredError: 0.6689 - val_loss: 0.4474\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4615 - RootMeanSquaredError: 0.6436 - loss: 0.4145 - val_MeanAbsoluteError: 0.4792 - val_RootMeanSquaredError: 0.6719 - val_loss: 0.4515\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4747 - RootMeanSquaredError: 0.7391 - loss: 0.5563 - val_MeanAbsoluteError: 0.4699 - val_RootMeanSquaredError: 0.6551 - val_loss: 0.4291\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4552 - RootMeanSquaredError: 0.6374 - loss: 0.4064 - val_MeanAbsoluteError: 0.4589 - val_RootMeanSquaredError: 0.6500 - val_loss: 0.4225\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4565 - RootMeanSquaredError: 0.6399 - loss: 0.4101 - val_MeanAbsoluteError: 0.4583 - val_RootMeanSquaredError: 0.6491 - val_loss: 0.4213\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4533 - RootMeanSquaredError: 0.6392 - loss: 0.4091 - val_MeanAbsoluteError: 0.4614 - val_RootMeanSquaredError: 0.6421 - val_loss: 0.4123\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4462 - RootMeanSquaredError: 0.6254 - loss: 0.3916 - val_MeanAbsoluteError: 0.4544 - val_RootMeanSquaredError: 0.6404 - val_loss: 0.4102\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4403 - RootMeanSquaredError: 0.6169 - loss: 0.3812 - val_MeanAbsoluteError: 0.4482 - val_RootMeanSquaredError: 0.6335 - val_loss: 0.4013\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4384 - RootMeanSquaredError: 0.6131 - loss: 0.3760 - val_MeanAbsoluteError: 0.4553 - val_RootMeanSquaredError: 0.6330 - val_loss: 0.4007\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4475 - RootMeanSquaredError: 0.6263 - loss: 0.3924 - val_MeanAbsoluteError: 0.4464 - val_RootMeanSquaredError: 0.6280 - val_loss: 0.3944\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4404 - RootMeanSquaredError: 0.6223 - loss: 0.3875 - val_MeanAbsoluteError: 0.4558 - val_RootMeanSquaredError: 0.6302 - val_loss: 0.3971\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4408 - RootMeanSquaredError: 0.6222 - loss: 0.3873 - val_MeanAbsoluteError: 0.4467 - val_RootMeanSquaredError: 0.6244 - val_loss: 0.3899\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4400 - RootMeanSquaredError: 0.6169 - loss: 0.3807 - val_MeanAbsoluteError: 0.4395 - val_RootMeanSquaredError: 0.6220 - val_loss: 0.3868\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4342 - RootMeanSquaredError: 0.6110 - loss: 0.3734 - val_MeanAbsoluteError: 0.4431 - val_RootMeanSquaredError: 0.6192 - val_loss: 0.3834\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4385 - RootMeanSquaredError: 0.6158 - loss: 0.3793 - val_MeanAbsoluteError: 0.4403 - val_RootMeanSquaredError: 0.6204 - val_loss: 0.3848\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4290 - RootMeanSquaredError: 0.6041 - loss: 0.3651 - val_MeanAbsoluteError: 0.4378 - val_RootMeanSquaredError: 0.6158 - val_loss: 0.3792\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4335 - RootMeanSquaredError: 0.6072 - loss: 0.3687 - val_MeanAbsoluteError: 0.4352 - val_RootMeanSquaredError: 0.6139 - val_loss: 0.3768\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - MeanAbsoluteError: 0.4425 - RootMeanSquaredError: 0.6421 - loss: 0.4132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "#Otra forma pure-Keras:\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "\n",
    "norm_layer = keras.layers.Normalization(input_shape = X_train.shape[1:]) # Es una Standardization\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    # No hace falta capa de flatten. No hay que aplanar ninguna imagen\n",
    "    norm_layer,\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1) # una unica neurona de salida\n",
    "    # Sin fun de activa. ReLu no iria mal si el output es positivo. Sigmoide si esta acotado.\n",
    "])\n",
    "optimizer = keras.optimizers.SGD()\n",
    "model.compile(loss=\"mean_squared_error\",\n",
    "              optimizer=optimizer, metrics = [\"RootMeanSquaredError\",\"MeanAbsoluteError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: [0.39453360438346863, 0.6281191110610962, 0.4392242133617401]\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE:\",mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> (1.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320\u001b[0m (1.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (72.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17\u001b[0m (72.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nueva capa al toolbox:\n",
    "\n",
    "Funcionales:  \n",
    "__Normalize__: keras.layers.Normalization -> Nos hace la standardizacion de la entrada \n",
    "Hay que ejecutar el metodo Adapt antes de llamar al fit del modelo que incluya la capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma es emplear el formato TensorFlow. En este caso crea un directorio con varios ficheros que facilita el despliegue en algunas aplicaciones (ojo, que habría que llevar a producción todo el directorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model_otro.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model_k= keras.models.load_model(\"my_keras_model_otro.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4321 - RootMeanSquaredError: 0.6063 - loss: 0.3681\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4395 - RootMeanSquaredError: 0.6138 - loss: 0.3769\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4321 - RootMeanSquaredError: 0.6094 - loss: 0.3714\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4330 - RootMeanSquaredError: 0.6058 - loss: 0.3673\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4278 - RootMeanSquaredError: 0.5972 - loss: 0.3568\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4287 - RootMeanSquaredError: 0.6025 - loss: 0.3632\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4203 - RootMeanSquaredError: 0.5919 - loss: 0.3505\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - MeanAbsoluteError: 0.4304 - RootMeanSquaredError: 0.6052 - loss: 0.3665\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4176 - RootMeanSquaredError: 0.5914 - loss: 0.3500  \n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4212 - RootMeanSquaredError: 0.5996 - loss: 0.3597\n",
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4186 - RootMeanSquaredError: 0.5930 - loss: 0.3522 - val_MeanAbsoluteError: 0.4198 - val_RootMeanSquaredError: 0.5999 - val_loss: 0.3599\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4141 - RootMeanSquaredError: 0.5767 - loss: 0.3331 - val_MeanAbsoluteError: 0.4277 - val_RootMeanSquaredError: 0.6040 - val_loss: 0.3649\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4245 - RootMeanSquaredError: 0.6007 - loss: 0.3612 - val_MeanAbsoluteError: 0.4404 - val_RootMeanSquaredError: 0.6222 - val_loss: 0.3871\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4253 - RootMeanSquaredError: 0.6048 - loss: 0.3661 - val_MeanAbsoluteError: 0.4251 - val_RootMeanSquaredError: 0.6113 - val_loss: 0.3737\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4205 - RootMeanSquaredError: 0.5898 - loss: 0.3480 - val_MeanAbsoluteError: 0.4218 - val_RootMeanSquaredError: 0.6047 - val_loss: 0.3657\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4216 - RootMeanSquaredError: 0.5941 - loss: 0.3533 - val_MeanAbsoluteError: 0.4211 - val_RootMeanSquaredError: 0.6038 - val_loss: 0.3645\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4083 - RootMeanSquaredError: 0.5711 - loss: 0.3263 - val_MeanAbsoluteError: 0.4255 - val_RootMeanSquaredError: 0.5965 - val_loss: 0.3559\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4112 - RootMeanSquaredError: 0.5822 - loss: 0.3391 - val_MeanAbsoluteError: 0.4157 - val_RootMeanSquaredError: 0.5940 - val_loss: 0.3528\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4128 - RootMeanSquaredError: 0.5790 - loss: 0.3354 - val_MeanAbsoluteError: 0.4143 - val_RootMeanSquaredError: 0.5955 - val_loss: 0.3546\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4014 - RootMeanSquaredError: 0.5612 - loss: 0.3153 - val_MeanAbsoluteError: 0.4250 - val_RootMeanSquaredError: 0.5951 - val_loss: 0.3541\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4016 - RootMeanSquaredError: 0.5679 - loss: 0.3226 - val_MeanAbsoluteError: 0.4137 - val_RootMeanSquaredError: 0.5905 - val_loss: 0.3487\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4131 - RootMeanSquaredError: 0.5852 - loss: 0.3427 - val_MeanAbsoluteError: 0.4115 - val_RootMeanSquaredError: 0.5922 - val_loss: 0.3508\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4056 - RootMeanSquaredError: 0.5726 - loss: 0.3280 - val_MeanAbsoluteError: 0.4172 - val_RootMeanSquaredError: 0.5937 - val_loss: 0.3524\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4096 - RootMeanSquaredError: 0.5804 - loss: 0.3371 - val_MeanAbsoluteError: 0.4240 - val_RootMeanSquaredError: 0.5960 - val_loss: 0.3552\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4026 - RootMeanSquaredError: 0.5734 - loss: 0.3290 - val_MeanAbsoluteError: 0.4175 - val_RootMeanSquaredError: 0.5913 - val_loss: 0.3497\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3996 - RootMeanSquaredError: 0.5658 - loss: 0.3203 - val_MeanAbsoluteError: 0.4146 - val_RootMeanSquaredError: 0.5900 - val_loss: 0.3481\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4072 - RootMeanSquaredError: 0.5743 - loss: 0.3302 - val_MeanAbsoluteError: 0.4045 - val_RootMeanSquaredError: 0.5877 - val_loss: 0.3453\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4035 - RootMeanSquaredError: 0.5711 - loss: 0.3263 - val_MeanAbsoluteError: 0.4130 - val_RootMeanSquaredError: 0.5867 - val_loss: 0.3443\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4100 - RootMeanSquaredError: 0.5872 - loss: 0.3450 - val_MeanAbsoluteError: 0.4150 - val_RootMeanSquaredError: 0.5866 - val_loss: 0.3441\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4013 - RootMeanSquaredError: 0.5680 - loss: 0.3227 - val_MeanAbsoluteError: 0.4172 - val_RootMeanSquaredError: 0.5871 - val_loss: 0.3447\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3959 - RootMeanSquaredError: 0.5628 - loss: 0.3171 - val_MeanAbsoluteError: 0.4080 - val_RootMeanSquaredError: 0.5829 - val_loss: 0.3397\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4007 - RootMeanSquaredError: 0.5711 - loss: 0.3262 - val_MeanAbsoluteError: 0.4084 - val_RootMeanSquaredError: 0.5866 - val_loss: 0.3441\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3948 - RootMeanSquaredError: 0.5603 - loss: 0.3143 - val_MeanAbsoluteError: 0.4125 - val_RootMeanSquaredError: 0.5821 - val_loss: 0.3389\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3993 - RootMeanSquaredError: 0.5723 - loss: 0.3276 - val_MeanAbsoluteError: 0.4072 - val_RootMeanSquaredError: 0.5806 - val_loss: 0.3371\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3970 - RootMeanSquaredError: 0.5699 - loss: 0.3249 - val_MeanAbsoluteError: 0.4040 - val_RootMeanSquaredError: 0.5817 - val_loss: 0.3384\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3976 - RootMeanSquaredError: 0.5670 - loss: 0.3217 - val_MeanAbsoluteError: 0.4131 - val_RootMeanSquaredError: 0.5908 - val_loss: 0.3490\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.4031 - RootMeanSquaredError: 0.5700 - loss: 0.3250 - val_MeanAbsoluteError: 0.4033 - val_RootMeanSquaredError: 0.5862 - val_loss: 0.3436\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4130 - RootMeanSquaredError: 0.5824 - loss: 0.3394 - val_MeanAbsoluteError: 0.4019 - val_RootMeanSquaredError: 0.5833 - val_loss: 0.3402\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3947 - RootMeanSquaredError: 0.5635 - loss: 0.3176 - val_MeanAbsoluteError: 0.4023 - val_RootMeanSquaredError: 0.5795 - val_loss: 0.3358\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.4015 - RootMeanSquaredError: 0.5709 - loss: 0.3261 - val_MeanAbsoluteError: 0.4031 - val_RootMeanSquaredError: 0.5821 - val_loss: 0.3389\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3949 - RootMeanSquaredError: 0.5606 - loss: 0.3144 - val_MeanAbsoluteError: 0.3982 - val_RootMeanSquaredError: 0.5795 - val_loss: 0.3359\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3956 - RootMeanSquaredError: 0.5628 - loss: 0.3169 - val_MeanAbsoluteError: 0.4094 - val_RootMeanSquaredError: 0.5834 - val_loss: 0.3403\n",
      "Epoch 13/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3887 - RootMeanSquaredError: 0.5528 - loss: 0.3059 - val_MeanAbsoluteError: 0.3961 - val_RootMeanSquaredError: 0.5765 - val_loss: 0.3324\n",
      "Epoch 14/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3985 - RootMeanSquaredError: 0.5724 - loss: 0.3278 - val_MeanAbsoluteError: 0.3985 - val_RootMeanSquaredError: 0.5763 - val_loss: 0.3321\n",
      "Epoch 15/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3822 - RootMeanSquaredError: 0.5442 - loss: 0.2965 - val_MeanAbsoluteError: 0.3943 - val_RootMeanSquaredError: 0.5758 - val_loss: 0.3316\n",
      "Epoch 16/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3930 - RootMeanSquaredError: 0.5593 - loss: 0.3128 - val_MeanAbsoluteError: 0.4041 - val_RootMeanSquaredError: 0.5766 - val_loss: 0.3325\n",
      "Epoch 17/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3895 - RootMeanSquaredError: 0.5542 - loss: 0.3074 - val_MeanAbsoluteError: 0.4035 - val_RootMeanSquaredError: 0.5790 - val_loss: 0.3353\n",
      "Epoch 18/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3925 - RootMeanSquaredError: 0.5584 - loss: 0.3120 - val_MeanAbsoluteError: 0.4016 - val_RootMeanSquaredError: 0.5790 - val_loss: 0.3352\n",
      "Epoch 19/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3907 - RootMeanSquaredError: 0.5574 - loss: 0.3107 - val_MeanAbsoluteError: 0.3978 - val_RootMeanSquaredError: 0.5757 - val_loss: 0.3314\n",
      "Epoch 20/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3932 - RootMeanSquaredError: 0.5602 - loss: 0.3141 - val_MeanAbsoluteError: 0.4018 - val_RootMeanSquaredError: 0.5778 - val_loss: 0.3338\n",
      "Epoch 21/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3904 - RootMeanSquaredError: 0.5615 - loss: 0.3154 - val_MeanAbsoluteError: 0.3978 - val_RootMeanSquaredError: 0.5723 - val_loss: 0.3276\n",
      "Epoch 22/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3953 - RootMeanSquaredError: 0.5615 - loss: 0.3153 - val_MeanAbsoluteError: 0.3945 - val_RootMeanSquaredError: 0.5735 - val_loss: 0.3290\n",
      "Epoch 23/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3905 - RootMeanSquaredError: 0.5501 - loss: 0.3028 - val_MeanAbsoluteError: 0.4010 - val_RootMeanSquaredError: 0.5722 - val_loss: 0.3274\n",
      "Epoch 24/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3832 - RootMeanSquaredError: 0.5465 - loss: 0.2989 - val_MeanAbsoluteError: 0.3992 - val_RootMeanSquaredError: 0.5738 - val_loss: 0.3293\n",
      "Epoch 25/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3959 - RootMeanSquaredError: 0.5625 - loss: 0.3164 - val_MeanAbsoluteError: 0.3934 - val_RootMeanSquaredError: 0.5693 - val_loss: 0.3241\n",
      "Epoch 26/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3908 - RootMeanSquaredError: 0.5599 - loss: 0.3136 - val_MeanAbsoluteError: 0.4011 - val_RootMeanSquaredError: 0.5724 - val_loss: 0.3276\n",
      "Epoch 27/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3952 - RootMeanSquaredError: 0.5633 - loss: 0.3174 - val_MeanAbsoluteError: 0.3941 - val_RootMeanSquaredError: 0.5698 - val_loss: 0.3247\n",
      "Epoch 28/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3907 - RootMeanSquaredError: 0.5610 - loss: 0.3148 - val_MeanAbsoluteError: 0.3923 - val_RootMeanSquaredError: 0.5683 - val_loss: 0.3230\n",
      "Epoch 29/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3890 - RootMeanSquaredError: 0.5623 - loss: 0.3162 - val_MeanAbsoluteError: 0.3942 - val_RootMeanSquaredError: 0.5720 - val_loss: 0.3272\n",
      "Epoch 30/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3847 - RootMeanSquaredError: 0.5511 - loss: 0.3041 - val_MeanAbsoluteError: 0.3996 - val_RootMeanSquaredError: 0.5812 - val_loss: 0.3378\n",
      "Epoch 31/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3909 - RootMeanSquaredError: 0.5644 - loss: 0.3190 - val_MeanAbsoluteError: 0.3916 - val_RootMeanSquaredError: 0.5693 - val_loss: 0.3241\n",
      "Epoch 32/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3891 - RootMeanSquaredError: 0.5575 - loss: 0.3109 - val_MeanAbsoluteError: 0.3930 - val_RootMeanSquaredError: 0.5695 - val_loss: 0.3244\n",
      "Epoch 33/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3856 - RootMeanSquaredError: 0.5529 - loss: 0.3057 - val_MeanAbsoluteError: 0.3904 - val_RootMeanSquaredError: 0.5695 - val_loss: 0.3243\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "10 esta bien. Lo pondemos a 5 para el ejercicio\n",
    "¿Qué considera como dejar de mejorar? parametros min_delta y baseline\n",
    "'''\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, \n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros y tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guía \"casera\":\n",
    "\n",
    "1- Recetas (adaptada de \"Hands-on...\")  PARA MLPs!!!!    \n",
    "    * Capas:   \n",
    "        - Empezar con una capa oculta e ir añadiendo (dependiendo de la complejidad del problema, probar wide & deep)\n",
    "        - Si pocas features -> más neuronas  (aumentar la combinación de features) (num_features < 100) [Orientativo]  \n",
    "        - Si muchas features  -> menos neuronas (proyección tipo PCA) (num_features > 1000) [Orientativo] e ir aumentando en capas sucesivas\n",
    "        - O empezar con muchas (doble de tus features e ir \"estrechando los pantalones\")  \n",
    "        - Construcción en prisma o pirámide (para empezar)  \n",
    "        - Inicialización: Empezar con Glorot, cambiar a He  \n",
    "        - Activación: ReLU salvo la última, si muchas capas probar -> SELU o Swish (con el inicializador a LeCunn) \n",
    "    * Optimizadores:   \n",
    "        - Si muchos datos*features -> Adam o AdamW con sus valores por defecto  \n",
    "        - Si no, SGD con Nesterov activado, y momento a 0.9  \n",
    "        - Learning rate -> 0.001-0.0001 para empezar e ir creciendo (learning-rate warm-up) (Si te atreves, buscar adaptative learning rate y optimizar con esto)  \n",
    "    * Entrenamiento:  \n",
    "        - Epoch, probar con pocas para ver duración -> Epochs altas y Callback de Early Stop activado  \n",
    "        - Batch_Size -> 32, si tienes muchos datos y una GPU a mano puedes subir mucho 64,128,256...\n",
    "    * Regularización (lo veremos):  \n",
    "        - Dropout al 0.25-0.5 (sin SELU)\n",
    "\n",
    "\n",
    "\n",
    "2- Pasos  \n",
    "    - Si overfitting -> Regularizar: Earlystopping, Dropout (lo veremos en la siguiente sección)  \n",
    "    - Comprobar underfitting -> Aumentar epochs, aumentar batch_size  \n",
    "    - Jugar con optimizador: learning rate (de pequeño a grande), tipo de optimizador   \n",
    "    - Jugar con número de capas (ojo al overfitting) y las funciones de activación y la inicialización de pesos  \n",
    "    - Jugar con el número de neuronas por capa (suele ser piramide o prisma, pero puedes jugar a expandir dimensiones)  \n",
    "    - Combinar los dos anteriores  \n",
    "\n",
    "3- Keras Tuner:\n",
    "    https://keras.io/guides/keras_tuner/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herramientas adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard\n",
    "Keras tiene implementado un dashboard para monitorizar las ejecuciones del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crea este directorio\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# Guarda una carpeta nueva con la fecha de la ejecucion\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3886 - RootMeanSquaredError: 0.5647 - loss: 0.3191 - val_MeanAbsoluteError: 0.3944 - val_RootMeanSquaredError: 0.5752 - val_loss: 0.3308\n",
      "Epoch 2/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3857 - RootMeanSquaredError: 0.5525 - loss: 0.3055 - val_MeanAbsoluteError: 0.3883 - val_RootMeanSquaredError: 0.5677 - val_loss: 0.3223\n",
      "Epoch 3/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3916 - RootMeanSquaredError: 0.5607 - loss: 0.3145 - val_MeanAbsoluteError: 0.3941 - val_RootMeanSquaredError: 0.5697 - val_loss: 0.3245\n",
      "Epoch 4/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3854 - RootMeanSquaredError: 0.5543 - loss: 0.3073 - val_MeanAbsoluteError: 0.3901 - val_RootMeanSquaredError: 0.5748 - val_loss: 0.3304\n",
      "Epoch 5/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3840 - RootMeanSquaredError: 0.5514 - loss: 0.3043 - val_MeanAbsoluteError: 0.3882 - val_RootMeanSquaredError: 0.5682 - val_loss: 0.3229\n",
      "Epoch 6/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3844 - RootMeanSquaredError: 0.5536 - loss: 0.3066 - val_MeanAbsoluteError: 0.4055 - val_RootMeanSquaredError: 0.5743 - val_loss: 0.3298\n",
      "Epoch 7/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3782 - RootMeanSquaredError: 0.5404 - loss: 0.2923 - val_MeanAbsoluteError: 0.3885 - val_RootMeanSquaredError: 0.5710 - val_loss: 0.3261\n",
      "Epoch 8/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3809 - RootMeanSquaredError: 0.5468 - loss: 0.2992 - val_MeanAbsoluteError: 0.4028 - val_RootMeanSquaredError: 0.5722 - val_loss: 0.3274\n",
      "Epoch 9/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3874 - RootMeanSquaredError: 0.5543 - loss: 0.3074 - val_MeanAbsoluteError: 0.3945 - val_RootMeanSquaredError: 0.5708 - val_loss: 0.3258\n",
      "Epoch 10/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3844 - RootMeanSquaredError: 0.5528 - loss: 0.3058 - val_MeanAbsoluteError: 0.3860 - val_RootMeanSquaredError: 0.5656 - val_loss: 0.3199\n",
      "Epoch 11/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3826 - RootMeanSquaredError: 0.5564 - loss: 0.3097 - val_MeanAbsoluteError: 0.3915 - val_RootMeanSquaredError: 0.5686 - val_loss: 0.3234\n",
      "Epoch 12/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3851 - RootMeanSquaredError: 0.5524 - loss: 0.3054 - val_MeanAbsoluteError: 0.3932 - val_RootMeanSquaredError: 0.5799 - val_loss: 0.3363\n",
      "Epoch 13/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3866 - RootMeanSquaredError: 0.5595 - loss: 0.3131 - val_MeanAbsoluteError: 0.3916 - val_RootMeanSquaredError: 0.5665 - val_loss: 0.3210\n",
      "Epoch 14/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3898 - RootMeanSquaredError: 0.5594 - loss: 0.3131 - val_MeanAbsoluteError: 0.3866 - val_RootMeanSquaredError: 0.5674 - val_loss: 0.3219\n",
      "Epoch 15/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3861 - RootMeanSquaredError: 0.5517 - loss: 0.3045 - val_MeanAbsoluteError: 0.3902 - val_RootMeanSquaredError: 0.5647 - val_loss: 0.3189\n",
      "Epoch 16/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3853 - RootMeanSquaredError: 0.5547 - loss: 0.3079 - val_MeanAbsoluteError: 0.3836 - val_RootMeanSquaredError: 0.5674 - val_loss: 0.3220\n",
      "Epoch 17/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3896 - RootMeanSquaredError: 0.5787 - loss: 0.3353 - val_MeanAbsoluteError: 0.3910 - val_RootMeanSquaredError: 0.5652 - val_loss: 0.3194\n",
      "Epoch 18/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3806 - RootMeanSquaredError: 0.5474 - loss: 0.2999 - val_MeanAbsoluteError: 0.3928 - val_RootMeanSquaredError: 0.5658 - val_loss: 0.3201\n",
      "Epoch 19/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3811 - RootMeanSquaredError: 0.5453 - loss: 0.2977 - val_MeanAbsoluteError: 0.3863 - val_RootMeanSquaredError: 0.5667 - val_loss: 0.3211\n",
      "Epoch 20/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3864 - RootMeanSquaredError: 0.5541 - loss: 0.3073 - val_MeanAbsoluteError: 0.3994 - val_RootMeanSquaredError: 0.5685 - val_loss: 0.3232\n",
      "Epoch 21/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3817 - RootMeanSquaredError: 0.5381 - loss: 0.2896 - val_MeanAbsoluteError: 0.3915 - val_RootMeanSquaredError: 0.5646 - val_loss: 0.3187\n",
      "Epoch 22/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3810 - RootMeanSquaredError: 0.5428 - loss: 0.2947 - val_MeanAbsoluteError: 0.3931 - val_RootMeanSquaredError: 0.5646 - val_loss: 0.3187\n",
      "Epoch 23/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3861 - RootMeanSquaredError: 0.5590 - loss: 0.3127 - val_MeanAbsoluteError: 0.3868 - val_RootMeanSquaredError: 0.5729 - val_loss: 0.3282\n",
      "Epoch 24/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3760 - RootMeanSquaredError: 0.5368 - loss: 0.2883 - val_MeanAbsoluteError: 0.3844 - val_RootMeanSquaredError: 0.5640 - val_loss: 0.3181\n",
      "Epoch 25/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3745 - RootMeanSquaredError: 0.5350 - loss: 0.2869 - val_MeanAbsoluteError: 0.3960 - val_RootMeanSquaredError: 0.5646 - val_loss: 0.3188\n",
      "Epoch 26/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3828 - RootMeanSquaredError: 0.5500 - loss: 0.3027 - val_MeanAbsoluteError: 0.3897 - val_RootMeanSquaredError: 0.5747 - val_loss: 0.3303\n",
      "Epoch 27/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3855 - RootMeanSquaredError: 0.5541 - loss: 0.3071 - val_MeanAbsoluteError: 0.3953 - val_RootMeanSquaredError: 0.5654 - val_loss: 0.3197\n",
      "Epoch 28/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3838 - RootMeanSquaredError: 0.5496 - loss: 0.3021 - val_MeanAbsoluteError: 0.3900 - val_RootMeanSquaredError: 0.5644 - val_loss: 0.3185\n",
      "Epoch 29/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3781 - RootMeanSquaredError: 0.5449 - loss: 0.2970 - val_MeanAbsoluteError: 0.3851 - val_RootMeanSquaredError: 0.5654 - val_loss: 0.3197\n",
      "Epoch 30/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3939 - RootMeanSquaredError: 0.5662 - loss: 0.3210 - val_MeanAbsoluteError: 0.3923 - val_RootMeanSquaredError: 0.5760 - val_loss: 0.3318\n",
      "Epoch 31/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3910 - RootMeanSquaredError: 0.5651 - loss: 0.3199 - val_MeanAbsoluteError: 0.3828 - val_RootMeanSquaredError: 0.5640 - val_loss: 0.3181\n",
      "Epoch 32/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3780 - RootMeanSquaredError: 0.5397 - loss: 0.2915 - val_MeanAbsoluteError: 0.3846 - val_RootMeanSquaredError: 0.5609 - val_loss: 0.3146\n",
      "Epoch 33/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3838 - RootMeanSquaredError: 0.5569 - loss: 0.3103 - val_MeanAbsoluteError: 0.3930 - val_RootMeanSquaredError: 0.5671 - val_loss: 0.3216\n",
      "Epoch 34/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3705 - RootMeanSquaredError: 0.5275 - loss: 0.2786 - val_MeanAbsoluteError: 0.3867 - val_RootMeanSquaredError: 0.5631 - val_loss: 0.3171\n",
      "Epoch 35/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3804 - RootMeanSquaredError: 0.5477 - loss: 0.3001 - val_MeanAbsoluteError: 0.3830 - val_RootMeanSquaredError: 0.5616 - val_loss: 0.3154\n",
      "Epoch 36/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3789 - RootMeanSquaredError: 0.5477 - loss: 0.3001 - val_MeanAbsoluteError: 0.3869 - val_RootMeanSquaredError: 0.5599 - val_loss: 0.3135\n",
      "Epoch 37/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanAbsoluteError: 0.3797 - RootMeanSquaredError: 0.5463 - loss: 0.2985 - val_MeanAbsoluteError: 0.3988 - val_RootMeanSquaredError: 0.5780 - val_loss: 0.3341\n",
      "Epoch 38/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3844 - RootMeanSquaredError: 0.5537 - loss: 0.3070 - val_MeanAbsoluteError: 0.3883 - val_RootMeanSquaredError: 0.5623 - val_loss: 0.3162\n",
      "Epoch 39/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3733 - RootMeanSquaredError: 0.5367 - loss: 0.2884 - val_MeanAbsoluteError: 0.3831 - val_RootMeanSquaredError: 0.5594 - val_loss: 0.3130\n",
      "Epoch 40/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3744 - RootMeanSquaredError: 0.5375 - loss: 0.2890 - val_MeanAbsoluteError: 0.3896 - val_RootMeanSquaredError: 0.5622 - val_loss: 0.3161\n",
      "Epoch 41/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3834 - RootMeanSquaredError: 0.5534 - loss: 0.3064 - val_MeanAbsoluteError: 0.3822 - val_RootMeanSquaredError: 0.5618 - val_loss: 0.3156\n",
      "Epoch 42/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3799 - RootMeanSquaredError: 0.5500 - loss: 0.3026 - val_MeanAbsoluteError: 0.3833 - val_RootMeanSquaredError: 0.5613 - val_loss: 0.3151\n",
      "Epoch 43/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3812 - RootMeanSquaredError: 0.5532 - loss: 0.3062 - val_MeanAbsoluteError: 0.3858 - val_RootMeanSquaredError: 0.5604 - val_loss: 0.3140\n",
      "Epoch 44/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3802 - RootMeanSquaredError: 0.5463 - loss: 0.2986 - val_MeanAbsoluteError: 0.3833 - val_RootMeanSquaredError: 0.5583 - val_loss: 0.3118\n",
      "Epoch 45/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3799 - RootMeanSquaredError: 0.5448 - loss: 0.2968 - val_MeanAbsoluteError: 0.3896 - val_RootMeanSquaredError: 0.5626 - val_loss: 0.3165\n",
      "Epoch 46/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3793 - RootMeanSquaredError: 0.5477 - loss: 0.3001 - val_MeanAbsoluteError: 0.3867 - val_RootMeanSquaredError: 0.5571 - val_loss: 0.3104\n",
      "Epoch 47/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3813 - RootMeanSquaredError: 0.5470 - loss: 0.2992 - val_MeanAbsoluteError: 0.3822 - val_RootMeanSquaredError: 0.5649 - val_loss: 0.3191\n",
      "Epoch 48/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3713 - RootMeanSquaredError: 0.5305 - loss: 0.2816 - val_MeanAbsoluteError: 0.3879 - val_RootMeanSquaredError: 0.5587 - val_loss: 0.3122\n",
      "Epoch 49/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3788 - RootMeanSquaredError: 0.5459 - loss: 0.2980 - val_MeanAbsoluteError: 0.3825 - val_RootMeanSquaredError: 0.5623 - val_loss: 0.3162\n",
      "Epoch 50/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - MeanAbsoluteError: 0.3764 - RootMeanSquaredError: 0.5408 - loss: 0.2926 - val_MeanAbsoluteError: 0.3883 - val_RootMeanSquaredError: 0.5648 - val_loss: 0.3190\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8b5442a60c9feb21\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8b5442a60c9feb21\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Para lanzarlo desde el jupyter notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "#Para lanzarlo desde el terminal, hay que estar en la carpeta de los logs\n",
    "#tensorboard --logdir=./my_logs --port=6006\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BootCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "167a7833a0358ac30a26ad970c5914014f41a5348f3dc652232a762d6e3283fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
